# -*- coding: utf-8 -*-
"""
UCI Kalp HastalÄ±ÄŸÄ± Veri Seti - KapsamlÄ± Veri Analizi Raporu
===========================================================

Yazan: Veri Bilimci
Tarih: 26 Ekim 2025

Bu rapor UCI kalp hastalÄ±ÄŸÄ± veri setinin kapsamlÄ± analizini iÃ§ermektedir.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# GÃ¶rselleÅŸtirme ayarlarÄ±
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print("="*80)
print("UCI KALP HASTALIÄI VERÄ° SETÄ° - KAPSAMLI VERÄ° ANALÄ°ZÄ°")
print("="*80)

def load_and_explore_data(file_path):
    """
    Veri setini yÃ¼kler ve temel keÅŸif analizini yapar.
    
    Parameters:
    -----------
    file_path : str
        CSV dosyasÄ±nÄ±n yolu
        
    Returns:
    --------
    pd.DataFrame
        YÃ¼klenen veri seti
    """
    print("\n1. VERÄ° YÃœKLEME VE Ä°LK Ä°NCELEME")
    print("-" * 40)
    
    # Veri setini yÃ¼kle
    df = pd.read_csv(file_path)
    
    print(f"Veri seti boyutu: {df.shape}")
    print(f"Toplam kayÄ±t sayÄ±sÄ±: {df.shape[0]}")
    print(f"Ã–zellik sayÄ±sÄ±: {df.shape[1]}")
    
    print("\nVeri setinin ilk 5 satÄ±rÄ±:")
    print(df.head())
    
    print("\nVeri setinin temel bilgileri:")
    print(df.info())
    
    print("\nVeri tÃ¼rleri:")
    print(df.dtypes)
    
    return df

def check_missing_values(df):
    """
    Eksik deÄŸerleri kontrol eder ve rapor eder.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n2. EKSÄ°K DEÄER ANALÄ°ZÄ°")
    print("-" * 40)
    
    missing_values = df.isnull().sum()
    missing_percentage = (missing_values / len(df)) * 100
    
    missing_df = pd.DataFrame({
        'SÃ¼tun': missing_values.index,
        'Eksik DeÄŸer SayÄ±sÄ±': missing_values.values,
        'Eksik DeÄŸer YÃ¼zdesi (%)': missing_percentage.values
    }).sort_values('Eksik DeÄŸer SayÄ±sÄ±', ascending=False)
    
    print("Eksik deÄŸer raporu:")
    print(missing_df[missing_df['Eksik DeÄŸer SayÄ±sÄ±'] > 0])
    
    if missing_values.sum() == 0:
        print("âœ“ Veri setinde eksik deÄŸer bulunmuyor.")
    else:
        print(f"âš  Toplam eksik deÄŸer sayÄ±sÄ±: {missing_values.sum()}")
        
        # Eksik deÄŸerlerin gÃ¶rselleÅŸtirilmesi
        if missing_values.sum() > 0:
            plt.figure(figsize=(12, 6))
            missing_cols = missing_values[missing_values > 0]
            plt.bar(missing_cols.index, missing_cols.values, color='red', alpha=0.7)
            plt.title('SÃ¼tunlara GÃ¶re Eksik DeÄŸer SayÄ±larÄ±')
            plt.xlabel('SÃ¼tunlar')
            plt.ylabel('Eksik DeÄŸer SayÄ±sÄ±')
            plt.xticks(rotation=45)
            plt.tight_layout()
            plt.show()

def analyze_dataset_sources(df):
    """
    Veri setindeki farklÄ± kaynaklarÄ±nÄ± (Cleveland, Hungary, etc.) analiz eder.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n3. VERÄ° SETÄ° KAYNAKLARI ANALÄ°ZÄ°")
    print("-" * 40)
    
    if 'dataset' in df.columns:
        print("Veri seti kaynaklarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±:")
        dataset_counts = df['dataset'].value_counts()
        print(dataset_counts)
        
        # Veri kaynaklarÄ± gÃ¶rselleÅŸtirmesi
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        dataset_counts.plot(kind='bar', color='lightblue', alpha=0.8)
        plt.title('Veri Seti KaynaklarÄ±na GÃ¶re DaÄŸÄ±lÄ±m')
        plt.xlabel('Veri Seti KaynaÄŸÄ±')
        plt.ylabel('KayÄ±t SayÄ±sÄ±')
        plt.xticks(rotation=45)
        
        plt.subplot(2, 2, 2)
        plt.pie(dataset_counts.values, labels=dataset_counts.index, autopct='%1.1f%%')
        plt.title('Veri Seti KaynaklarÄ±nÄ±n YÃ¼zde DaÄŸÄ±lÄ±mÄ±')
        
        # Dataset'e gÃ¶re kalp hastalÄ±ÄŸÄ± daÄŸÄ±lÄ±mÄ±
        if 'num' in df.columns:
            df['heart_disease'] = (df['num'] > 0).astype(int)
            
            plt.subplot(2, 2, 3)
            cross_tab = pd.crosstab(df['dataset'], df['heart_disease'], normalize='index') * 100
            cross_tab.plot(kind='bar', stacked=False, color=['lightgreen', 'lightcoral'])
            plt.title('Veri KaynaÄŸÄ±na GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
            plt.xlabel('Veri KaynaÄŸÄ±')
            plt.ylabel('Oran (%)')
            plt.legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
            plt.xticks(rotation=45)
            
            plt.subplot(2, 2, 4)
            # Dataset'e gÃ¶re yaÅŸ ortalamasÄ±
            age_by_dataset = df.groupby('dataset')['age'].mean()
            age_by_dataset.plot(kind='bar', color='orange', alpha=0.8)
            plt.title('Veri KaynaÄŸÄ±na GÃ¶re Ortalama YaÅŸ')
            plt.xlabel('Veri KaynaÄŸÄ±')
            plt.ylabel('Ortalama YaÅŸ')
            plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.show()
        
        print("\nVeri kaynaÄŸÄ±na gÃ¶re istatistikler:")
        for dataset in df['dataset'].unique():
            subset = df[df['dataset'] == dataset]
            print(f"\n{dataset}:")
            print(f"  - KayÄ±t sayÄ±sÄ±: {len(subset)}")
            print(f"  - Ortalama yaÅŸ: {subset['age'].mean():.1f}")
            if 'heart_disease' in df.columns:
                print(f"  - Kalp hastalÄ±ÄŸÄ± oranÄ±: %{(subset['heart_disease'].mean() * 100):.1f}")

def check_fields_to_remove(df):
    """
    AtÄ±lmasÄ± gereken sÃ¼tunlarÄ± kontrol eder ve Ã¶nerir.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n4. ALINMASI GEREKEN SÃœTUN KONTROLÃœ")
    print("-" * 40)
    
    recommendations = []
    
    # ID sÃ¼tunu kontrolÃ¼
    if 'id' in df.columns:
        if df['id'].nunique() == len(df):
            recommendations.append(('id', 'Benzersiz ID sÃ¼tunu - analiz iÃ§in gereksiz'))
    
    # Tek deÄŸerli sÃ¼tunlar
    single_value_cols = []
    for col in df.columns:
        if df[col].nunique() == 1:
            single_value_cols.append(col)
            recommendations.append((col, f'Tek deÄŸer iÃ§eriyor: {df[col].iloc[0]}'))
    
    # YÃ¼ksek eksik deÄŸer oranÄ±na sahip sÃ¼tunlar
    high_missing_cols = []
    for col in df.columns:
        missing_ratio = df[col].isnull().sum() / len(df)
        if missing_ratio > 0.5:  # %50'den fazla eksik
            high_missing_cols.append(col)
            recommendations.append((col, f'%{missing_ratio*100:.1f} eksik deÄŸer'))
    
    # YÃ¼ksek kardinalite (Ã§ok fazla benzersiz deÄŸer)
    high_cardinality_cols = []
    for col in df.select_dtypes(include=['object']).columns:
        cardinality_ratio = df[col].nunique() / len(df)
        if cardinality_ratio > 0.8:  # %80'den fazla benzersiz deÄŸer
            high_cardinality_cols.append(col)
            recommendations.append((col, f'YÃ¼ksek kardinalite: {df[col].nunique()} benzersiz deÄŸer'))
    
    if recommendations:
        print("AtÄ±lmasÄ± Ã¶nerilen sÃ¼tunlar:")
        for col, reason in recommendations:
            print(f"  - {col}: {reason}")
    else:
        print("âœ“ AtÄ±lmasÄ± gereken sÃ¼tun tespit edilmedi.")
    
    return [rec[0] for rec in recommendations]

def detect_outliers(df):
    """
    AykÄ±rÄ± deÄŸerleri tespit eder ve gÃ¶rselleÅŸtirir.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n5. AYKIRI DEÄER ANALÄ°ZÄ°")
    print("-" * 40)
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    numeric_cols = [col for col in numeric_cols if col not in ['id', 'num', 'heart_disease']]
    
    # IQR yÃ¶ntemi ile aykÄ±rÄ± deÄŸer tespiti
    outlier_summary = {}
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.ravel()
    
    for i, col in enumerate(numeric_cols[:6]):  # Ä°lk 6 sayÄ±sal sÃ¼tun
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outlier_summary[col] = {
            'count': len(outliers),
            'percentage': (len(outliers) / len(df)) * 100,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound
        }
        
        # Box plot
        if i < len(axes):
            axes[i].boxplot(df[col].dropna())
            axes[i].set_title(f'{col}\n{len(outliers)} aykÄ±rÄ± deÄŸer (%{(len(outliers)/len(df)*100):.1f})')
            axes[i].set_ylabel(col)
    
    # KullanÄ±lmayan subplot'larÄ± gizle
    for i in range(len(numeric_cols), len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    plt.show()
    
    # AykÄ±rÄ± deÄŸer raporu
    print("AykÄ±rÄ± deÄŸer raporu (IQR yÃ¶ntemi):")
    print("-" * 50)
    for col, info in outlier_summary.items():
        print(f"{col}:")
        print(f"  - AykÄ±rÄ± deÄŸer sayÄ±sÄ±: {info['count']}")
        print(f"  - YÃ¼zdesi: %{info['percentage']:.1f}")
        print(f"  - Alt sÄ±nÄ±r: {info['lower_bound']:.2f}")
        print(f"  - Ãœst sÄ±nÄ±r: {info['upper_bound']:.2f}")
        print()

def analyze_gender_heart_disease_distribution(df):
    """
    Cinsiyete gÃ¶re kalp hastalÄ±ÄŸÄ± daÄŸÄ±lÄ±mÄ±nÄ± analiz eder.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n6. CÄ°NSÄ°YETE GÃ–RE KALP HASTALIÄI DAÄILIMI")
    print("-" * 40)
    
    if 'heart_disease' not in df.columns and 'num' in df.columns:
        df['heart_disease'] = (df['num'] > 0).astype(int)
    
    # Cinsiyet ve kalp hastalÄ±ÄŸÄ± Ã§apraz tablosu
    cross_tab = pd.crosstab(df['sex'], df['heart_disease'], margins=True)
    print("Cinsiyet ve kalp hastalÄ±ÄŸÄ± Ã§apraz tablosu:")
    print(cross_tab)
    
    # YÃ¼zdelik daÄŸÄ±lÄ±m
    cross_tab_pct = pd.crosstab(df['sex'], df['heart_disease'], normalize='index') * 100
    print("\nYÃ¼zdelik daÄŸÄ±lÄ±m (satÄ±r bazÄ±nda):")
    print(cross_tab_pct)
    
    # GÃ¶rselleÅŸtirme
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # Mutlak sayÄ±lar
    cross_tab_counts = pd.crosstab(df['sex'], df['heart_disease'])
    cross_tab_counts.plot(kind='bar', ax=axes[0], color=['lightblue', 'lightcoral'])
    axes[0].set_title('Cinsiyete GÃ¶re Kalp HastalÄ±ÄŸÄ± SayÄ±larÄ±')
    axes[0].set_xlabel('Cinsiyet')
    axes[0].set_ylabel('KiÅŸi SayÄ±sÄ±')
    axes[0].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0].tick_params(axis='x', rotation=0)
    
    # YÃ¼zdelik oranlar
    cross_tab_pct.plot(kind='bar', ax=axes[1], color=['lightblue', 'lightcoral'])
    axes[1].set_title('Cinsiyete GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[1].set_xlabel('Cinsiyet')
    axes[1].set_ylabel('Oran (%)')
    axes[1].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[1].tick_params(axis='x', rotation=0)
    
    # Stacked bar chart
    cross_tab_counts.plot(kind='bar', stacked=True, ax=axes[2], color=['lightblue', 'lightcoral'])
    axes[2].set_title('Cinsiyete GÃ¶re Kalp HastalÄ±ÄŸÄ± DaÄŸÄ±lÄ±mÄ± (YÄ±ÄŸÄ±lmÄ±ÅŸ)')
    axes[2].set_xlabel('Cinsiyet')
    axes[2].set_ylabel('KiÅŸi SayÄ±sÄ±')
    axes[2].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[2].tick_params(axis='x', rotation=0)
    
    plt.tight_layout()
    plt.show()

def analyze_age_gender_distributions(df):
    """
    YaÅŸ ve cinsiyet daÄŸÄ±lÄ±mlarÄ±nÄ± analiz eder ve normal daÄŸÄ±lÄ±ma uygunluÄŸunu test eder.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n7. YAÅ VE CÄ°NSÄ°YET DAÄILIMLARI - NORMAL DAÄILIM TESTÄ°")
    print("-" * 50)
    
    # Genel yaÅŸ daÄŸÄ±lÄ±mÄ± analizi
    print("YaÅŸ daÄŸÄ±lÄ±mÄ± istatistikleri:")
    print(f"  - Ortalama: {df['age'].mean():.2f}")
    print(f"  - Medyan: {df['age'].median():.2f}")
    print(f"  - Standart sapma: {df['age'].std():.2f}")
    print(f"  - Minimum: {df['age'].min()}")
    print(f"  - Maksimum: {df['age'].max()}")
    print(f"  - Ã‡eyreklikler: Q1={df['age'].quantile(0.25):.1f}, Q3={df['age'].quantile(0.75):.1f}")
    
    # Cinsiyet daÄŸÄ±lÄ±mÄ±
    print(f"\nCinsiyet daÄŸÄ±lÄ±mÄ±:")
    gender_counts = df['sex'].value_counts()
    gender_pct = df['sex'].value_counts(normalize=True) * 100
    for gender in gender_counts.index:
        print(f"  - {gender}: {gender_counts[gender]} kiÅŸi (%{gender_pct[gender]:.1f})")
    
    # Normal daÄŸÄ±lÄ±m testleri
    print(f"\nNormal daÄŸÄ±lÄ±m testleri:")
    print("Hâ‚€: Veriler normal daÄŸÄ±lÄ±ma uyar")
    print("Hâ‚: Veriler normal daÄŸÄ±lÄ±ma uymaz")
    print("Î± = 0.05")
    
    # Genel yaÅŸ daÄŸÄ±lÄ±mÄ±
    shapiro_stat, shapiro_p = stats.shapiro(df['age'])
    jarque_stat, jarque_p = stats.jarque_bera(df['age'])
    
    print(f"\nGenel yaÅŸ daÄŸÄ±lÄ±mÄ±:")
    print(f"  - Shapiro-Wilk: W={shapiro_stat:.4f}, p={shapiro_p:.6f}")
    print(f"  - Jarque-Bera: JB={jarque_stat:.4f}, p={jarque_p:.6f}")
    
    # Cinsiyete gÃ¶re yaÅŸ daÄŸÄ±lÄ±mÄ±
    for gender in df['sex'].unique():
        age_subset = df[df['sex'] == gender]['age']
        shapiro_stat, shapiro_p = stats.shapiro(age_subset)
        print(f"\n{gender} yaÅŸ daÄŸÄ±lÄ±mÄ±:")
        print(f"  - Shapiro-Wilk: W={shapiro_stat:.4f}, p={shapiro_p:.6f}")
        print(f"  - Ortalama: {age_subset.mean():.2f}")
        print(f"  - Standart sapma: {age_subset.std():.2f}")
    
    # GÃ¶rselleÅŸtirme
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # Genel yaÅŸ histogramÄ±
    axes[0, 0].hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black', density=True)
    axes[0, 0].set_title('YaÅŸ DaÄŸÄ±lÄ±mÄ± (Genel)')
    axes[0, 0].set_xlabel('YaÅŸ')
    axes[0, 0].set_ylabel('YoÄŸunluk')
    
    # Normal daÄŸÄ±lÄ±m eÄŸrisi ekleme
    mu, sigma = df['age'].mean(), df['age'].std()
    x = np.linspace(df['age'].min(), df['age'].max(), 100)
    axes[0, 0].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', label='Normal DaÄŸÄ±lÄ±m')
    axes[0, 0].legend()
    
    # Q-Q plot
    stats.probplot(df['age'], dist="norm", plot=axes[0, 1])
    axes[0, 1].set_title('Q-Q Plot (YaÅŸ)')
    
    # Cinsiyete gÃ¶re yaÅŸ daÄŸÄ±lÄ±mÄ±
    for i, gender in enumerate(df['sex'].unique()):
        age_subset = df[df['sex'] == gender]['age']
        axes[0, 2].hist(age_subset, alpha=0.7, label=gender, bins=15, density=True)
    axes[0, 2].set_title('Cinsiyete GÃ¶re YaÅŸ DaÄŸÄ±lÄ±mÄ±')
    axes[0, 2].set_xlabel('YaÅŸ')
    axes[0, 2].set_ylabel('YoÄŸunluk')
    axes[0, 2].legend()
    
    # Box plot - cinsiyete gÃ¶re yaÅŸ
    df.boxplot(column='age', by='sex', ax=axes[1, 0])
    axes[1, 0].set_title('Cinsiyete GÃ¶re YaÅŸ Box Plot')
    axes[1, 0].set_xlabel('Cinsiyet')
    axes[1, 0].set_ylabel('YaÅŸ')
    
    # Violin plot
    if 'heart_disease' in df.columns:
        # Kalp hastalÄ±ÄŸÄ±na gÃ¶re yaÅŸ daÄŸÄ±lÄ±mÄ±
        axes[1, 1].violinplot([df[df['heart_disease']==0]['age'], 
                              df[df['heart_disease']==1]['age']], 
                             positions=[0, 1])
        axes[1, 1].set_title('Kalp HastalÄ±ÄŸÄ±na GÃ¶re YaÅŸ DaÄŸÄ±lÄ±mÄ±')
        axes[1, 1].set_xticks([0, 1])
        axes[1, 1].set_xticklabels(['SaÄŸlÄ±klÄ±', 'Hasta'])
        axes[1, 1].set_ylabel('YaÅŸ')
    
    # YaÅŸ gruplarÄ±na gÃ¶re daÄŸÄ±lÄ±m
    age_groups = pd.cut(df['age'], bins=[0, 40, 50, 60, 100], labels=['<40', '40-50', '50-60', '60+'])
    age_group_counts = age_groups.value_counts()
    axes[1, 2].pie(age_group_counts.values, labels=age_group_counts.index, autopct='%1.1f%%')
    axes[1, 2].set_title('YaÅŸ GruplarÄ±na GÃ¶re DaÄŸÄ±lÄ±m')
    
    plt.tight_layout()
    plt.show()

# Ana analiz fonksiyonlarÄ±
def descriptive_statistics(df):
    """
    TanÄ±mlayÄ±cÄ± istatistikleri hesaplar ve gÃ¶rÃ¼ntÃ¼ler.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n8. TANIMLAYICI Ä°STATÄ°STÄ°KLER")
    print("-" * 40)

    print("SayÄ±sal deÄŸiÅŸkenler iÃ§in temel istatistikler:")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    print(df[numeric_cols].describe())

    print("\nKategorik deÄŸiÅŸkenler iÃ§in frekans analizi:")
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        print(f"\n{col} deÄŸiÅŸkeni daÄŸÄ±lÄ±mÄ±:")
        print(df[col].value_counts())

    # Target deÄŸiÅŸken analizi
    target_col = 'num'  # Kalp hastalÄ±ÄŸÄ± hedef deÄŸiÅŸkeni
    if target_col in df.columns:
        print(f"\n\nHedef deÄŸiÅŸken ({target_col}) daÄŸÄ±lÄ±mÄ±:")
        target_counts = df[target_col].value_counts()
        print(target_counts)
        
        # Binary sÄ±nÄ±flandÄ±rma iÃ§in hedef deÄŸiÅŸkeni dÃ¶nÃ¼ÅŸtÃ¼r
        df['heart_disease'] = (df[target_col] > 0).astype(int)
        print(f"\nBinary kalp hastalÄ±ÄŸÄ± daÄŸÄ±lÄ±mÄ±:")
        print("0: HastalÄ±k yok, 1: HastalÄ±k var")
        print(df['heart_disease'].value_counts())

def correlation_analysis(df):
    """
    Ã–zellikler arasÄ±ndaki korelasyon analizini yapar ve Ä±sÄ± haritasÄ± oluÅŸturur.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    """
    print("\n9. KORELASYON ANALÄ°ZÄ°")
    print("-" * 40)

    # Kategorik deÄŸiÅŸkenleri sayÄ±sal hale dÃ¶nÃ¼ÅŸtÃ¼r (geÃ§ici olarak)
    df_temp = df.copy()
    label_encoders = {}
    
    for col in df_temp.select_dtypes(include=['object']).columns:
        if col != 'dataset':  # dataset sÃ¼tununu koruyalÄ±m
            le = LabelEncoder()
            df_temp[col] = le.fit_transform(df_temp[col].astype(str))
            label_encoders[col] = le

    # SayÄ±sal deÄŸiÅŸkenler iÃ§in korelasyon matrisi
    numeric_df = df_temp.select_dtypes(include=[np.number])
    
    # ID sÃ¼tununu Ã§Ä±kar
    if 'id' in numeric_df.columns:
        numeric_df = numeric_df.drop('id', axis=1)
    
    correlation_matrix = numeric_df.corr()

    # Korelasyon Ä±sÄ± haritasÄ±
    plt.figure(figsize=(16, 12))
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    
    # Korelasyon matrisi gÃ¶rselleÅŸtirmesi
    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": 0.8}, fmt='.2f')
    plt.title('Ã–zellikler ArasÄ± Korelasyon Matrisi', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

    # Kalp hastalÄ±ÄŸÄ± ile en yÃ¼ksek korelasyonlu deÄŸiÅŸkenler
    if 'heart_disease' in correlation_matrix.columns:
        heart_correlations = correlation_matrix['heart_disease'].abs().sort_values(ascending=False)
        print("Kalp hastalÄ±ÄŸÄ± ile en yÃ¼ksek korelasyonlu deÄŸiÅŸkenler:")
        print(heart_correlations.drop('heart_disease'))  # Kendisi hariÃ§
        
        # En yÃ¼ksek korelasyonlu ilk 10 Ã¶zellik
        top_correlations = heart_correlations.drop('heart_disease').head(10)
        
        plt.figure(figsize=(12, 8))
        colors = ['red' if x > 0 else 'blue' for x in correlation_matrix['heart_disease'][top_correlations.index]]
        bars = plt.bar(range(len(top_correlations)), top_correlations.values, color=colors, alpha=0.7)
        plt.title('Kalp HastalÄ±ÄŸÄ± ile En YÃ¼ksek Korelasyonlu Ã–zellikler')
        plt.xlabel('Ã–zellikler')
        plt.ylabel('Mutlak Korelasyon')
        plt.xticks(range(len(top_correlations)), top_correlations.index, rotation=45, ha='right')
        
        # DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine yaz
        for bar, value in zip(bars, top_correlations.values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.show()

    # GÃ¼Ã§lÃ¼ korelasyonlarÄ± (>0.5 veya <-0.5) raporla
    strong_correlations = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.5:
                strong_correlations.append({
                    'DeÄŸiÅŸken 1': correlation_matrix.columns[i],
                    'DeÄŸiÅŸken 2': correlation_matrix.columns[j],
                    'Korelasyon': corr_value
                })
    
    if strong_correlations:
        print(f"\nGÃ¼Ã§lÃ¼ korelasyonlar (|r| > 0.5):")
        strong_corr_df = pd.DataFrame(strong_correlations).sort_values('Korelasyon', key=abs, ascending=False)
        print(strong_corr_df)
    
    return correlation_matrix

def generate_final_report(df, test_results, model_results, clustering_results, pca_results, feature_importance):
    """
    Final analiz raporunu oluÅŸturur ve yazdÄ±rÄ±r.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Orijinal veri seti
    test_results : dict
        Ä°statistiksel test sonuÃ§larÄ±
    model_results : list
        Model performans sonuÃ§larÄ±
    clustering_results : dict
        KÃ¼meleme analizi sonuÃ§larÄ±
    pca_results : dict
        PCA analizi sonuÃ§larÄ±
    feature_importance : pd.DataFrame
        Ã–zellik Ã¶nemliliÄŸi sonuÃ§larÄ±
    """
    print("\n" + "="*80)
    print("UCI KALP HASTALIÄI VERÄ° SETÄ° - FÄ°NAL ANALÄ°Z RAPORU")
    print("="*80)
    
    print("\nğŸ“Š VERÄ° SETÄ° Ã–ZETÄ°:")
    print(f"â€¢ Toplam kayÄ±t sayÄ±sÄ±: {df.shape[0]}")
    print(f"â€¢ Ã–zellik sayÄ±sÄ±: {df.shape[1]}")
    
    if 'heart_disease' in df.columns:
        print(f"â€¢ Kalp hastalÄ±ÄŸÄ± olan kiÅŸi sayÄ±sÄ±: {df['heart_disease'].sum()}")
        print(f"â€¢ Kalp hastalÄ±ÄŸÄ± oranÄ±: {df['heart_disease'].mean():.1%}")
    
    if 'dataset' in df.columns:
        print(f"â€¢ Veri kaynaklarÄ±: {', '.join(df['dataset'].unique())}")
        
    print(f"â€¢ YaÅŸ aralÄ±ÄŸÄ±: {df['age'].min()}-{df['age'].max()} yÄ±l")
    print(f"â€¢ Ortalama yaÅŸ: {df['age'].mean():.1f} yÄ±l")
    
    # Cinsiyet daÄŸÄ±lÄ±mÄ±
    gender_dist = df['sex'].value_counts(normalize=True) * 100
    print(f"â€¢ Cinsiyet daÄŸÄ±lÄ±mÄ±: {gender_dist.to_dict()}")

    print("\nğŸ“ˆ Ä°STATÄ°STÄ°KSEL BULGULAR:")
    
    # Normallik test sonuÃ§larÄ±
    if 'normality' in test_results:
        normal_count = sum(1 for result in test_results['normality'].values() if result['result'] == 'Normal daÄŸÄ±lÄ±m')
        total_tests = len(test_results['normality'])
        print(f"â€¢ Normallik testleri: {total_tests} testten {normal_count} tanesi normal daÄŸÄ±lÄ±m gÃ¶sterdi")
    
    # T-test sonuÃ§larÄ±
    if 't_tests' in test_results:
        for test_name, result in test_results['t_tests'].items():
            print(f"â€¢ {test_name}: p={result['p_value']:.6f} - {result['result']}")
    
    # Chi-square sonuÃ§larÄ±
    if 'chi_square' in test_results:
        for test_name, result in test_results['chi_square'].items():
            print(f"â€¢ {test_name} Chi-square: p={result['p_value']:.6f} - {result['result']}")
    
    # ANOVA sonuÃ§larÄ±
    if 'anova' in test_results:
        for test_name, result in test_results['anova'].items():
            print(f"â€¢ {test_name} ANOVA: p={result['p_value']:.6f} - {result['result']}")

    print("\nğŸ¤– MAKÄ°NE Ã–ÄRENMESÄ° SONUÃ‡LARI:")
    model_df = pd.DataFrame(model_results, columns=['Model', 'DoÄŸruluk OranÄ±'])
    model_df = model_df.sort_values('DoÄŸruluk OranÄ±', ascending=False)
    
    for _, row in model_df.iterrows():
        print(f"â€¢ {row['Model']}: {row['DoÄŸruluk OranÄ±']:.3f}")
    
    print(f"\nğŸ† En iyi performans: {model_df.iloc[0]['Model']} ({model_df.iloc[0]['DoÄŸruluk OranÄ±']:.3f})")

    print("\nğŸ¯ Ã–NEMLÄ° Ã–ZELLÄ°KLER:")
    print("En Ã¶nemli Ã¶zellikler (Random Forest modeline gÃ¶re):")
    for i in range(min(8, len(feature_importance))):
        feature = feature_importance.iloc[i]
        print(f"â€¢ {feature['feature']}: {feature['importance']:.3f}")

    print("\nğŸ” KÃœMELEME ANALÄ°ZÄ°:")
    if clustering_results:
        print(f"â€¢ Optimal kÃ¼me sayÄ±sÄ±: {clustering_results['optimal_k']}")
        print(f"â€¢ Silhouette skoru: {clustering_results['silhouette_score']:.3f}")
        print(f"â€¢ KÃ¼meleme kalitesi: {'Ä°yi' if clustering_results['silhouette_score'] > 0.5 else 'Orta' if clustering_results['silhouette_score'] > 0.3 else 'DÃ¼ÅŸÃ¼k'}")

    print(f"\nğŸ“‰ PCA ANALÄ°ZÄ°:")
    if pca_results:
        print(f"â€¢ Ä°lk 2 bileÅŸenin aÃ§Ä±kladÄ±ÄŸÄ± varyans: %{sum(pca_results['explained_variance_ratio'][:2])*100:.1f}")
        print(f"â€¢ %95 varyans iÃ§in gerekli bileÅŸen: {pca_results['components_95']}")
        print(f"â€¢ Boyut indirgeme potansiyeli: {'YÃ¼ksek' if pca_results['components_95'] < len(pca_results['explained_variance_ratio'])/2 else 'Orta' if pca_results['components_95'] < len(pca_results['explained_variance_ratio'])*0.8 else 'DÃ¼ÅŸÃ¼k'}")

    print("\nğŸ’¡ ANA BULGULAR VE Ã–NERÄ°LER:")
    
    # Cinsiyet etkisi analizi
    if 'chi_square' in test_results and 'gender_heart_disease' in test_results['chi_square']:
        if test_results['chi_square']['gender_heart_disease']['p_value'] < 0.05:
            print("â€¢ Cinsiyet kalp hastalÄ±ÄŸÄ± riski Ã¼zerinde anlamlÄ± etkiye sahiptir")
            
            # Hangi cinsiyette risk daha yÃ¼ksek?
            if 'heart_disease' in df.columns:
                male_risk = df[df['sex'] == 'Male']['heart_disease'].mean()
                female_risk = df[df['sex'] == 'Female']['heart_disease'].mean()
                
                if male_risk > female_risk:
                    print(f"  - Erkeklerde risk daha yÃ¼ksek: %{male_risk*100:.1f} vs %{female_risk*100:.1f}")
                else:
                    print(f"  - KadÄ±nlarda risk daha yÃ¼ksek: %{female_risk*100:.1f} vs %{male_risk*100:.1f}")
    
    # Model Ã¶nerileri
    best_model = model_df.iloc[0]['Model']
    if model_df.iloc[0]['DoÄŸruluk OranÄ±'] > 0.85:
        print(f"â€¢ {best_model} modeli yÃ¼ksek performans gÃ¶sterdi (%{model_df.iloc[0]['DoÄŸruluk OranÄ±']*100:.1f})")
        print("  - Klinik uygulamalar iÃ§in umut verici")
    elif model_df.iloc[0]['DoÄŸruluk OranÄ±'] > 0.75:
        print(f"â€¢ {best_model} modeli makul performans gÃ¶sterdi")
        print("  - Daha fazla veri ve Ã¶zellik mÃ¼hendisliÄŸi ile iyileÅŸtirilebilir")
    
    # Veri kalitesi deÄŸerlendirmesi
    missing_ratio = df.isnull().sum().sum() / (df.shape[0] * df.shape[1])
    if missing_ratio < 0.01:
        print("â€¢ Veri kalitesi mÃ¼kemmel - minimal eksik deÄŸer")
    elif missing_ratio < 0.05:
        print("â€¢ Veri kalitesi iyi - az eksik deÄŸer")
    else:
        print("â€¢ Veri kalitesi iyileÅŸtirilebilir - eksik deÄŸerler mevcut")

    print("\nğŸ“‹ SONUÃ‡:")
    print("UCI kalp hastalÄ±ÄŸÄ± veri seti Ã¼zerinde gerÃ§ekleÅŸtirilen kapsamlÄ± analiz,")
    print("kalp hastalÄ±ÄŸÄ± risk faktÃ¶rlerinin belirlenmesi ve tahmin modellerinin")
    print("geliÅŸtirilmesi aÃ§Ä±sÄ±ndan deÄŸerli bulgular sunmuÅŸtur.")
    
    if model_df.iloc[0]['DoÄŸruluk OranÄ±'] > 0.80:
        print(f"\n{best_model} modeli ile %{model_df.iloc[0]['DoÄŸruluk OranÄ±']*100:.1f} doÄŸruluk oranÄ±nda")
        print("kalp hastalÄ±ÄŸÄ± tahmini yapÄ±labilmektedir.")
    
    print(f"\nEn kritik risk faktÃ¶rleri arasÄ±nda {feature_importance.iloc[0]['feature']},")
    print(f"{feature_importance.iloc[1]['feature']} ve {feature_importance.iloc[2]['feature']} bulunmaktadÄ±r.")
    
    print("\n" + "="*80)
    print("ANALÄ°Z TAMAMLANDI - DETAYLI RAPOR Ä°Ã‡Ä°N 'UCI_Heart_Disease_Analysis_Report.md' DOSYASINA BAKINIZ")
    print("="*80)

# Ana analiz akÄ±ÅŸÄ±
def main_analysis():
    """
    TÃ¼m analiz adÄ±mlarÄ±nÄ± sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    print("Analiz baÅŸlatÄ±lÄ±yor...")
    
    # 1. Veri yÃ¼kleme ve keÅŸif
    df = load_and_explore_data('heart_disease_uci.csv')
    
    # 2. Eksik deÄŸer kontrolÃ¼
    check_missing_values(df)
    
    # 3. Veri seti kaynaklarÄ± analizi
    analyze_dataset_sources(df)
    
    # 4. AtÄ±lmasÄ± gereken sÃ¼tun kontrolÃ¼
    columns_to_remove = check_fields_to_remove(df)
    
    # 5. AykÄ±rÄ± deÄŸer analizi
    detect_outliers(df)
    
    # 6. Cinsiyet-kalp hastalÄ±ÄŸÄ± analizi
    analyze_gender_heart_disease_distribution(df)
    
    # 7. YaÅŸ ve cinsiyet daÄŸÄ±lÄ±mlarÄ±
    analyze_age_gender_distributions(df)
    
    # 8. TanÄ±mlayÄ±cÄ± istatistikler
    descriptive_statistics(df)
    
    # 9. Korelasyon analizi
    correlation_matrix = correlation_analysis(df)
    
    # 10. KapsamlÄ± gÃ¶rselleÅŸtirme
    comprehensive_data_visualization(df)
    
    # 11. Ä°statistiksel testler
    test_results = statistical_tests(df)
    
    # 12. GeliÅŸmiÅŸ gÃ¶rselleÅŸtirme
    advanced_visualization(df)
    
    # 13. Veri Ã¶n iÅŸleme
    df_processed, label_encoders = data_preprocessing(df)
    
    # 14. Makine Ã¶ÄŸrenmesi modelleri
    model_results, model_details, feature_importance = machine_learning_models(df_processed)
    
    # Veri setini ML iÃ§in hazÄ±rla
    feature_cols = [col for col in df_processed.columns if col not in ['id', 'num', 'heart_disease', 'age_group']]
    X = df_processed[feature_cols]
    y = df_processed['heart_disease']
    
    # EÄŸitim verisi iÃ§in split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Ã–lÃ§eklendirme
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # 15. KÃ¼meleme analizi
    clustering_results = clustering_analysis(X_train_scaled, y_train)
    
    # 16. PCA analizi
    pca_results = pca_analysis(X_train_scaled, y_train, clustering_results['cluster_labels'])
    
    # 17. Final rapor
    generate_final_report(df, test_results, model_results, clustering_results, pca_results, feature_importance)
    
    return {
        'original_data': df,
        'processed_data': df_processed,
        'correlation_matrix': correlation_matrix,
        'test_results': test_results,
        'model_results': model_results,
        'model_details': model_details,
        'feature_importance': feature_importance,
        'clustering_results': clustering_results,
        'pca_results': pca_results,
        'label_encoders': label_encoders
    }

# Analizi Ã§alÄ±ÅŸtÄ±r
if __name__ == "__main__":
    print("ğŸš€ UCI Kalp HastalÄ±ÄŸÄ± Veri Seti Analizi BaÅŸlatÄ±lÄ±yor...")
    results = main_analysis()
    print("âœ… Analiz baÅŸarÄ±yla tamamlandÄ±!")

def comprehensive_data_visualization(df):
    """
    KapsamlÄ± veri gÃ¶rselleÅŸtirmesi yapar.
    
    Parameters:
    -----------
    df : pd.DataFrame
        GÃ¶rselleÅŸtirilecek veri seti
    """
    print("\n10. KAPSAMLI VERÄ° GÃ–RSELLEÅTÄ°RME")
    print("-" * 40)

    # Ana daÄŸÄ±lÄ±m grafikleri
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # Hedef deÄŸiÅŸken daÄŸÄ±lÄ±mÄ±
    if 'heart_disease' in df.columns:
        df['heart_disease'].value_counts().plot(kind='bar', ax=axes[0, 0], color=['lightblue', 'lightcoral'])
        axes[0, 0].set_title('Kalp HastalÄ±ÄŸÄ± DaÄŸÄ±lÄ±mÄ±')
        axes[0, 0].set_xlabel('0: SaÄŸlÄ±klÄ±, 1: Hasta')
        axes[0, 0].set_ylabel('KiÅŸi SayÄ±sÄ±')
        axes[0, 0].tick_params(axis='x', rotation=0)

    # YaÅŸ daÄŸÄ±lÄ±mÄ±
    axes[0, 1].hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 1].set_title('YaÅŸ DaÄŸÄ±lÄ±mÄ±')
    axes[0, 1].set_xlabel('YaÅŸ')
    axes[0, 1].set_ylabel('Frekans')

    # Cinsiyet daÄŸÄ±lÄ±mÄ±
    df['sex'].value_counts().plot(kind='pie', ax=axes[0, 2], autopct='%1.1f%%', colors=['lightpink', 'lightblue'])
    axes[0, 2].set_title('Cinsiyet DaÄŸÄ±lÄ±mÄ±')

    # GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ daÄŸÄ±lÄ±mÄ±
    df['cp'].value_counts().plot(kind='bar', ax=axes[1, 0], color='lightgreen')
    axes[1, 0].set_title('GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ± TÃ¼rÃ¼ DaÄŸÄ±lÄ±mÄ±')
    axes[1, 0].set_xlabel('GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ± TÃ¼rÃ¼')
    axes[1, 0].set_ylabel('Frekans')
    axes[1, 0].tick_params(axis='x', rotation=45)

    # Kolesterol seviyesi daÄŸÄ±lÄ±mÄ±
    axes[1, 1].hist(df['chol'], bins=20, alpha=0.7, color='orange', edgecolor='black')
    axes[1, 1].set_title('Kolesterol Seviyesi DaÄŸÄ±lÄ±mÄ±')
    axes[1, 1].set_xlabel('Kolesterol (mg/dl)')
    axes[1, 1].set_ylabel('Frekans')

    # Maksimum kalp atÄ±ÅŸÄ± daÄŸÄ±lÄ±mÄ±
    axes[1, 2].hist(df['thalch'], bins=20, alpha=0.7, color='purple', edgecolor='black')
    axes[1, 2].set_title('Maksimum Kalp AtÄ±ÅŸÄ± DaÄŸÄ±lÄ±mÄ±')
    axes[1, 2].set_xlabel('Kalp AtÄ±ÅŸÄ± (bpm)')
    axes[1, 2].set_ylabel('Frekans')

    plt.tight_layout()
    plt.show()

    # Ä°kinci set gÃ¶rselleÅŸtirmeler - Klinik parametreler
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Kan basÄ±ncÄ± daÄŸÄ±lÄ±mÄ±
    axes[0, 0].hist(df['trestbps'], bins=20, alpha=0.7, color='red', edgecolor='black')
    axes[0, 0].set_title('Dinlenme Kan BasÄ±ncÄ± DaÄŸÄ±lÄ±mÄ±')
    axes[0, 0].set_xlabel('Kan BasÄ±ncÄ± (mmHg)')
    axes[0, 0].set_ylabel('Frekans')
    
    # ST depresyonu daÄŸÄ±lÄ±mÄ±
    axes[0, 1].hist(df['oldpeak'], bins=20, alpha=0.7, color='brown', edgecolor='black')
    axes[0, 1].set_title('ST Depresyonu DaÄŸÄ±lÄ±mÄ±')
    axes[0, 1].set_xlabel('ST Depresyonu')
    axes[0, 1].set_ylabel('Frekans')
    
    # Major damar sayÄ±sÄ±
    if 'ca' in df.columns:
        df['ca'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 0], color='teal')
        axes[1, 0].set_title('Major Damar SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±')
        axes[1, 0].set_xlabel('Major Damar SayÄ±sÄ±')
        axes[1, 0].set_ylabel('Frekans')
        axes[1, 0].tick_params(axis='x', rotation=0)
    
    # Thalassemia daÄŸÄ±lÄ±mÄ±
    if 'thal' in df.columns:
        df['thal'].value_counts().plot(kind='bar', ax=axes[1, 1], color='gold')
        axes[1, 1].set_title('Thalassemia TÃ¼rÃ¼ DaÄŸÄ±lÄ±mÄ±')
        axes[1, 1].set_xlabel('Thalassemia TÃ¼rÃ¼')
        axes[1, 1].set_ylabel('Frekans')
        axes[1, 1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.show()

    print("âœ“ KapsamlÄ± gÃ¶rselleÅŸtirmeler oluÅŸturuldu.")

def statistical_tests(df):
    """
    KapsamlÄ± istatistiksel testleri gerÃ§ekleÅŸtirir.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Test edilecek veri seti
        
    Returns:
    --------
    dict
        Test sonuÃ§larÄ±nÄ± iÃ§eren sÃ¶zlÃ¼k
    """
    print("\n11. Ä°STATÄ°STÄ°KSEL TESTLER")
    print("-" * 40)
    
    test_results = {}

    # Normallik testleri (Shapiro-Wilk)
    print("Normallik Testleri (Shapiro-Wilk):")
    print("Hâ‚€: Veriler normal daÄŸÄ±lÄ±ma uyar")
    print("Hâ‚: Veriler normal daÄŸÄ±lÄ±ma uymaz")
    print("Î± = 0.05")
    
    normality_results = {}
    numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']
    
    for col in numeric_cols:
        if col in df.columns:
            # Shapiro-Wilk testi
            statistic, p_value = stats.shapiro(df[col].dropna())
            result = "Normal daÄŸÄ±lÄ±m" if p_value > 0.05 else "Normal daÄŸÄ±lÄ±m deÄŸil"
            normality_results[col] = {'statistic': statistic, 'p_value': p_value, 'result': result}
            print(f"{col}: W={statistic:.4f}, p-value = {p_value:.6f} â†’ {result}")
    
    test_results['normality'] = normality_results

    # T-testleri
    print("\n\nBaÄŸÄ±msÄ±z T-Testleri:")
    t_test_results = {}
    
    # 1. Cinsiyete gÃ¶re yaÅŸ farkÄ±
    print("\n1. Cinsiyete gÃ¶re yaÅŸ farkÄ±:")
    male_ages = df[df['sex'] == 'Male']['age']
    female_ages = df[df['sex'] == 'Female']['age']
    t_stat, t_p_value = stats.ttest_ind(male_ages, female_ages)
    print(f"   T-istatistiÄŸi: {t_stat:.4f}")
    print(f"   P-deÄŸeri: {t_p_value:.6f}")
    print(f"   Erkek yaÅŸ ort: {male_ages.mean():.1f}, KadÄ±n yaÅŸ ort: {female_ages.mean():.1f}")
    result = "AnlamlÄ± fark var" if t_p_value < 0.05 else "AnlamlÄ± fark yok"
    print(f"   SonuÃ§ (Î±=0.05): {result}")
    t_test_results['gender_age'] = {'t_stat': t_stat, 'p_value': t_p_value, 'result': result}
    
    # 2. Kalp hastalÄ±ÄŸÄ±na gÃ¶re yaÅŸ farkÄ±
    if 'heart_disease' in df.columns:
        print("\n2. Kalp hastalÄ±ÄŸÄ±na gÃ¶re yaÅŸ farkÄ±:")
        healthy_ages = df[df['heart_disease'] == 0]['age']
        diseased_ages = df[df['heart_disease'] == 1]['age']
        t_stat2, t_p_value2 = stats.ttest_ind(healthy_ages, diseased_ages)
        print(f"   T-istatistiÄŸi: {t_stat2:.4f}")
        print(f"   P-deÄŸeri: {t_p_value2:.6f}")
        print(f"   SaÄŸlÄ±klÄ± yaÅŸ ort: {healthy_ages.mean():.1f}, Hasta yaÅŸ ort: {diseased_ages.mean():.1f}")
        result2 = "AnlamlÄ± fark var" if t_p_value2 < 0.05 else "AnlamlÄ± fark yok"
        print(f"   SonuÃ§ (Î±=0.05): {result2}")
        t_test_results['heart_disease_age'] = {'t_stat': t_stat2, 'p_value': t_p_value2, 'result': result2}
    
    test_results['t_tests'] = t_test_results

    # Chi-square testleri
    print("\n\nChi-square BaÄŸÄ±msÄ±zlÄ±k Testleri:")
    chi_square_results = {}
    
    # 1. Cinsiyet ve kalp hastalÄ±ÄŸÄ± iliÅŸkisi
    if 'heart_disease' in df.columns:
        print("\n1. Cinsiyet ve kalp hastalÄ±ÄŸÄ± iliÅŸkisi:")
        contingency_table = pd.crosstab(df['sex'], df['heart_disease'])
        chi2, chi_p_value, dof, expected = stats.chi2_contingency(contingency_table)
        print("   Kontinjensi Tablosu:")
        print(contingency_table)
        print(f"   Chi-square: {chi2:.4f}")
        print(f"   P-deÄŸeri: {chi_p_value:.6f}")
        print(f"   Serbestlik derecesi: {dof}")
        result = "BaÄŸÄ±mlÄ± (iliÅŸki var)" if chi_p_value < 0.05 else "BaÄŸÄ±msÄ±z (iliÅŸki yok)"
        print(f"   SonuÃ§ (Î±=0.05): {result}")
        chi_square_results['gender_heart_disease'] = {
            'chi2': chi2, 'p_value': chi_p_value, 'dof': dof, 'result': result,
            'contingency_table': contingency_table
        }
    
    # 2. GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ ve kalp hastalÄ±ÄŸÄ± iliÅŸkisi
    if 'heart_disease' in df.columns:
        print("\n2. GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ ve kalp hastalÄ±ÄŸÄ± iliÅŸkisi:")
        contingency_table2 = pd.crosstab(df['cp'], df['heart_disease'])
        chi2_2, chi_p_value2, dof2, expected2 = stats.chi2_contingency(contingency_table2)
        print("   Kontinjensi Tablosu:")
        print(contingency_table2)
        print(f"   Chi-square: {chi2_2:.4f}")
        print(f"   P-deÄŸeri: {chi_p_value2:.6f}")
        result2 = "BaÄŸÄ±mlÄ± (iliÅŸki var)" if chi_p_value2 < 0.05 else "BaÄŸÄ±msÄ±z (iliÅŸki yok)"
        print(f"   SonuÃ§ (Î±=0.05): {result2}")
        chi_square_results['cp_heart_disease'] = {
            'chi2': chi2_2, 'p_value': chi_p_value2, 'dof': dof2, 'result': result2
        }
    
    test_results['chi_square'] = chi_square_results

    # ANOVA testleri
    print("\n\nTek YÃ¶nlÃ¼ ANOVA Testleri:")
    anova_results = {}
    
    # 1. GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ne gÃ¶re yaÅŸ farklarÄ±
    print("\n1. GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ne gÃ¶re yaÅŸ farklarÄ±:")
    cp_groups = [df[df['cp'] == cp_type]['age'].dropna() for cp_type in df['cp'].unique()]
    f_stat, anova_p_value = stats.f_oneway(*cp_groups)
    print(f"   F-istatistiÄŸi: {f_stat:.4f}")
    print(f"   P-deÄŸeri: {anova_p_value:.6f}")
    result = "Gruplar arasÄ± anlamlÄ± fark var" if anova_p_value < 0.05 else "Gruplar arasÄ± anlamlÄ± fark yok"
    print(f"   SonuÃ§ (Î±=0.05): {result}")
    anova_results['cp_age'] = {'f_stat': f_stat, 'p_value': anova_p_value, 'result': result}
    
    # 2. Veri seti kaynaÄŸÄ±na gÃ¶re yaÅŸ farklarÄ±
    if 'dataset' in df.columns:
        print("\n2. Veri seti kaynaÄŸÄ±na gÃ¶re yaÅŸ farklarÄ±:")
        dataset_groups = [df[df['dataset'] == dataset_type]['age'].dropna() for dataset_type in df['dataset'].unique()]
        f_stat2, anova_p_value2 = stats.f_oneway(*dataset_groups)
        print(f"   F-istatistiÄŸi: {f_stat2:.4f}")
        print(f"   P-deÄŸeri: {anova_p_value2:.6f}")
        result2 = "Gruplar arasÄ± anlamlÄ± fark var" if anova_p_value2 < 0.05 else "Gruplar arasÄ± anlamlÄ± fark yok"
        print(f"   SonuÃ§ (Î±=0.05): {result2}")
        anova_results['dataset_age'] = {'f_stat': f_stat2, 'p_value': anova_p_value2, 'result': result2}
    
    test_results['anova'] = anova_results
    
    # Mann-Whitney U testleri (parametrik olmayan)
    print("\n\nMann-Whitney U Testleri (Parametrik Olmayan):")
    mann_whitney_results = {}
    
    if 'heart_disease' in df.columns:
        print("\n1. Kalp hastalÄ±ÄŸÄ±na gÃ¶re kolesterol seviyesi farkÄ±:")
        healthy_chol = df[df['heart_disease'] == 0]['chol'].dropna()
        diseased_chol = df[df['heart_disease'] == 1]['chol'].dropna()
        u_stat, u_p_value = stats.mannwhitneyu(healthy_chol, diseased_chol, alternative='two-sided')
        print(f"   U-istatistiÄŸi: {u_stat:.4f}")
        print(f"   P-deÄŸeri: {u_p_value:.6f}")
        print(f"   SaÄŸlÄ±klÄ± kolesterol med: {healthy_chol.median():.1f}, Hasta kolesterol med: {diseased_chol.median():.1f}")
        result = "AnlamlÄ± fark var" if u_p_value < 0.05 else "AnlamlÄ± fark yok"
        print(f"   SonuÃ§ (Î±=0.05): {result}")
        mann_whitney_results['heart_disease_cholesterol'] = {
            'u_stat': u_stat, 'p_value': u_p_value, 'result': result
        }
    
    test_results['mann_whitney'] = mann_whitney_results
    
    return test_results

def advanced_visualization(df):
    """
    GeliÅŸmiÅŸ gÃ¶rselleÅŸtirmeler ve karÅŸÄ±laÅŸtÄ±rmalÄ± analizler yapar.
    
    Parameters:
    -----------
    df : pd.DataFrame
        GÃ¶rselleÅŸtirilecek veri seti
    """
    print("\n12. GELIÅMIÅ GÃ–RSELLEÅTÄ°RME VE KARÅILAÅTIRMALI ANALÄ°Z")
    print("-" * 50)

    if 'heart_disease' not in df.columns and 'num' in df.columns:
        df['heart_disease'] = (df['num'] > 0).astype(int)

    # Ã‡iftli deÄŸiÅŸken iliÅŸkileri - Box plotlar
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # YaÅŸ vs Kalp hastalÄ±ÄŸÄ± (Box plot)
    axes[0, 0].boxplot([df[df['heart_disease']==0]['age'], 
                        df[df['heart_disease']==1]['age']], 
                       labels=['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 0].set_title('Kalp HastalÄ±ÄŸÄ± Durumuna GÃ¶re YaÅŸ DaÄŸÄ±lÄ±mÄ±')
    axes[0, 0].set_ylabel('YaÅŸ')

    # Kolesterol vs Kalp hastalÄ±ÄŸÄ±
    axes[0, 1].boxplot([df[df['heart_disease']==0]['chol'], 
                        df[df['heart_disease']==1]['chol']], 
                       labels=['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 1].set_title('Kalp HastalÄ±ÄŸÄ± Durumuna GÃ¶re Kolesterol Seviyesi')
    axes[0, 1].set_ylabel('Kolesterol (mg/dl)')

    # Maksimum kalp atÄ±ÅŸÄ± vs Kalp hastalÄ±ÄŸÄ±
    axes[1, 0].boxplot([df[df['heart_disease']==0]['thalch'], 
                        df[df['heart_disease']==1]['thalch']], 
                       labels=['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[1, 0].set_title('Kalp HastalÄ±ÄŸÄ± Durumuna GÃ¶re Max Kalp AtÄ±ÅŸÄ±')
    axes[1, 0].set_ylabel('Kalp AtÄ±ÅŸÄ± (bpm)')

    # Dinlenme kan basÄ±ncÄ± vs Kalp hastalÄ±ÄŸÄ±
    axes[1, 1].boxplot([df[df['heart_disease']==0]['trestbps'], 
                        df[df['heart_disease']==1]['trestbps']], 
                       labels=['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[1, 1].set_title('Kalp HastalÄ±ÄŸÄ± Durumuna GÃ¶re Dinlenme Kan BasÄ±ncÄ±')
    axes[1, 1].set_ylabel('Kan BasÄ±ncÄ± (mmHg)')

    plt.tight_layout()
    plt.show()

    # Kategorik deÄŸiÅŸkenler analizi
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # Cinsiyet ve kalp hastalÄ±ÄŸÄ±
    cross_tab = pd.crosstab(df['sex'], df['heart_disease'], normalize='index') * 100
    cross_tab.plot(kind='bar', ax=axes[0, 0], color=['lightblue', 'lightcoral'])
    axes[0, 0].set_title('Cinsiyete GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[0, 0].set_xlabel('Cinsiyet')
    axes[0, 0].set_ylabel('Oran (%)')
    axes[0, 0].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 0].tick_params(axis='x', rotation=0)
    
    # GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tÃ¼rÃ¼ ve kalp hastalÄ±ÄŸÄ±
    cp_cross_tab = pd.crosstab(df['cp'], df['heart_disease'], normalize='index') * 100
    cp_cross_tab.plot(kind='bar', ax=axes[0, 1], color=['lightblue', 'lightcoral'])
    axes[0, 1].set_title('GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ± TÃ¼rÃ¼ne GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[0, 1].set_xlabel('GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ± TÃ¼rÃ¼')
    axes[0, 1].set_ylabel('Oran (%)')
    axes[0, 1].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # AÃ§lÄ±k kan ÅŸekeri ve kalp hastalÄ±ÄŸÄ±
    fbs_cross_tab = pd.crosstab(df['fbs'], df['heart_disease'], normalize='index') * 100
    fbs_cross_tab.plot(kind='bar', ax=axes[0, 2], color=['lightblue', 'lightcoral'])
    axes[0, 2].set_title('AÃ§lÄ±k Kan Åekerine GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[0, 2].set_xlabel('AÃ§lÄ±k Kan Åekeri > 120 mg/dl')
    axes[0, 2].set_ylabel('Oran (%)')
    axes[0, 2].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 2].tick_params(axis='x', rotation=0)
    
    # Egzersiz anjini ve kalp hastalÄ±ÄŸÄ±
    exang_cross_tab = pd.crosstab(df['exang'], df['heart_disease'], normalize='index') * 100
    exang_cross_tab.plot(kind='bar', ax=axes[1, 0], color=['lightblue', 'lightcoral'])
    axes[1, 0].set_title('Egzersiz Anjinine GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[1, 0].set_xlabel('Egzersiz Anjini')
    axes[1, 0].set_ylabel('Oran (%)')
    axes[1, 0].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[1, 0].tick_params(axis='x', rotation=0)
    
    # YaÅŸ gruplarÄ± ve kalp hastalÄ±ÄŸÄ±
    df['age_group'] = pd.cut(df['age'], bins=[0, 45, 55, 65, 100], 
                            labels=['â‰¤45', '46-55', '56-65', '>65'])
    age_group_cross_tab = pd.crosstab(df['age_group'], df['heart_disease'], normalize='index') * 100
    age_group_cross_tab.plot(kind='bar', ax=axes[1, 1], color=['lightblue', 'lightcoral'])
    axes[1, 1].set_title('YaÅŸ GruplarÄ±na GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
    axes[1, 1].set_xlabel('YaÅŸ Grubu')
    axes[1, 1].set_ylabel('Oran (%)')
    axes[1, 1].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[1, 1].tick_params(axis='x', rotation=0)
    
    # Veri seti kaynaÄŸÄ±na gÃ¶re kalp hastalÄ±ÄŸÄ± (eÄŸer varsa)
    if 'dataset' in df.columns:
        dataset_cross_tab = pd.crosstab(df['dataset'], df['heart_disease'], normalize='index') * 100
        dataset_cross_tab.plot(kind='bar', ax=axes[1, 2], color=['lightblue', 'lightcoral'])
        axes[1, 2].set_title('Veri KaynaÄŸÄ±na GÃ¶re Kalp HastalÄ±ÄŸÄ± OranlarÄ± (%)')
        axes[1, 2].set_xlabel('Veri KaynaÄŸÄ±')
        axes[1, 2].set_ylabel('Oran (%)')
        axes[1, 2].legend(['SaÄŸlÄ±klÄ±', 'Hasta'])
        axes[1, 2].tick_params(axis='x', rotation=45)
    else:
        axes[1, 2].set_visible(False)
    
    plt.tight_layout()
    plt.show()

    print("âœ“ GeliÅŸmiÅŸ gÃ¶rselleÅŸtirmeler ve karÅŸÄ±laÅŸtÄ±rmalÄ± analizler oluÅŸturuldu.")

def data_preprocessing(df):
    """
    Makine Ã¶ÄŸrenmesi iÃ§in veri Ã¶n iÅŸleme yapar.
    
    Parameters:
    -----------
    df : pd.DataFrame
        Ä°ÅŸlenecek veri seti
        
    Returns:
    --------
    tuple
        Ä°ÅŸlenmiÅŸ veri seti ve encoder'lar
    """
    print("\n13. VERÄ° Ã–N Ä°ÅLEME")
    print("-" * 40)

    # Kategorik deÄŸiÅŸkenleri sayÄ±sala dÃ¶nÃ¼ÅŸtÃ¼rme
    df_processed = df.copy()

    # Hedef deÄŸiÅŸkeni oluÅŸtur
    if 'heart_disease' not in df_processed.columns and 'num' in df_processed.columns:
        df_processed['heart_disease'] = (df_processed['num'] > 0).astype(int)

    # Label encoding iÃ§in kategorik sÃ¼tunlarÄ± belirle
    categorical_columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']

    label_encoders = {}
    for col in categorical_columns:
        if col in df_processed.columns:
            le = LabelEncoder()
            # Eksik deÄŸerleri Ã¶nce doldur
            df_processed[col] = df_processed[col].fillna('missing')
            df_processed[col] = le.fit_transform(df_processed[col].astype(str))
            label_encoders[col] = le
            print(f"âœ“ {col} sÃ¼tunu sayÄ±sala dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")

    # Eksik deÄŸerleri medyan/mod ile doldur
    for col in df_processed.columns:
        if df_processed[col].isnull().sum() > 0:
            if df_processed[col].dtype in ['int64', 'float64']:
                median_value = df_processed[col].median()
                df_processed[col].fillna(median_value, inplace=True)
                print(f"âœ“ {col} sÃ¼tunundaki eksik deÄŸerler medyan ({median_value}) ile dolduruldu")
            else:
                mode_value = df_processed[col].mode()[0]
                df_processed[col].fillna(mode_value, inplace=True)
                print(f"âœ“ {col} sÃ¼tunundaki eksik deÄŸerler mod ({mode_value}) ile dolduruldu")
    
    print(f"\nâœ“ Veri Ã¶n iÅŸleme tamamlandÄ±. Final boyut: {df_processed.shape}")
    
    return df_processed, label_encoders

def machine_learning_models(df_processed):
    """
    Ã‡eÅŸitli makine Ã¶ÄŸrenmesi modellerini eÄŸitir ve karÅŸÄ±laÅŸtÄ±rÄ±r.
    
    Parameters:
    -----------
    df_processed : pd.DataFrame
        Ã–n iÅŸlemesi yapÄ±lmÄ±ÅŸ veri seti
        
    Returns:
    --------
    tuple
        Model sonuÃ§larÄ±, en iyi model ve Ã¶zellik Ã¶nemliliÄŸi
    """
    print("\n14. MAKÄ°NE Ã–ÄRENMESÄ° MODELLERÄ°")
    print("-" * 40)

    # Ã–zellik ve hedef deÄŸiÅŸkeni ayÄ±rma
    feature_cols = [col for col in df_processed.columns if col not in ['id', 'num', 'heart_disease', 'age_group']]
    X = df_processed[feature_cols]
    y = df_processed['heart_disease']

    print(f"Ã–zellik sayÄ±sÄ±: {X.shape[1]}")
    print(f"KullanÄ±lan Ã¶zellikler: {list(X.columns)}")

    # Veri setini eÄŸitim ve test olarak ayÄ±rma
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    print(f"EÄŸitim seti boyutu: {X_train.shape}")
    print(f"Test seti boyutu: {X_test.shape}")
    print(f"SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± - EÄŸitim: {y_train.value_counts().to_dict()}")
    print(f"SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± - Test: {y_test.value_counts().to_dict()}")

    # Ã–zellik Ã¶lÃ§eklendirme
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Model performanslarÄ±nÄ± saklamak iÃ§in liste
    model_results = []
    model_details = {}

    # 1. Logistic Regression
    print("\n14.1. LOJÄ°STÄ°K REGRESYON")
    print("-" * 25)
    lr_model = LogisticRegression(random_state=42, max_iter=1000)
    lr_model.fit(X_train_scaled, y_train)
    lr_pred = lr_model.predict(X_test_scaled)
    lr_prob = lr_model.predict_proba(X_test_scaled)[:, 1]
    lr_accuracy = accuracy_score(y_test, lr_pred)

    print(f"DoÄŸruluk OranÄ±: {lr_accuracy:.4f}")
    print("\nSÄ±nÄ±flandÄ±rma Raporu:")
    lr_report = classification_report(y_test, lr_pred, output_dict=True)
    print(classification_report(y_test, lr_pred))

    model_results.append(('Logistic Regression', lr_accuracy))
    model_details['Logistic Regression'] = {
        'model': lr_model, 'predictions': lr_pred, 'probabilities': lr_prob,
        'accuracy': lr_accuracy, 'report': lr_report
    }

    # 2. Random Forest
    print("\n14.2. RASTGELE ORMAN (RANDOM FOREST)")
    print("-" * 35)
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_test)
    rf_prob = rf_model.predict_proba(X_test)[:, 1]
    rf_accuracy = accuracy_score(y_test, rf_pred)

    print(f"DoÄŸruluk OranÄ±: {rf_accuracy:.4f}")
    print("\nSÄ±nÄ±flandÄ±rma Raporu:")
    rf_report = classification_report(y_test, rf_pred, output_dict=True)
    print(classification_report(y_test, rf_pred))

    # Ã–zellik Ã¶nemliliÄŸi
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print("\nÃ–zellik Ã–nemliliÄŸi (Random Forest):")
    print(feature_importance.head(10))

    model_results.append(('Random Forest', rf_accuracy))
    model_details['Random Forest'] = {
        'model': rf_model, 'predictions': rf_pred, 'probabilities': rf_prob,
        'accuracy': rf_accuracy, 'report': rf_report, 'feature_importance': feature_importance
    }

    # 3. Support Vector Machine
    print("\n14.3. DESTEK VEKTÃ–R MAKÄ°NESÄ° (SVM)")
    print("-" * 35)
    svm_model = SVC(kernel='rbf', random_state=42, probability=True, C=1.0, gamma='scale')
    svm_model.fit(X_train_scaled, y_train)
    svm_pred = svm_model.predict(X_test_scaled)
    svm_prob = svm_model.predict_proba(X_test_scaled)[:, 1]
    svm_accuracy = accuracy_score(y_test, svm_pred)

    print(f"DoÄŸruluk OranÄ±: {svm_accuracy:.4f}")
    print("\nSÄ±nÄ±flandÄ±rma Raporu:")
    svm_report = classification_report(y_test, svm_pred, output_dict=True)
    print(classification_report(y_test, svm_pred))

    model_results.append(('SVM', svm_accuracy))
    model_details['SVM'] = {
        'model': svm_model, 'predictions': svm_pred, 'probabilities': svm_prob,
        'accuracy': svm_accuracy, 'report': svm_report
    }

    # 4. Gradient Boosting (ek model)
    from sklearn.ensemble import GradientBoostingClassifier
    print("\n14.4. GRADIENT BOOSTING")
    print("-" * 25)
    gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1)
    gb_model.fit(X_train_scaled, y_train)
    gb_pred = gb_model.predict(X_test_scaled)
    gb_prob = gb_model.predict_proba(X_test_scaled)[:, 1]
    gb_accuracy = accuracy_score(y_test, gb_pred)

    print(f"DoÄŸruluk OranÄ±: {gb_accuracy:.4f}")
    print("\nSÄ±nÄ±flandÄ±rma Raporu:")
    gb_report = classification_report(y_test, gb_pred, output_dict=True)
    print(classification_report(y_test, gb_pred))

    model_results.append(('Gradient Boosting', gb_accuracy))
    model_details['Gradient Boosting'] = {
        'model': gb_model, 'predictions': gb_pred, 'probabilities': gb_prob,
        'accuracy': gb_accuracy, 'report': gb_report
    }

    # Model performanslarÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
    print("\n14.5. MODEL PERFORMANS KARÅILAÅTIRMASI")
    print("-" * 35)
    model_df = pd.DataFrame(model_results, columns=['Model', 'DoÄŸruluk OranÄ±'])
    model_df = model_df.sort_values('DoÄŸruluk OranÄ±', ascending=False)
    print(model_df)

    # DetaylÄ± performans metrikleri
    print("\n14.6. DETAYLI PERFORMANS METRÄ°KLERÄ°")
    print("-" * 35)
    
    detailed_metrics = []
    for model_name, details in model_details.items():
        report = details['report']
        detailed_metrics.append({
            'Model': model_name,
            'Accuracy': details['accuracy'],
            'Precision': report['1']['precision'],
            'Recall': report['1']['recall'],
            'F1-Score': report['1']['f1-score'],
            'Macro Avg F1': report['macro avg']['f1-score']
        })
    
    detailed_df = pd.DataFrame(detailed_metrics).round(4)
    print(detailed_df)

    # GÃ¶rselleÅŸtirmeler
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Model performans karÅŸÄ±laÅŸtÄ±rmasÄ±
    model_df.plot(x='Model', y='DoÄŸruluk OranÄ±', kind='bar', ax=axes[0, 0], 
                  color=['skyblue', 'lightgreen', 'lightcoral', 'gold'], legend=False)
    axes[0, 0].set_title('Model DoÄŸruluk OranlarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±')
    axes[0, 0].set_xlabel('Model')
    axes[0, 0].set_ylabel('DoÄŸruluk OranÄ±')
    axes[0, 0].set_ylim(0, 1)
    axes[0, 0].tick_params(axis='x', rotation=45)

    # En iyi modelin karÄ±ÅŸÄ±klÄ±k matrisi
    best_model_name = model_df.iloc[0]['Model']
    best_pred = model_details[best_model_name]['predictions']
    
    cm = confusion_matrix(y_test, best_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],
                xticklabels=['SaÄŸlÄ±klÄ±', 'Hasta'],
                yticklabels=['SaÄŸlÄ±klÄ±', 'Hasta'])
    axes[0, 1].set_title(f'KarÄ±ÅŸÄ±klÄ±k Matrisi - {best_model_name}')
    axes[0, 1].set_xlabel('Tahmin Edilen')
    axes[0, 1].set_ylabel('GerÃ§ek')

    # Ã–zellik Ã¶nemliliÄŸi (Random Forest)
    if 'Random Forest' in model_details:
        top_features = model_details['Random Forest']['feature_importance'].head(10)
        axes[1, 0].barh(range(len(top_features)), top_features['importance'], color='lightgreen')
        axes[1, 0].set_yticks(range(len(top_features)))
        axes[1, 0].set_yticklabels(top_features['feature'])
        axes[1, 0].set_xlabel('Ã–nem Skoru')
        axes[1, 0].set_title('En Ã–nemli 10 Ã–zellik (Random Forest)')
        axes[1, 0].invert_yaxis()

    # ROC EÄŸrileri karÅŸÄ±laÅŸtÄ±rmasÄ±
    from sklearn.metrics import roc_curve, auc
    axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Random Guess')
    
    colors = ['blue', 'red', 'green', 'orange']
    for i, (model_name, details) in enumerate(model_details.items()):
        fpr, tpr, _ = roc_curve(y_test, details['probabilities'])
        roc_auc = auc(fpr, tpr)
        axes[1, 1].plot(fpr, tpr, color=colors[i], label=f'{model_name} (AUC = {roc_auc:.3f})')
    
    axes[1, 1].set_xlabel('False Positive Rate')
    axes[1, 1].set_ylabel('True Positive Rate')
    axes[1, 1].set_title('ROC EÄŸrileri KarÅŸÄ±laÅŸtÄ±rmasÄ±')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("âœ“ Makine Ã¶ÄŸrenmesi modelleri tamamlandÄ±.")
    
    return model_results, model_details, feature_importance

def clustering_analysis(X_train_scaled, y_train):
    """
    KÃ¼meleme analizi yapar ve sonuÃ§larÄ± gÃ¶rselleÅŸtirir.
    
    Parameters:
    -----------
    X_train_scaled : array-like
        Ã–lÃ§eklendirilmiÅŸ eÄŸitim verisi
    y_train : array-like
        EÄŸitim hedef deÄŸiÅŸkeni
        
    Returns:
    --------
    dict
        KÃ¼meleme sonuÃ§larÄ±
    """
    print("\n15. KÃœMELEME ANALÄ°ZÄ° (CLUSTERING)")
    print("-" * 35)

    # K-Means kÃ¼meleme
    print("15.1. K-MEANS KÃœMELEME")
    print("-" * 20)

    # Optimal kÃ¼me sayÄ±sÄ±nÄ± bulma (Elbow Method)
    sse = []
    silhouette_scores = []
    k_range = range(2, 11)  # Silhouette iÃ§in en az 2 kÃ¼me gerekli
    
    from sklearn.metrics import silhouette_score

    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_train_scaled)
        sse.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(X_train_scaled, cluster_labels))

    # Elbow ve Silhouette grafikleri
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Elbow grafiÄŸi
    ax1.plot(k_range, sse, 'bo-')
    ax1.set_title('Elbow Method - Optimal KÃ¼me SayÄ±sÄ±')
    ax1.set_xlabel('KÃ¼me SayÄ±sÄ± (k)')
    ax1.set_ylabel('SSE (Sum of Squared Errors)')
    ax1.grid(True, alpha=0.3)

    # Silhouette skorlarÄ±
    ax2.plot(k_range, silhouette_scores, 'ro-')
    ax2.set_title('Silhouette SkorlarÄ± - Optimal KÃ¼me SayÄ±sÄ±')
    ax2.set_xlabel('KÃ¼me SayÄ±sÄ± (k)')
    ax2.set_ylabel('Silhouette Skoru')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Optimal kÃ¼me sayÄ±sÄ±nÄ± belirle (en yÃ¼ksek silhouette skoru)
    optimal_k = k_range[np.argmax(silhouette_scores)]
    print(f"Optimal kÃ¼me sayÄ±sÄ± (Silhouette): {optimal_k}")
    print(f"En yÃ¼ksek Silhouette skoru: {max(silhouette_scores):.3f}")

    # Final kÃ¼meleme
    kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    cluster_labels = kmeans_final.fit_predict(X_train_scaled)

    print(f"\nKÃ¼me daÄŸÄ±lÄ±mÄ± (k={optimal_k}):")
    unique, counts = np.unique(cluster_labels, return_counts=True)
    for i, count in enumerate(counts):
        print(f"KÃ¼me {i}: {count} kiÅŸi (%{count/len(cluster_labels)*100:.1f})")

    # KÃ¼meleme kalitesi deÄŸerlendirmesi
    from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score
    
    if len(np.unique(y_train)) > 1:  # EÄŸer hedef deÄŸiÅŸkende birden fazla sÄ±nÄ±f varsa
        ari_score = adjusted_rand_score(y_train, cluster_labels)
        nmi_score = normalized_mutual_info_score(y_train, cluster_labels)
        print(f"\nKÃ¼meleme kalitesi:")
        print(f"  - Adjusted Rand Index: {ari_score:.3f}")
        print(f"  - Normalized Mutual Information: {nmi_score:.3f}")

    # KÃ¼me merkezlerini analiz et
    cluster_centers = kmeans_final.cluster_centers_
    print(f"\nKÃ¼me merkezleri analizi:")
    for i, center in enumerate(cluster_centers):
        print(f"KÃ¼me {i} merkezi - Ortalama deÄŸerler:")
        print(f"  Boyut: {len(center)} Ã¶zellik")

    clustering_results = {
        'optimal_k': optimal_k,
        'cluster_labels': cluster_labels,
        'silhouette_score': silhouette_scores[optimal_k-2],  # k_range 2'den baÅŸladÄ±ÄŸÄ± iÃ§in
        'cluster_centers': cluster_centers,
        'sse_scores': sse,
        'silhouette_scores': silhouette_scores
    }

    return clustering_results

def pca_analysis(X_train_scaled, y_train, cluster_labels=None):
    """
    Temel BileÅŸen Analizi (PCA) yapar ve gÃ¶rselleÅŸtirir.
    
    Parameters:
    -----------
    X_train_scaled : array-like
        Ã–lÃ§eklendirilmiÅŸ eÄŸitim verisi
    y_train : array-like
        EÄŸitim hedef deÄŸiÅŸkeni
    cluster_labels : array-like, optional
        KÃ¼me etiketleri
        
    Returns:
    --------
    dict
        PCA sonuÃ§larÄ±
    """
    print("\n16. PCA ANALÄ°ZÄ° (TEMEL BÄ°LEÅEN ANALÄ°ZÄ°)")
    print("-" * 40)

    # PCA uygulama
    pca = PCA()
    X_pca = pca.fit_transform(X_train_scaled)

    # AÃ§Ä±klanan varyans oranlarÄ±
    explained_variance_ratio = pca.explained_variance_ratio_
    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

    # PCA istatistikleri
    print(f"Toplam bileÅŸen sayÄ±sÄ±: {len(explained_variance_ratio)}")
    print(f"Ä°lk bileÅŸenin aÃ§Ä±kladÄ±ÄŸÄ± varyans: %{explained_variance_ratio[0]*100:.1f}")
    print(f"Ä°lk iki bileÅŸenin aÃ§Ä±kladÄ±ÄŸÄ± varyans: %{sum(explained_variance_ratio[:2])*100:.1f}")
    
    # %95 varyansÄ± aÃ§Ä±klamak iÃ§in gereken bileÅŸen sayÄ±sÄ±
    components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1
    print(f"%95 varyansÄ± aÃ§Ä±klamak iÃ§in gereken bileÅŸen sayÄ±sÄ±: {components_95}")
    print(f"%90 varyansÄ± aÃ§Ä±klamak iÃ§in gereken bileÅŸen sayÄ±sÄ±: {np.argmax(cumulative_variance_ratio >= 0.90) + 1}")

    # PCA gÃ¶rselleÅŸtirmesi
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # AÃ§Ä±klanan varyans oranlarÄ±
    axes[0, 0].bar(range(1, min(len(explained_variance_ratio) + 1, 11)), 
                   explained_variance_ratio[:10], alpha=0.7, color='skyblue')
    axes[0, 0].set_title('Ä°lk 10 BileÅŸenin AÃ§Ä±kladÄ±ÄŸÄ± Varyans OranÄ±')
    axes[0, 0].set_xlabel('BileÅŸen')
    axes[0, 0].set_ylabel('AÃ§Ä±klanan Varyans OranÄ±')
    axes[0, 0].grid(True, alpha=0.3)

    # KÃ¼mÃ¼latif aÃ§Ä±klanan varyans
    axes[0, 1].plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, 'bo-')
    axes[0, 1].axhline(y=0.95, color='r', linestyle='--', label='%95 Varyans')
    axes[0, 1].axhline(y=0.90, color='orange', linestyle='--', label='%90 Varyans')
    axes[0, 1].set_title('KÃ¼mÃ¼latif AÃ§Ä±klanan Varyans OranÄ±')
    axes[0, 1].set_xlabel('BileÅŸen SayÄ±sÄ±')
    axes[0, 1].set_ylabel('KÃ¼mÃ¼latif Varyans OranÄ±')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # Ä°lk 2 bileÅŸenle gÃ¶rselleÅŸtirme
    pca_2d = PCA(n_components=2)
    X_pca_2d = pca_2d.fit_transform(X_train_scaled)

    # GerÃ§ek sÄ±nÄ±flar ile PCA
    scatter1 = axes[1, 0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=y_train, 
                                  cmap='coolwarm', alpha=0.7, s=50)
    axes[1, 0].set_title('PCA - GerÃ§ek Kalp HastalÄ±ÄŸÄ± SÄ±nÄ±flarÄ±')
    axes[1, 0].set_xlabel(f'1. BileÅŸen (%{pca_2d.explained_variance_ratio_[0]*100:.1f} varyans)')
    axes[1, 0].set_ylabel(f'2. BileÅŸen (%{pca_2d.explained_variance_ratio_[1]*100:.1f} varyans)')
    axes[1, 0].grid(True, alpha=0.3)
    
    # Colorbar ekle
    cbar1 = plt.colorbar(scatter1, ax=axes[1, 0])
    cbar1.set_ticks([0, 1])
    cbar1.set_ticklabels(['SaÄŸlÄ±klÄ±', 'Hasta'])

    # KÃ¼meleme sonuÃ§larÄ± ile PCA (eÄŸer varsa)
    if cluster_labels is not None:
        scatter2 = axes[1, 1].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=cluster_labels, 
                                      cmap='viridis', alpha=0.7, s=50)
        axes[1, 1].set_title('PCA - K-Means KÃ¼meleme SonuÃ§larÄ±')
        axes[1, 1].set_xlabel(f'1. BileÅŸen (%{pca_2d.explained_variance_ratio_[0]*100:.1f} varyans)')
        axes[1, 1].set_ylabel(f'2. BileÅŸen (%{pca_2d.explained_variance_ratio_[1]*100:.1f} varyans)')
        axes[1, 1].grid(True, alpha=0.3)
        plt.colorbar(scatter2, ax=axes[1, 1])
    else:
        axes[1, 1].set_visible(False)

    plt.tight_layout()
    plt.show()

    # BileÅŸen yÃ¼kleri analizi (Component loadings)
    print(f"\nÄ°lk 2 bileÅŸenin Ã¶zellik yÃ¼kleri:")
    if hasattr(pca_2d, 'components_'):
        components_df = pd.DataFrame(
            pca_2d.components_.T,
            columns=['PC1', 'PC2'],
            index=[f'Feature_{i}' for i in range(pca_2d.components_.shape[1])]
        )
        
        # En yÃ¼ksek yÃ¼klere sahip Ã¶zellikler
        pc1_top = components_df['PC1'].abs().nlargest(5)
        pc2_top = components_df['PC2'].abs().nlargest(5)
        
        print("PC1 iÃ§in en Ã¶nemli Ã¶zellikler:")
        for feature, loading in pc1_top.items():
            sign = '+' if components_df.loc[feature, 'PC1'] > 0 else '-'
            print(f"  {feature}: {sign}{loading:.3f}")
            
        print("\nPC2 iÃ§in en Ã¶nemli Ã¶zellikler:")
        for feature, loading in pc2_top.items():
            sign = '+' if components_df.loc[feature, 'PC2'] > 0 else '-'
            print(f"  {feature}: {sign}{loading:.3f}")

    pca_results = {
        'explained_variance_ratio': explained_variance_ratio,
        'cumulative_variance_ratio': cumulative_variance_ratio,
        'components_95': components_95,
        'pca_2d_data': X_pca_2d,
        'pca_model': pca,
        'pca_2d_model': pca_2d
    }

    return pca_results

