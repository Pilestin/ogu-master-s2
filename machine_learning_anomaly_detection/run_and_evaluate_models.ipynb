{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Wz06Wu9uNbNh","83dec760","b5e40000"],"gpuType":"T4","authorship_tag":"ABX9TyML4KY+C3aFgmvOOhvrXd+i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Modellerin Performans Değerlendirilmesi\n","\n","Bu notebook öncekine kıyasla sadece kaydedilmiş verisetini drive üzerinden okuyarak alır ve modelleri kullanarak test eder.\n","\n","Bu çalışmada kullanılan modeller şunlardır:\n","\n","1. AutoEncoder\n","2. Padim\n","3. SimpleNet\n","\n","Ek olarak şunlar de denenmeye çalışılacak:\n","\n","=> CRT\n","\n","=>\n"],"metadata":{"id":"wRXmUfODQL88"}},{"cell_type":"code","source":["# Çalıştığın ortama göre\n","ENVIRONMENT = \"colab\" # \"local\""],"metadata":{"id":"AEdzq5DEWjrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"x3ZGbLs9QGVt","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"error","timestamp":1766663614784,"user_tz":-180,"elapsed":39,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"}},"outputId":"95de75d8-f74c-4167-9c1b-2d0470c52116"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ENVIRONMENT' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3779622847.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mENVIRONMENT\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"colab\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mDRIVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Makale-Döküman-Makale Çalışmaları/YL Dersler/Makine Öğrenimi ve Anomali Tespiti/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mPROJECT_ROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Kod\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ENVIRONMENT' is not defined"]}],"source":["if ENVIRONMENT == \"colab\":\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    DRIVE_PATH = \"/content/drive/MyDrive/Makale-Döküman-Makale Çalışmaları/YL Dersler/Makine Öğrenimi ve Anomali Tespiti/\"\n","    PROJECT_ROOT = os.path.join(DRIVE_PATH, \"Kod\")\n","    DATASET_ROOT = os.path.join(DRIVE_PATH, \"dataset\")\n","else:\n","    PROJECT_ROOT = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"..\")\n","    DATASET_ROOT = os.path.join(PROJECT_ROOT, \"dataset\")\n","\n","# Orijinal olan veriler\n","ORIGINAL_DATA = os.path.join(DATASET_ROOT, \"wood\")\n"]},{"cell_type":"code","source":["SELECTED_DATASET = os.path.join(DATASET_ROOT, \"wood_otsu_clahe\")\n","TRAIN_GOOD_PATH = os.path.join(ORIGINAL_DATA, \"train\", \"good\")\n","TEST_GOOD_PATH = os.path.join(ORIGINAL_DATA, \"test\", \"good\")\n","TEST_DEFECT_PATH = os.path.join(ORIGINAL_DATA, \"test\", \"defect\")\n","\n","print(f\"Orijinal Dataset Path: {ORIGINAL_DATA}\")\n","print(f\"Kullanılacak Dataset Path: {SELECTED_DATASET}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZYuMRX2B_ja","executionInfo":{"status":"ok","timestamp":1766608997739,"user_tz":-180,"elapsed":36,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"}},"outputId":"b8640d1a-b40f-43d5-a178-279f5e4d576a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Orijinal Dataset Path: /content/drive/MyDrive/Makale-Döküman-Makale Çalışmaları/YL Dersler/Makine Öğrenimi ve Anomali Tespiti/Kod/dataset/wood\n","Kullanılacak Dataset Path: /content/drive/MyDrive/Makale-Döküman-Makale Çalışmaları/YL Dersler/Makine Öğrenimi ve Anomali Tespiti/Kod/dataset/wood_otsu_clahe\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","import shutil\n","from skimage import exposure\n","import json\n","\n","# Deep Learning Kütüphaneleri\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, roc_curve, auc\n","\n","# tqdm'un pandas ile entegrasyonu için\n","tqdm.pandas()"],"metadata":{"id":"fJNvMS3cB9ZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PGShfM0tHGwx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Util func."],"metadata":{"id":"Wz06Wu9uNbNh"}},{"cell_type":"code","source":["\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import (\n","    roc_auc_score, f1_score, precision_score, recall_score,\n","    accuracy_score, confusion_matrix, roc_curve\n",")\n","import json\n","import pandas as pd\n","\n","\n","def load_image(image_path, target_size=(256, 256)):\n","    \"\"\"\n","    Görüntü dosyasını yükler ve RGB formatına çevirir\n","\n","    Args:\n","        image_path: Görüntü dosyasının yolu\n","        target_size: Hedef boyut (width, height)\n","\n","    Returns:\n","        RGB formatında numpy array veya None\n","    \"\"\"\n","    try:\n","        image = cv2.imread(str(image_path))\n","        if image is None:\n","            return None\n","\n","        # BGR to RGB\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        return image\n","    except Exception as e:\n","        print(f\"Görüntü yüklenirken hata: {image_path} - {e}\")\n","        return None\n","\n","\n","def normalize_image(image):\n","    \"\"\"\n","    Görüntüyü 0-1 aralığına normalize eder\n","\n","    Args:\n","        image: Numpy array (0-255)\n","\n","    Returns:\n","        Normalize edilmiş görüntü (0-1)\n","    \"\"\"\n","    return image.astype(np.float32) / 255.0\n","\n","\n","def preprocess_for_anomaly_detection(image, target_size=(256, 256)):\n","    \"\"\"\n","    Anomali tespiti için görüntü ön işleme\n","\n","    Args:\n","        image: RGB görüntü\n","        target_size: Hedef boyut\n","\n","    Returns:\n","        Normalize edilmiş ve resize edilmiş görüntü\n","    \"\"\"\n","    # Resize\n","    if image.shape[:2] != target_size:\n","        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n","\n","    # Normalize (0-1)\n","    image = normalize_image(image)\n","\n","    return image\n","\n","\n","def create_anomaly_map(original, reconstructed):\n","    \"\"\"\n","    Orijinal ve yeniden oluşturulmuş görüntüler arasındaki farkı hesaplar\n","\n","    Args:\n","        original: Orijinal görüntü\n","        reconstructed: Yeniden oluşturulmuş görüntü\n","\n","    Returns:\n","        Anomali haritası\n","    \"\"\"\n","    # MSE hesapla (her piksel için)\n","    diff = np.mean(np.square(original - reconstructed), axis=-1)\n","\n","    # Normalize et\n","    diff = (diff - diff.min()) / (diff.max() - diff.min() + 1e-8)\n","\n","    return diff\n","\n","\n","def calculate_metrics(y_true, y_scores, threshold=0.5):\n","    \"\"\"\n","    Sınıflandırma metriklerini hesaplar\n","\n","    Args:\n","        y_true: Gerçek etiketler (0: normal, 1: anomaly)\n","        y_scores: Anomali skorları (0-1 arası)\n","        threshold: Karar eşiği\n","\n","    Returns:\n","        Metrik sözlüğü\n","    \"\"\"\n","    # Binary predictions\n","    y_pred = (y_scores >= threshold).astype(int)\n","\n","    # Metrikler\n","    results = {\n","        'auc_score': roc_auc_score(y_true, y_scores),\n","        'f1_score': f1_score(y_true, y_pred),\n","        'precision': precision_score(y_true, y_pred, zero_division=0),\n","        'recall': recall_score(y_true, y_pred, zero_division=0),\n","        'accuracy': accuracy_score(y_true, y_pred),\n","        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),\n","        'threshold': threshold,\n","        'y_scores': y_scores.tolist() if isinstance(y_scores, np.ndarray) else y_scores,\n","        'y_true': y_true.tolist() if isinstance(y_true, np.ndarray) else y_true\n","    }\n","\n","    return results\n","\n","\n","def plot_metrics(results, model_name=\"Model\"):\n","    \"\"\"\n","    Metrik sonuçlarını görselleştirir\n","\n","    Args:\n","        results: calculate_metrics fonksiyonundan dönen sözlük\n","        model_name: Model adı\n","    \"\"\"\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n","\n","    # Confusion Matrix\n","    cm = np.array(results['confusion_matrix'])\n","    axes[0].imshow(cm, cmap='Blues', interpolation='nearest')\n","    axes[0].set_title(f'{model_name} - Confusion Matrix')\n","    axes[0].set_xlabel('Predicted')\n","    axes[0].set_ylabel('Actual')\n","\n","    # Değerleri yazdır\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            axes[0].text(j, i, str(cm[i, j]),\n","                        ha='center', va='center', color='red')\n","\n","    # ROC Curve\n","    y_true = np.array(results['y_true'])\n","    y_scores = np.array(results['y_scores'])\n","    fpr, tpr, _ = roc_curve(y_true, y_scores)\n","\n","    axes[1].plot(fpr, tpr, label=f'AUC = {results[\"auc_score\"]:.4f}')\n","    axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n","    axes[1].set_xlabel('False Positive Rate')\n","    axes[1].set_ylabel('True Positive Rate')\n","    axes[1].set_title(f'{model_name} - ROC Curve')\n","    axes[1].legend()\n","    axes[1].grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Metrikleri yazdır\n","    print(f\"\\n=== {model_name} PERFORMANS METRİKLERİ ===\")\n","    print(f\"AUC Score:    {results['auc_score']:.4f}\")\n","    print(f\"F1 Score:     {results['f1_score']:.4f}\")\n","    print(f\"Precision:    {results['precision']:.4f}\")\n","    print(f\"Recall:       {results['recall']:.4f}\")\n","    print(f\"Accuracy:     {results['accuracy']:.4f}\")\n","    print(f\"Threshold:    {results['threshold']:.4f}\")\n","    print(\"=\"*45)\n","\n","\n","def visualize_anomaly_detection(images, labels, scores, anomaly_maps,\n","                                model_name=\"Model\", num_samples=6):\n","    \"\"\"\n","    Anomali tespit sonuçlarını görselleştirir\n","\n","    Args:\n","        images: Test görüntüleri\n","        labels: Gerçek etiketler\n","        scores: Anomali skorları\n","        anomaly_maps: Anomali haritaları\n","        model_name: Model adı\n","        num_samples: Gösterilecek örnek sayısı\n","    \"\"\"\n","    # Her sınıftan eşit sayıda örnek seç\n","    normal_indices = np.where(labels == 0)[0]\n","    anomaly_indices = np.where(labels == 1)[0]\n","\n","    n_per_class = num_samples // 2\n","\n","    selected_indices = []\n","    if len(normal_indices) > 0:\n","        selected_indices.extend(np.random.choice(normal_indices,\n","                                                min(n_per_class, len(normal_indices)),\n","                                                replace=False))\n","    if len(anomaly_indices) > 0:\n","        selected_indices.extend(np.random.choice(anomaly_indices,\n","                                                 min(n_per_class, len(anomaly_indices)),\n","                                                 replace=False))\n","\n","    n_samples = len(selected_indices)\n","    fig, axes = plt.subplots(n_samples, 2, figsize=(8, 3*n_samples))\n","\n","    if n_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    for idx, img_idx in enumerate(selected_indices):\n","        # Orijinal görüntü\n","        axes[idx, 0].imshow(images[img_idx])\n","        label_text = \"Normal\" if labels[img_idx] == 0 else \"Anomaly\"\n","        axes[idx, 0].set_title(f'{label_text} | Score: {scores[img_idx]:.3f}')\n","        axes[idx, 0].axis('off')\n","\n","        # Anomaly map\n","        axes[idx, 1].imshow(anomaly_maps[img_idx], cmap='jet')\n","        axes[idx, 1].set_title('Anomaly Map')\n","        axes[idx, 1].axis('off')\n","\n","    plt.suptitle(f'{model_name} - Anomaly Detection Results', fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def save_model_results(model_name, results, output_dir=\"results\"):\n","    \"\"\"\n","    Model sonuçlarını dosyaya kaydeder\n","\n","    Args:\n","        model_name: Model adı\n","        results: Metrik sonuçları\n","        output_dir: Çıktı dizini\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # JSON olarak kaydet\n","    output_file = os.path.join(output_dir, f\"{model_name}_results.json\")\n","\n","    # Numpy array'leri liste'ye çevir\n","    results_copy = results.copy()\n","\n","    with open(output_file, 'w') as f:\n","        json.dump(results_copy, f, indent=4)\n","\n","    print(f\"\\n✅ Sonuçlar kaydedildi: {output_file}\")\n","\n","\n","def compare_models(results_list, model_names):\n","    \"\"\"\n","    Birden fazla modelin performansını karşılaştırır\n","\n","    Args:\n","        results_list: Model sonuçları listesi\n","        model_names: Model isimleri listesi\n","    \"\"\"\n","    metrics_to_compare = ['auc_score', 'f1_score', 'precision', 'recall', 'accuracy']\n","\n","    # DataFrame oluştur\n","    comparison_data = []\n","    for model_name, results in zip(model_names, results_list):\n","        row = {'Model': model_name}\n","        for metric in metrics_to_compare:\n","            row[metric] = results.get(metric, 0)\n","        comparison_data.append(row)\n","\n","    df = pd.DataFrame(comparison_data)\n","\n","    # Görselleştirme\n","    fig, axes = plt.subplots(1, len(metrics_to_compare), figsize=(18, 4))\n","\n","    for idx, metric in enumerate(metrics_to_compare):\n","        axes[idx].bar(df['Model'], df[metric])\n","        axes[idx].set_title(metric.replace('_', ' ').title())\n","        axes[idx].set_ylim(0, 1)\n","        axes[idx].grid(True, alpha=0.3)\n","        axes[idx].tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Tablo yazdır\n","    print(\"\\n=== MODEL KARŞILAŞTIRMA TABLOSU ===\")\n","    print(df.to_string(index=False))\n","    print(\"=\"*60)\n","\n","    return df\n","\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def visualize_reconstructions(\n","    model,\n","    dataset,\n","    device,\n","    num_samples=5,\n","    is_anomaly=False,\n","    title_prefix=\"\"\n","):\n","    \"\"\"\n","    AutoEncoder reconstruction görselleştirme\n","    - Train için: is_anomaly=False\n","    - Test için anomaly görmek istiyorsan: is_anomaly=True\n","    \"\"\"\n","\n","    model.eval()\n","\n","    # Dataset içinden index seç\n","    indices = []\n","\n","    if hasattr(dataset, \"labels\") and dataset.labels is not None:\n","        # Test dataset\n","        labels = np.array(dataset.labels)\n","        target_label = 1 if is_anomaly else 0\n","        indices = np.where(labels == target_label)[0]\n","    else:\n","        # Train dataset (sadece good vardır)\n","        indices = np.arange(len(dataset))\n","\n","    if len(indices) == 0:\n","        print(\"Seçilen sınıfa ait örnek yok.\")\n","        return\n","\n","    selected_indices = np.random.choice(\n","        indices,\n","        size=min(num_samples, len(indices)),\n","        replace=False\n","    )\n","\n","    fig, axes = plt.subplots(\n","        len(selected_indices),\n","        3,\n","        figsize=(12, 4 * len(selected_indices))\n","    )\n","\n","    if len(selected_indices) == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    with torch.no_grad():\n","        for i, idx in enumerate(selected_indices):\n","\n","            sample = dataset[idx]\n","\n","            if isinstance(sample, tuple):\n","                image = sample[0]\n","            else:\n","                image = sample\n","\n","            image = image.unsqueeze(0).to(device)\n","\n","            # Reconstruction\n","            recon = model(image)\n","\n","            # Error map (MAE)\n","            error_map = torch.mean(\n","                torch.abs(recon - image),\n","                dim=1\n","            )\n","\n","            # Tensor → numpy\n","            original_np = image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n","            recon_np = recon.squeeze(0).permute(1, 2, 0).cpu().numpy()\n","            error_np = error_map.squeeze(0).cpu().numpy()\n","\n","            # 0–1 aralığında göster\n","            original_np = np.clip(original_np, 0, 1)\n","            recon_np = np.clip(recon_np, 0, 1)\n","\n","            # Plot\n","            axes[i, 0].imshow(original_np)\n","            axes[i, 0].set_title(f\"Original {title_prefix}\")\n","            axes[i, 0].axis(\"off\")\n","\n","            axes[i, 1].imshow(recon_np)\n","            axes[i, 1].set_title(\"Reconstructed\")\n","            axes[i, 1].axis(\"off\")\n","\n","            axes[i, 2].imshow(error_np, cmap=\"hot\")\n","            axes[i, 2].set_title(f\"Error Map (mean={error_np.mean():.4f})\")\n","            axes[i, 2].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"7RxjD8dYHaXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def load_dataset(data_dir, target_size=(256, 256)):\n","    \"\"\"Dataset'i yükle ve hazırla\"\"\"\n","    train_good_dir = os.path.join(data_dir, \"train\", \"good\")\n","    test_good_dir = os.path.join(data_dir, \"test\", \"good\")\n","    test_defect_dir = os.path.join(data_dir, \"test\", \"defect\")\n","\n","    # Training verisi (sadece good örnekler)\n","    train_images = []\n","    train_files = [f for f in os.listdir(train_good_dir) if f.endswith('.bmp')]\n","\n","    print(f\"Training verisi yükleniyor: {len(train_files)} dosya...\")\n","    for filename in train_files:\n","        img_path = os.path.join(train_good_dir, filename)\n","        img = load_image(img_path, target_size)\n","        if img is not None:\n","            img = preprocess_for_anomaly_detection(img, target_size)\n","            train_images.append(img)\n","\n","    # Test verisi (good + defect)\n","    test_images = []\n","    test_labels = []\n","\n","    # Good örnekler\n","    test_good_files = [f for f in os.listdir(test_good_dir) if f.endswith('.bmp')]\n","    print(f\"Test good verisi yükleniyor: {len(test_good_files)} dosya...\")\n","    for filename in test_good_files:\n","        img_path = os.path.join(test_good_dir, filename)\n","        img = load_image(img_path, target_size)\n","        if img is not None:\n","            img = preprocess_for_anomaly_detection(img, target_size)\n","            test_images.append(img)\n","            test_labels.append(0)  # 0 = normal\n","\n","    # Defect örnekler\n","    test_defect_files = [f for f in os.listdir(test_defect_dir) if f.endswith('.bmp')]\n","    print(f\"Test defect verisi yükleniyor: {len(test_defect_files)} dosya...\")\n","    for filename in test_defect_files:\n","        img_path = os.path.join(test_defect_dir, filename)\n","        img = load_image(img_path, target_size)\n","        if img is not None:\n","            img = preprocess_for_anomaly_detection(img, target_size)\n","            test_images.append(img)\n","            test_labels.append(1)  # 1 = anomaly\n","\n","    return np.array(train_images), np.array(test_images), np.array(test_labels)\n"],"metadata":{"id":"SXKFjRMdHDCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Autoencoder modelini ve loader fonksiyonunu içe aktar\n","print('Modül yüklendi: model1_autoencoder')\n","\n","# Dataseti yükle (modelin sağladığı loader ile)\n","target_size = (256, 256)\n","train_images, test_images, test_labels = load_dataset(SELECTED_DATASET, target_size)\n","\n","print('\\nDataset Bilgileri:')\n","print('Training set:', train_images.shape)\n","print('Test set    :', test_images.shape)\n","print('Test labels :', test_labels.shape)\n","print('Normal samples:', int(np.sum(test_labels == 0)))\n","print('Anomaly samples:', int(np.sum(test_labels == 1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTDWJxInG80i","executionInfo":{"status":"ok","timestamp":1766609841394,"user_tz":-180,"elapsed":1709,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"}},"outputId":"dc66955c-d218-4ae3-804c-ae292353a368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Modül yüklendi: model1_autoencoder\n","Training verisi yükleniyor: 90 dosya...\n","Test good verisi yükleniyor: 10 dosya...\n","Test defect verisi yükleniyor: 36 dosya...\n","\n","Dataset Bilgileri:\n","Training set: (90, 256, 256, 3)\n","Test set    : (46, 256, 256, 3)\n","Test labels : (46,)\n","Normal samples: 10\n","Anomaly samples: 36\n"]}]},{"cell_type":"code","source":["class WoodDataset(Dataset):\n","    def __init__(self, images, labels=None):\n","        self.images = images\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = torch.tensor(\n","            self.images[idx], dtype=torch.float32\n","        ).permute(2, 0, 1)\n","\n","        if self.labels is None:\n","            return img          # train\n","        else:\n","            return img, self.labels[idx]  # test\n"],"metadata":{"id":"8B1-2ggrIyQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = WoodDataset(train_images)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","test_dataset = WoodDataset(test_images, test_labels)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","\n"],"metadata":{"id":"k3r3K1XmI0qR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83dec760"},"source":["## Implement AutoEncoder Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1766609910017,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"17160e7e","outputId":"25c7b69e-8430-4ef8-8749-2dd3f16ce9e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["AutoEncoder model defined.\n"]}],"source":["import torch.nn as nn\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self, in_channels=3, latent_dim=128):\n","        super(AutoEncoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(in_channels, 32, kernel_size=4, stride=2, padding=1), # Output: 32x128x128\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1), # Output: 64x64x64\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # Output: 128x32x32\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(128),\n","            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # Output: 256x16x16\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(256, latent_dim, kernel_size=4, stride=2, padding=1), # Output: latent_dim x 8 x 8\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(latent_dim)\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(latent_dim, 256, kernel_size=4, stride=2, padding=1), # Output: 256x16x16\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # Output: 128x32x32\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(128),\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # Output: 64x64x64\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(64),\n","            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # Output: 32x128x128\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(32),\n","            nn.ConvTranspose2d(32, in_channels, kernel_size=4, stride=2, padding=1), # Output: in_channelsx256x256\n","            nn.Sigmoid() # Output pixels in [0, 1] range for image reconstruction\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n","\n","print(\"AutoEncoder model defined.\")"]},{"cell_type":"markdown","metadata":{"id":"0f4453cc"},"source":["## SimpleNet Modelini Uygula\n","\n","Anomali tespiti için SimpleNet mimarisini PyTorch'ta tanımlayın. Bu modelin, sınıflandırma veya özellik çıkarımı için uygun katmanları içermesi gerekmektedir.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1766611527966,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"788e6c41","outputId":"17c41726-6a37-4f19-dbb0-212413ffa920"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleNet model architecture defined.\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleNet(nn.Module):\n","    def __init__(self, in_channels=3, latent_dim=256):\n","        super(SimpleNet, self).__init__()\n","        self.backbone = backbone\n","        self.head = nn.Linear(latent_dim, 1)  # binary\n","\n","        # Convolutional layers\n","        self.features = nn.Sequential(\n","            # Block 1\n","            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1), # 32x256x256\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2), # 32x128x128\n","\n","            # Block 2\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 64x128x128\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2), # 64x64x64\n","\n","            # Block 3\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 128x64x64\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2), # 128x32x32\n","\n","            # Block 4\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 256x32x32\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)  # 256x16x16\n","        )\n","\n","        # Calculate the size of the flattened features\n","        # For an input of 256x256, after 4 MaxPool2d(k=2,s=2) layers, the spatial size becomes 256 / (2^4) = 256 / 16 = 16\n","        # And the last conv layer outputs 256 channels\n","        self.flat_features_size = 256 * 16 * 16 # 256 channels * 16x16 spatial dimensions\n","\n","        # Fully connected layer for feature extraction\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.flat_features_size, latent_dim),\n","            nn.ReLU(inplace=True) # Output a feature vector\n","            # If it were for classification, a final nn.Linear(latent_dim, num_classes) would follow, possibly with a softmax/sigmoid\n","        )\n","\n","    def forward(self, x):\n","        feats = self.backbone(x)          # [B, latent_dim]\n","        logits = self.head(feats).squeeze(1)  # [B]\n","        return logits\n","\n","print(\"SimpleNet model architecture defined.\")"]},{"cell_type":"markdown","source":["----"],"metadata":{"id":"SCkHXIvUIVqx"}},{"cell_type":"markdown","metadata":{"id":"b5e40000"},"source":["## Train AutoEncoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5832,"status":"ok","timestamp":1766610011094,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"a629dcc7","outputId":"9832b907-7f17-458a-a52c-7146cffc7e49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","AutoEncoder model instantiated and moved to device.\n","Loss function (MSE) and optimizer (Adam) defined.\n","Starting AutoEncoder training...\n","Epoch [1/20], Loss: 0.0636\n","Epoch [2/20], Loss: 0.0467\n","Epoch [3/20], Loss: 0.0443\n","Epoch [4/20], Loss: 0.0421\n","Epoch [5/20], Loss: 0.0396\n","Epoch [6/20], Loss: 0.0374\n","Epoch [7/20], Loss: 0.0354\n","Epoch [8/20], Loss: 0.0333\n","Epoch [9/20], Loss: 0.0309\n","Epoch [10/20], Loss: 0.0279\n","Epoch [11/20], Loss: 0.0268\n","Epoch [12/20], Loss: 0.0248\n","Epoch [13/20], Loss: 0.0246\n","Epoch [14/20], Loss: 0.0239\n","Epoch [15/20], Loss: 0.0220\n","Epoch [16/20], Loss: 0.0221\n","Epoch [17/20], Loss: 0.0210\n","Epoch [18/20], Loss: 0.0215\n","Epoch [19/20], Loss: 0.0210\n","Epoch [20/20], Loss: 0.0204\n","AutoEncoder training complete.\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Instantiate the AutoEncoder model\n","# Assuming input images are RGB (3 channels) and TARGET_IMAGE_SIZE is used for output\n","model = AutoEncoder(in_channels=3, latent_dim=128).to(device)\n","print(\"AutoEncoder model instantiated and moved to device.\")\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","print(\"Loss function (MSE) and optimizer (Adam) defined.\")\n","\n","NUM_EPOCHS = 20\n","\n","# Training loop\n","print(\"Starting AutoEncoder training...\")\n","model.train() # Set the model to training mode\n","\n","for epoch in range(NUM_EPOCHS):\n","    running_loss = 0.0\n","    num_samples = 0\n","\n","    for images in train_loader:   # ← SADECE images\n","        images = images.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, images)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        num_samples += images.size(0)\n","\n","    epoch_loss = running_loss / num_samples\n","    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {epoch_loss:.4f}\")\n","\n","\n","print(\"AutoEncoder training complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1766610029910,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"b400371d","outputId":"7f4e2e34-ceeb-41c6-fb80-cff70dfe4be7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rekonstrüksiyon hataları ve gerçek etiketler toplandı.\n","Toplam rekons. hatası sayısı: 46\n","Toplam gerçek etiket sayısı: 46\n"]}],"source":["\n","# 1. Modeli değerlendirme moduna alın\n","model.eval()\n","\n","# Rekonstrüksiyon hatalarını ve gerçek etiketleri depolamak için listeler\n","reconstruction_errors = []\n","true_labels = []\n","\n","# 2. Test veri setindeki tüm görüntüleri modelden geçirin\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        # Skip if the batch is empty\n","        if images is None or labels is None:\n","            continue\n","\n","        images = images.to(device)\n","\n","        # Forward pass (reconstruction)\n","        outputs = model(images)\n","\n","        # Rekonstrüksiyon hatasını hesapla (MSE)\n","        # Her bir resim için hata hesaplamak adına reduction='none' kullan\n","        batch_errors = torch.mean((outputs - images)**2, dim=[1,2,3])\n","        reconstruction_errors.extend(batch_errors.cpu().numpy())\n","        true_labels.extend(labels.cpu().numpy())\n","\n","print(\"Rekonstrüksiyon hataları ve gerçek etiketler toplandı.\")\n","\n","# Sonuçları NumPy dizilerine dönüştür\n","reconstruction_errors = np.array(reconstruction_errors)\n","true_labels = np.array(true_labels)\n","\n","print(f\"Toplam rekons. hatası sayısı: {len(reconstruction_errors)}\")\n","print(f\"Toplam gerçek etiket sayısı: {len(true_labels)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1766610316404,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"3b8f7be5","outputId":"a5b7a1e2-10eb-4c58-f687-3a1b109e57a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["(reconstruction_errors) kullanıldı (yüksek skor = anomali)\n","AUC (chosen): 0.6583\n","Optimal Anomaly Threshold (based on ROC / Youden J): 0.015774\n","Predicted labels count (0=normal, 1=anomaly): [ 5 41]\n","True labels count (0=normal, 1=anomaly): [10 36]\n"]}],"source":["\n","\n","# numpy'a çevir ve 1D yap\n","y_true = np.asarray(true_labels).astype(int).ravel()\n","scores = np.asarray(reconstruction_errors).astype(float).ravel()\n","\n","# Güvenlik: iki sınıf var mı?\n","uniq = np.unique(y_true)\n","if uniq.size != 2:\n","    raise ValueError(f\"ROC için y_true iki sınıf içermeli (0 ve 1). Şu an: {uniq}\")\n","\n","# Skor yönü kontrolü: \"yüksek skor = anomali\" mi, yoksa tersi mi?\n","# İki yön için AUC hesapla ve daha iyi olanı seç\n","fpr1, tpr1, thr1 = roc_curve(y_true, scores)          # yüksek = pozitif (anomaly)\n","auc1 = auc(fpr1, tpr1)\n","\n","fpr2, tpr2, thr2 = roc_curve(y_true, -scores)         # düşük = pozitif (anomaly) durumunu yakalar\n","auc2 = auc(fpr2, tpr2)\n","\n","if auc2 > auc1:\n","    used_scores = -scores\n","    fpr, tpr, thresholds = fpr2, tpr2, thr2\n","    direction = \"(-reconstruction_errors) kullanıldı (düşük skor = anomali varsayımı daha iyi çıktı)\"\n","else:\n","    used_scores = scores\n","    fpr, tpr, thresholds = fpr1, tpr1, thr1\n","    direction = \"(reconstruction_errors) kullanıldı (yüksek skor = anomali)\"\n","\n","# Youden's J: tpr - fpr maksimum\n","optimal_idx = int(np.argmax(tpr - fpr))\n","anomaly_threshold = float(thresholds[optimal_idx])\n","\n","print(direction)\n","print(f\"AUC (chosen): {max(auc1, auc2):.4f}\")\n","print(f\"Optimal Anomaly Threshold (based on ROC / Youden J): {anomaly_threshold:.6f}\")\n","\n","# Eşik ile sınıflandırma (pozitif=1)\n","predicted_labels = (used_scores >= anomaly_threshold).astype(int)\n","\n","# Sayım (0 ve 1 her zaman görünsün)\n","pred_counts = np.bincount(predicted_labels, minlength=2)\n","true_counts = np.bincount(y_true, minlength=2)\n","\n","print(f\"Predicted labels count (0=normal, 1=anomaly): {pred_counts}\")\n","print(f\"True labels count (0=normal, 1=anomaly): {true_counts}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1766610350152,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"68a8b400","outputId":"2bbf45f1-5259-45b5-f56c-df6b92f80764"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Model Performans Metrikleri ---\n","Accuracy: 0.8913\n","F1-Score: 0.9351\n","Recall: 1.0000\n","\n","Karışıklık Matrisi:\n","[[ 5  5]\n"," [ 0 36]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x500 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAhAAAAHWCAYAAAAmWbC9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVqdJREFUeJzt3Xlcjen/P/DXad8TSrJUQkh2g4xlkIjsO0PMYOxbmGZsg7GMfRk0w2BobCPLxzKWZCQzdmFslbIkky2VUqrr94df5+s4p5w7J/fJvJ6Px3lwX/d9X/f7LPfpfa77uq5bIYQQICIiIpLAQO4AiIiIqOhhAkFERESSMYEgIiIiyZhAEBERkWRMIIiIiEgyJhBEREQkGRMIIiIikowJBBEREUnGBIKIiIgkYwJBHz0XFxf4+/vLHcZHZcaMGVAoFCplRfV1jouLg0KhwIYNG+QO5YM6fvw4FAoFfv/993y327BhAxQKBeLi4t67rqIk9zkdP35c0n5F9TwoCCYQemzVqlVQKBRo0KDBe9d14MABzJgx473qcHFxgUKh0Pho06bNe8f4McnOzoaTkxMUCgUOHjwodzh6wd/fP8/Pz5sPffjylXq+NG/eHNWrV1crDw0NhYWFBerUqYOnT5/qMMKPR24Cp1AoMHv2bI3b9O3bFwqFAlZWVgU6xm+//YalS5e+R5SkiZHcAVDegoOD4eLigjNnziA6OhoVK1YscF0HDhzAjz/++N5JRK1atTBhwgS1cicnp/eq92Nz7NgxJCQkwMXFBcHBwWjbtq3cIRW6mzdvwsAg798kQ4cORatWrZTLsbGxmDZtGoYMGYImTZooy93c3Ao1zrc5OzsjPT0dxsbGyjJdnC/Hjh2Dn58f3N3dcfToURQvXlwH0X68zMzMsGXLFkyZMkWl/MWLF9izZw/MzMwKXPdvv/2Gq1evYuzYsVrv07RpU6Snp8PExETSsd51HnxMmEDoqdjYWJw6dQohISEYOnQogoODMX36dLnDQpkyZdCvXz+5w5BNVlYWcnJy3vmlsnnzZtSpUwcDBgzAN998gxcvXsDS0vIDRSkPU1PTfNc3atQIjRo1Ui6fO3cO06ZNQ6NGjWT9TCkUivf646TJn3/+CT8/P1SuXFlnyYO2n72iytfXFyEhIYiMjETNmjWV5Xv27EFmZibatGmDY8eOFXocL1++hImJCQwMDAr0uXjXefAx+W+kSUVQcHAw7Ozs0K5dO3Tr1g3BwcFq2+R1je7ta7r+/v748ccfAUClqTjXixcvMGHCBJQrVw6mpqZwd3fHwoULUdAbtfr7+8PKygrx8fHo1KkTrKysYG9vj4CAAGRnZ6tsm5OTg2XLlsHT0xNmZmawt7dHmzZtcO7cOeU2WVlZmDVrFtzc3GBqagoXFxd88803yMjIUKlLCIHZs2ejbNmysLCwwGeffYZ//vlHY4xJSUkYO3as8jlXrFgR8+fPR05OjtrruHDhQixdulR5/GvXruX7/NPT07Fr1y706tULPXr0QHp6Ovbs2fNer5O275FCocDIkSOxY8cOVKtWDebm5mjUqBGuXLkCAAgKCkLFihVhZmaG5s2bq13XDg8PR/fu3VG+fHmYmpqiXLlyGDduHNLT0/N9zoDurv2ePn0abdq0ga2tLSwsLNCsWTNERESobJOSkoKxY8fCxcUFpqamcHBwgLe3Ny5cuKDcJveywvnz5+Hl5QVzc3O4urpizZo1KnVJPV/eJTw8HO3atUPFihVx9OhRlChRQrkuMzMT06ZNQ926dWFrawtLS0s0adIEYWFhGmPS9NnT1Gfj4cOHGDhwIMqWLQtTU1OULl0aHTt2VHl/mzdvjubNm+cbe0ZGBtq3bw9bW1ucOnUqz+10WVeuRo0awdXVFb/99ptKeXBwMNq0aaMxCduzZw/atWsHJycnmJqaws3NDbNmzVI5f5o3b479+/fjzp07yvfSxcUFwP99h27duhVTpkxBmTJlYGFhgeTkZI3fr1FRUejatSscHR1hZmaGsmXLolevXnj+/Llym/9SHwi2QOip4OBgdOnSBSYmJujduzdWr16Ns2fPon79+pLrGjp0KB48eIAjR45g06ZNKuuEEOjQoQPCwsLwxRdfoFatWjh06BAmTpyI+Ph4LFmyRGX7V69e4fHjx2rHsLS0hLm5uXI5OzsbPj4+aNCgARYuXIijR49i0aJFcHNzw7Bhw5TbffHFF9iwYQPatm2LL7/8EllZWQgPD8fff/+NevXqAQC+/PJLbNy4Ed26dcOECRNw+vRpzJ07F9evX8euXbuUdU2bNg2zZ8+Gr68vfH19ceHCBbRu3RqZmZkqsaalpaFZs2aIj4/H0KFDUb58eZw6dQqBgYFISEhQu1a6fv16vHz5EkOGDIGpqek7f03u3bsXqamp6NWrFxwdHdG8eXMEBwejT58+attq8zpJfY/Cw8Oxd+9ejBgxAgAwd+5ctG/fHpMmTcKqVaswfPhwPHv2DD/88AMGDRqk8qtux44dSEtLw7Bhw1CiRAmcOXMGK1aswP3797Fjx458n7cuHDt2DG3btkXdunUxffp0GBgYYP369WjRogXCw8PxySefAAC++uor/P777xg5ciSqVauGJ0+e4OTJk7h+/Trq1KmjrO/Zs2fw9fVFjx490Lt3b2zfvh3Dhg2DiYkJBg0apDGG/M6Xd4mIiICvry9cXV0RGhqKkiVLqqxPTk7G2rVr0bt3bwwePBgpKSlYt24dfHx8cObMGdSqVUtle02fvTeT3Fxdu3bFP//8g1GjRsHFxQWJiYk4cuQI7t69q/xj+S7p6eno2LEjzp07h6NHjxbou+Z96+rduzc2b96MefPmQaFQ4PHjxzh8+DA2bdqEP/74Q237DRs2wMrKCuPHj4eVlRWOHTuGadOmITk5GQsWLAAAfPvtt3j+/Dnu37+vPFfe7ksxa9YsmJiYICAgABkZGRpbeTIzM+Hj44OMjAyMGjUKjo6OiI+Px759+5CUlARbW1upL1PRJ0jvnDt3TgAQR44cEUIIkZOTI8qWLSvGjBmjsl1YWJgAIMLCwlTKY2NjBQCxfv16ZdmIESOEprd79+7dAoCYPXu2Snm3bt2EQqEQ0dHRyjJnZ2cBQONj7ty5yu0GDBggAIiZM2eq1Fm7dm1Rt25d5fKxY8cEADF69Gi1uHJycoQQQly6dEkAEF9++aXK+oCAAAFAHDt2TAghRGJiojAxMRHt2rVT7iuEEN98840AIAYMGKAsmzVrlrC0tBS3bt1SqfPrr78WhoaG4u7duyqvo42NjUhMTFSLMS/t27cXjRs3Vi7/9NNPwsjISK0ObV8nKe8RAGFqaipiY2OVZUFBQQKAcHR0FMnJycrywMBAAUBl27S0NLXnM3fuXKFQKMSdO3eUZdOnT1f7PDk7O6u8zu9y9uxZlc9pTk6OqFSpkvDx8VF5D9PS0oSrq6vw9vZWltna2ooRI0bkW3+zZs0EALFo0SJlWUZGhqhVq5ZwcHAQmZmZQghp50t+xypevLiwtrYWHh4eeX5esrKyREZGhkrZs2fPRKlSpcSgQYOUZfl99t6O99mzZwKAWLBgwTtjbNasmXI59/tjx44dIiUlRTRr1kyULFlSXLx4UWW/9evXq31OClqXJrnPZ8GCBeLq1asCgAgPDxdCCPHjjz8KKysr8eLFCzFgwABhaWmpsq+mz+vQoUOFhYWFePnypbKsXbt2wtnZWW3b3LgrVKigVtfb368XL15UPsf8SD0PijJewtBDwcHBKFWqFD777DMAr5tRe/bsia1bt6o1bb+vAwcOwNDQEKNHj1YpnzBhAoQQaiMIGjRogCNHjqg9evfurVb3V199pbLcpEkT3L59W7m8c+dOKBQKjX07cpuMDxw4AAAYP368WnwAsH//fgDA0aNHkZmZiVGjRqk0N2vqNLVjxw40adIEdnZ2ePz4sfLRqlUrZGdn48SJEyrbd+3aFfb29mr1aPLkyRMcOnRI5fXo2rUrFAoFtm/frnGfd71OUt+jli1bqvzqzB3F07VrV1hbW6uVv3msN1uRXrx4gcePH8PLywtCCFy8eDHf5/6+Ll26hKioKPTp0wdPnjxRvi8vXrxAy5YtceLECeWv72LFiuH06dN48OBBvnUaGRlh6NChymUTExMMHToUiYmJOH/+vE7jf/HiBVJSUlCqVCnY2Nho3MbQ0FD56zYnJwdPnz5FVlYW6tWrp3L5JZc2nz1zc3OYmJjg+PHjePbsmeS4nz9/jtatW+PGjRs4fvy4WivIh6zLw8MDNWrUwJYtWwC87vzYsWNHWFhYaNz+zc9rSkoKHj9+jCZNmiAtLQ03btzQ+rgDBgxQqUuT3BaGQ4cOIS0tTeu6P2ZMIPRMdnY2tm7dis8++wyxsbGIjo5GdHQ0GjRogH///RehoaE6Pd6dO3fg5OSk8ocFAKpWrapc/6aSJUuiVatWag9nZ2eV7XL7M7zJzs5O5QsuJiYGTk5O+V4SuHPnDgwMDNRGoDg6OqJYsWLK+HL/rVSpksp29vb2sLOzUymLiorCH3/8AXt7e5VH7giBxMREle1dXV3zjO9t27Ztw6tXr1C7dm3le/f06VM0aNBAYz8WbV4nqe9R+fLlVZZzv/jKlSunsfzNY929exf+/v4oXry4sk9Gs2bNAEDlOm9hiIqKAvD6y/zt92bt2rXIyMhQxvDDDz/g6tWrKFeuHD755BPMmDFDJRHK5eTkpNZ5tXLlygCQ77wGBZHbj+bYsWPo3bt3nsn+xo0bUaNGDZiZmaFEiRKwt7fH/v37Nb6+2nz2TE1NMX/+fBw8eBClSpVC06ZN8cMPP+Dhw4daxT127FicPXsWR48ehYeHh1b7FGZdffr0wY4dOxAdHY1Tp05pvPSX659//kHnzp1ha2sLGxsb2NvbKzvkSvm8avM6u7q6Yvz48Vi7di1KliwJHx8f/Pjjj4V+Xugz9oHQM7nD/7Zu3YqtW7eqrQ8ODkbr1q0BIM+OXbpupSgIQ0NDndYnpRPbu+Tk5MDb2xuTJk3SuD73D0yud/0yeVNuktC4cWON62/fvo0KFSool3X9OuVXZ17l4v93xMzOzoa3tzeePn2KyZMno0qVKrC0tER8fDz8/f01XnvXpdz6FyxYkOcv19xr1z169ECTJk2wa9cuHD58GAsWLMD8+fMREhIi65DZSZMm4cmTJ/jhhx8wePBgrFu3TuWzu3nzZvj7+6NTp06YOHEiHBwcYGhoiLlz5yImJkatPm0/e2PHjoWfnx92796NQ4cOYerUqZg7dy6OHTuG2rVr57tvx44dsXXrVsybNw+//vrrew1B1EVdvXv3RmBgIAYPHowSJUoov+/elpSUhGbNmsHGxgYzZ86Em5sbzMzMcOHCBUyePFnS51Xb13nRokXw9/fHnj17cPjwYYwePRpz587F33//jbJly2p9vI8FEwg9ExwcDAcHB2Uv8DeFhIRg165dWLNmDczNzZW/rJOSklS2e/sXKZD3H2BnZ2ccPXoUKSkpKr9wc5v/3m5Z0CU3NzccOnQIT58+zbMVwtnZGTk5OYiKilL+4gaAf//9F0lJScr4cv+NiopS+QP96NEjtWZdNzc3pKamqsxJoAu5Q29Hjhyp/NWeKycnB59//jl+++03tXHu7/Kh3qMrV67g1q1b2LhxI/r3768sP3LkiE7qf5fc+R9sbGy0em9Kly6N4cOHY/jw4UhMTESdOnXw/fffqyQQDx48UBtCe+vWLQDIt3Ph+ySs8+fPx9OnT7F27VrY2dlh0aJFynW///47KlSogJCQEJVj6GKItpubGyZMmIAJEyYgKioKtWrVwqJFi7B58+Z89+vUqRNat24Nf39/WFtbY/Xq1QWOQRd1lS9fHo0bN8bx48cxbNgwGBlp/jN1/PhxPHnyBCEhIWjatKmyPDY2Vm1bXf4A8fT0hKenJ6ZMmYJTp06hcePGWLNmTZ6TYH3MeAlDj6SnpyMkJATt27dHt27d1B4jR45ESkoK9u7dC+D1Hw5DQ0O1a/arVq1Sqzv3C/TtZMPX1xfZ2dlYuXKlSvmSJUugUCgK9ddc165dIYTAd999p7Yu91exr68vAKiNjFi8eDEAoF27dgCAVq1awdjYGCtWrFAZ2qhp9rkePXrgr7/+wqFDh9TWJSUlISsrq0DPJ7f1YdKkSWrvXY8ePdCsWTONlzHe5UO9R7ktFG++fkIILFu2TCf1v0vdunXh5uaGhQsXIjU1VW39o0ePALxuKXm72djBwQFOTk5qQ3uzsrIQFBSkXM7MzERQUBDs7e1Rt27dPGPJ63zRVlBQELp164bFixer/GHR9BqfPn0af/31V4GOA7weVfTy5UuVMjc3N1hbW6u9Hnnp378/li9fjjVr1mDy5MkFjkVXdc2ePRvTp0/HqFGj8txG02uZmZmZ5/ff+15qSE5OVvtu8PT0hIGBgdav88eGLRB6ZO/evUhJSUGHDh00rm/YsCHs7e0RHByMnj17wtbWFt27d8eKFSugUCjg5uaGffv2qV3DB6D8shw9ejR8fHxgaGiIXr16wc/PD5999hm+/fZbxMXFoWbNmjh8+DD27NmDsWPHqs0KGB8fr/EXjZWVFTp16iTp+X722Wf4/PPPsXz5ckRFRaFNmzbIyclBeHg4PvvsM4wcORI1a9bEgAED8NNPPymbLM+cOYONGzeiU6dOyo6mufMn5A5Z9PX1xcWLF3Hw4EG1oXQTJ07E3r170b59e/j7+6Nu3bp48eIFrly5gt9//x1xcXFq+2gjODgYtWrVUutrkKtDhw4YNWoULly4oDLU8F2kvkcFVaVKFbi5uSEgIADx8fGwsbHBzp07C9QxryAMDAywdu1atG3bFh4eHhg4cCDKlCmD+Ph4hIWFwcbGBv/73/+QkpKCsmXLolu3bqhZsyasrKxw9OhRnD17VuXXPvC6D8T8+fMRFxeHypUrY9u2bbh06RJ++uknlZkn35bX+SLluQQHB+P58+eYOnUqihcvjuHDh6N9+/YICQlB586d0a5dO8TGxmLNmjWoVq2axqRJG7du3ULLli3Ro0cPVKtWDUZGRti1axf+/fdfSTGPHDkSycnJ+Pbbb2Fra4tvvvmmQPHooq5mzZqpteK9zcvLC3Z2dhgwYABGjx4NhUKBTZs2aZy/pm7duti2bRvGjx+P+vXrw8rKCn5+fpJiOnbsGEaOHInu3bujcuXKyMrKwqZNm2BoaIiuXbtKquujIc/gD9LEz89PmJmZiRcvXuS5jb+/vzA2NhaPHz8WQgjx6NEj0bVrV2FhYSHs7OzE0KFDlUOh3hyWlpWVJUaNGiXs7e2FQqFQGaKWkpIixo0bJ5ycnISxsbGoVKmSWLBggcpQOiHyH8b55hApTcOthNA89C8rK0ssWLBAVKlSRZiYmAh7e3vRtm1bcf78eeU2r169Et99951wdXUVxsbGoly5ciIwMFBlmJYQQmRnZ4vvvvtOlC5dWpibm4vmzZuLq1evahxWlZKSIgIDA0XFihWFiYmJKFmypPDy8hILFy5UG973ruFxQghx/vx5AUBMnTo1z23i4uIEADFu3DjJr5O27xEAteGNeT2PN4fe5bp27Zpo1aqVsLKyEiVLlhSDBw8WkZGRap+nwhjGmevixYuiS5cuokSJEsLU1FQ4OzuLHj16iNDQUCHE66GYEydOFDVr1hTW1tbC0tJS1KxZU6xatUqlnmbNmgkPDw9x7tw50ahRI2FmZiacnZ3FypUrNb4+2p4vmuQe622pqamiYcOGwsDAQAQHB4ucnBwxZ84c4ezsLExNTUXt2rXFvn37xIABA1TOofw+e2/H+/jxYzFixAhRpUoVYWlpKQCIOnXqiO3bt6vFmNfQyzdNmjRJAFC+TlKHceZXlybanmeazpeIiAjRsGFDYW5uLpycnMSkSZPEoUOH1Ia3p6amij59+ohixYqpfF/lFfeb63LruX37thg0aJBwc3MTZmZmonjx4uKzzz4TR48eVdnvvzSMUyFEAacbJCLSY82bN8fjx49x9epVuUP5oIYOHYratWurDQ8m0jX2gSAi+oi0b9++QH1tiKRiHwgioo/AwYMHce/ePezfvx8vXryQOxz6D2ACQUT0EYiPj8e4ceNgbW2tcRg4ka6xDwQRERFJxj4QREREJBkTCCIiIpKMCQQRERFJ9lF2ooxJTJc7BCIioiLJzUG7m4uxBYKIiIgkYwJBREREkjGBICIiIsmYQBAREZFkTCCIiIhIMiYQREREJBkTCCIiIpKMCQQRERFJxgSCiIiIJGMCQURERJIxgSAiIiLJmEAQERGRZEwgiIiISDImEERERCQZEwgiIiKSjAkEERERScYEgoiIiCRjAkFERESSMYEgIiIiyZhAEBERkWRMIIiIiEgyJhBEREQkGRMIIiIikowJBBEREUnGBIKIiIgkYwJBREREkjGBICIiIsmYQBAREZFkTCCIiIhIMiYQREREJBkTCCIiIpKMCQQRERFJxgSCiIiIJGMCQURERJIxgSAiIiLJmEAQERGRZEwgiIiISDImEERERCQZEwgiIiKSjAkEERERSWYkdwAZGRk4ffo07ty5g7S0NNjb26N27dpwdXWVOzQiIiLKg2wJREREBJYtW4b//e9/ePXqFWxtbWFubo6nT58iIyMDFSpUwJAhQ/DVV1/B2tparjCJiIhIA1kuYXTo0AE9e/aEi4sLDh8+jJSUFDx58gT3799HWloaoqKiMGXKFISGhqJy5co4cuSIHGESERFRHhRCCPGhDxoUFIRBgwbB2Nj4ndteu3YNCQkJaNmypdb1xySmv094RERE/1luDuZabSdLAqEtIQQUCoXk/ZhAEBERFYy2CYTsozAWLFigsTw7Oxt9+vT5wNEQERGRNvQigVi3bp1KWXZ2Nnr16oVLly7JExQRERHlS/ZhnPv370fr1q1ha2uLbt26ISsrCz169MCNGzcQFhYmd3hERESkgewJRP369bFz50506tQJJiYmWLduHaKjoxEWFoZSpUrJHR4RERFpoDedKHfv3o3u3bujatWqOHbsGEqWLFngutiJkoiIqGC07UQpSwtEly5dNJbb29ujWLFiGDJkiLIsJCTkQ4VFREREWpIlgbC1tdVY7uPj84EjISIiooLQm0sYusRLGERERAVTZOaBAICsrCwcPXoUQUFBSElJAQA8ePAAqampMkdGREREmsg+CuPOnTto06YN7t69i4yMDHh7e8Pa2hrz589HRkYG1qxZI3eIRERE9BbZWyDGjBmDevXq4dmzZzA3/79mk86dOyM0NFTGyIiIiCgvsrdAhIeH49SpUzAxMVEpd3FxQXx8vExRERERUX5kb4HIyclBdna2Wvn9+/dhbW0tQ0RERET0LrInEK1bt8bSpUuVywqFAqmpqZg+fTp8fX3lC4yIiIjyJPswzvv378PHxwdCCERFRaFevXqIiopCyZIlceLECTg4OEiuk8M4iYiICkbbYZyyJxDA62Gc27ZtQ2RkJFJTU1GnTh307dtXpVOlFEwgiIiICqZIJRC6xgSCiIioYIrMRFJz587FL7/8olb+yy+/YP78+TJERERERO8iewIRFBSEKlWqqJV7eHhg1apVWL9+PTp37ozNmzfLEB0RERFpInsC8fDhQ5QuXVqt3N7eHvfu3UNiYiIaNWqEUaNGyRAdERERaSJ7AlGuXDlERESolUdERMDFxQWTJ09Ghw4dYGQk+5xXRERE9P/J/ld58ODBGDt2LF69eoUWLVoAAEJDQzFp0iRMmDABAODm5oaYmBg5wyQiIqI3yJ5ATJw4EU+ePMHw4cORmZkJADAzM8PkyZMRGBgIADA2NoaxsbGcYRIREdEbZB3GmZ2djYiICHh6esLY2BjXr1+Hubk5KlWqBFNT0wLXy2GcREREBVNk5oEwMzPD9evX4erqqrM6mUAQEREVTJGZB6J69eq4ffu23GEQERGRBLInELNnz0ZAQAD27duHhIQEJCcnqzyIiIhI/8h+CcPA4P9yGIVCofy/EAIKhULjrb7fhZcwiIiICkbbSxiyj8IICwuTOwQiIiKSSPYWiMLAFggiIqKCKTKdKAEgPDwc/fr1g5eXF+Lj4wEAmzZtwsmTJ2WOjIiIiDSRPYHYuXMnfHx8YG5ujgsXLiAjIwMA8Pz5c8yZM0fm6IiIiEgT2ROI2bNnY82aNfj5559VZpts3LgxLly4IGNkRERElBfZE4ibN2+iadOmauW2trZISkr68AERERHRO8meQDg6OiI6Olqt/OTJk6hQoYIMEREREdG7yJ5ADB48GGPGjMHp06ehUCjw4MEDBAcHIyAgAMOGDZM7PCIiItJA9nkgvv76a+Tk5KBly5ZIS0tD06ZNYWpqioCAAIwaNUru8IiIiEgDvZkHIjMzE9HR0UhNTUW1atVgZWVV4Lo4DwQREVHBFJm7cRYGJhBEREQFo/dTWSckJGDlypX4/vvvAQCffvop0tLSlOsNDQ2xe/dulClTRq4QiYiIKA+ydaJctWoVnj17plyOjIxEkyZN0LFjR3Ts2BGGhoZYsmSJXOERERFRPmS7hFG7dm0sX74cTZo0AQBYW1sjMjJSOXTz0KFDGD9+PP755x/JdfMSBhERUcHo/b0w4uLi4Orqqlz29vaGpaWlctnd3R2xsbFyhEZERETvIFsC8erVKzx69Ei5HBISglKlSimXnz17BgMD2aepICIiIg1k+wvt7u6OU6dO5bk+PDwclStX/oARERERkbZkG4XRq1cvTJs2DU2aNEGNGjVU1kVGRmLmzJmYPHmyTNGR3Db/shq/rQ9SKStb3gU/Be+WJyAiUsFzlGRLIMaOHYt9+/ahbt268Pb2hru7O4DXN9c6cuQIGjVqhLFjx8oVHukBZ1c3fL/k/76gDA0NZYyGiN7Gc/S/TbYEwtjYGEeOHMHixYuxdetWHD9+HABQqVIlzJo1C+PGjVO5vTf99xgaGqJ4iZJyh0FEeeA5+t/GmShJL23+ZTV2btkIS0trmJiYoEr1GvAfOhoOpUrLHRoRgefox0yvp7IWQkChUOikroyMDGRkZKiU3X+eA1NTU53UT/I4+/dJvExPQ9lyLnj65DF+27AGjx89wupff4eFheW7KyCiQsVz9OOl1/NAeHh4YOvWrcjMzMx3u6ioKAwbNgzz5s3Lc5u5c+fC1tZW5bFm+QJdh0wfWP2Gn6LJZ63hWrEy6jbwwnc/rMSL1BSEHzssd2hEBJ6jJFMfiBUrVmDy5MkYPnw4vL29Ua9ePTg5OcHMzAzPnj3DtWvXcPLkSfzzzz8YOXIkhg0blmddgYGBGD9+vErZ/ec5hf0U6AOzsrZBmXLl8eD+PblDISINeI7+98iSQLRs2RLnzp3DyZMnsW3bNgQHB+POnTtIT09HyZIlUbt2bfTv3x99+/aFnZ1dvnWZmpqqXa4wfck+EB+b9LQ0JMTfRwsfdtgi0kc8R/97ZBuFAby+A+enn34qZwikp9b+uBgNvJrCwbE0njx+hM2/rIaBgSGat2wjd2hEBJ6jJHMCQZSXx4n/Yv53gUhOToJtMTt4eNbGkqBfYWtXXO7QiAg8R4nDOImIiOgNej0Kg4iIiIo2JhBEREQkGRMIIiIikkyWTpTJyclab2tjY1OIkRAREVFByJJAFCtW7J1TWedOd52dnf2BoiIiIiJtyZJAhIWFyXFYIiIi0hEO4yQiIiIlbYdx6s1EUmlpabh7967aDbZq1KghU0RERESUF9kTiEePHmHgwIE4ePCgxvXsA0FERKR/ZB/GOXbsWCQlJeH06dMwNzfHH3/8gY0bN6JSpUrYu3ev3OERERGRBrK3QBw7dgx79uxBvXr1YGBgAGdnZ3h7e8PGxgZz585Fu3bt5A6RiIiI3iJ7C8SLFy/g4OAAALCzs8OjR48AAJ6enrhw4YKcoREREVEeZE8g3N3dcfPmTQBAzZo1ERQUhPj4eKxZswalS5eWOToiIiLSRPZLGGPGjEFCQgIAYPr06WjTpg2Cg4NhYmKCDRs2yBscERERaaR380CkpaXhxo0bKF++PEqWLFmgOjgPBBERUcFoOw+E3iUQusAEgoiIqGCKzERSQgj8/vvvCAsLQ2JiInJyclTWh4SEyBQZERER5UX2BGLs2LEICgrCZ599hlKlSr3zJltEREQkP9kvYRQvXhybN2+Gr6+vzurkJQwiIqKC0fYShuzDOG1tbVGhQgW5wyAiIiIJZE8gZsyYge+++w7p6Ww1ICIiKipkv4SRnp6Ozp07IyIiAi4uLjA2NlZZX5DZKHkJg4iIqGCKzCiMAQMG4Pz58+jXrx87URIRERURsrdAWFpa4tChQ/j00091VidbIIiIiAqmyHSiLFeuHGxsbOQOg4iIiCSQPYFYtGgRJk2ahLi4OLlDISIiIi3JfgnDzs4OaWlpyMrKgoWFhVonyqdPn0quk5cwiIiICqbIdKJcunSp3CEQERGRRLImEK9evcKff/6JqVOnwtXVVc5QiIiISAJZ+0AYGxtj586dcoZAREREBSB7J8pOnTph9+7dcodBREREEsjeB6JSpUqYOXMmIiIiULduXVhaWqqsHz16tEyRERERUV5kH4WRX98HhUKB27dvS66TozCIiIgKpsiMwoiNjZU7BCIiIpJI9j4QbxJCQOYGESIiItKCpAQiOzsbJ06cQFJSkk6D+PXXX+Hp6Qlzc3OYm5ujRo0a2LRpk06PQURERLoj6RKGoaEhWrdujevXr6NYsWI6CWDx4sWYOnUqRo4cicaNGwMATp48ia+++gqPHz/GuHHjdHIcIiIi0h3JfSCqV6+O27dv62zipxUrVmD16tXo37+/sqxDhw7w8PDAjBkzmEAQERHpIcl9IGbPno2AgADs27cPCQkJSE5OVnlIlZCQAC8vL7VyLy8vJCQkSK6PiIiICp/kFghfX18Ar1sJFAqFslwIAYVCgezsbEn1VaxYEdu3b8c333yjUr5t2zZUqlRJanhERET0AUhOIMLCwnQawHfffYeePXvixIkTyj4QERERCA0Nxfbt23V6LCIiItIN2SeSAoDz589jyZIluH79OgCgatWqmDBhAmrXrl2g+jiRFBERUcFoO5FUgRKI8PBwBAUF4fbt29ixYwfKlCmDTZs2wdXVFZ9++qnkYHWNCQQREVHBaJtASO5EuXPnTvj4+MDc3BwXLlxARkYGAOD58+eYM2eO1OqIiIioCCrQKIw1a9bg559/hrGxsbK8cePGuHDhgvYHNjCAoaFhvg8jI9ln2iYiIiINJP+FvnnzJpo2bapWbmtrK2mGyl27duW57q+//sLy5cuRk5MjNTwiIiL6ACQnEI6OjoiOjoaLi4tK+cmTJ1GhQgWt6+nYsaNa2c2bN/H111/jf//7H/r27YuZM2dKDY+IiIg+AMmXMAYPHowxY8bg9OnTUCgUePDgAYKDgxEQEIBhw4YVKIgHDx5g8ODB8PT0RFZWFi5duoSNGzfC2dm5QPURERFR4ZLcAvH1118jJycHLVu2RFpaGpo2bQpTU1MEBARg1KhRkurK7Xi5YsUK1KpVC6GhoWjSpInUkIiIiOgDK/A8EJmZmYiOjkZqaiqqVasGKysrSfv/8MMPmD9/PhwdHTFnzhyNlzQKisM4iYiICqZQ54HQBQMDA5ibm6NVq1YwNDTMc7uQkBDJdTOBICIiKhhtEwitLmF06dJF6wNr+we/f//+KvfSICIioqJDqwTC1tZW5wfesGGDzuskIiKiD0Mv7oWha7yEQUREVDCFNpV1ixYtNE4YlZycjBYtWkitjoiIiIogyQnE8ePHkZmZqVb+8uVLhIeH6yQoIiIi0m9azwNx+fJl5f+vXbuGhw8fKpezs7Pxxx9/oEyZMrqNjoiIiPSS1glErVq1oFAooFAoNF6qMDc3x4oVK3QaHBEREeknrROI2NhYCCFQoUIFnDlzBvb29sp1JiYmcHBwyHc+ByIiIvp4aJ1A5N6XgnfIJCIiIsmdKAFg06ZNaNy4MZycnHDnzh0AwJIlS7Bnzx6dBkdERET6SXICsXr1aowfPx6+vr5ISkpCdnY2AMDOzg5Lly7VdXxERESkhyQnECtWrMDPP/+Mb7/9VqXPQ7169XDlyhWdBkdERET6SXICERsbi9q1a6uVm5qa4sWLFzoJioiIiPSb5ATC1dUVly5dUiv/448/ULVqVV3ERERERHpO61EYucaPH48RI0bg5cuXEELgzJkz2LJlC+bOnYu1a9cWRoxERESkZwp0M63g4GDMmDEDMTExAAAnJyd89913+OKLL3QeYEHwZlpEREQFo+3NtCQnEMnJybCxsQEApKWlITU1FQ4ODgCA6OhoVKxYUWKouscEgoiIqGAK7W6c7dq1Q0ZGBgDAwsJCmTzcvHkTzZs3l1odERERFUGSEwgrKyt07twZWVlZyrLr16+jefPm6Nq1q06DIyIiIv0kOYEICQnB8+fP0bdvXwghcPXqVTRv3hy9e/fGsmXLCiNGIiIi0jMF6kSZlJSE5s2bo1KlSjhx4gT69++PBQsWFEZ8BcI+EERERAWj006UycnJamUJCQnw9vZG+/btMW/ePGV5bgdLOTGBICIiKhidJhAGBgZQKBRq5bm7KhQKCCGgUCiU98aQExMIIiKigtE2gdBqIqmwsLD3CoaIiIg+LgXqA6Hv2AJBRERUMDptgbh8+TKqV68OAwMDXL58Od9ta9SoodWBiYiIqOjSug/Ew4cP4eDgoOwPoWk39oEgIiIq2nTaAhEbGwt7e3vl/4mIiOi/TasEwtnZWfn/O3fuwMvLC0ZGqrtmZWXh1KlTKtsSERHRx0lyJ0pDQ0MkJCQo74GR68mTJ3BwcOAlDCIioiKs0G6mlTvfw9uePHkCS0tLqdURERFREaTVJQwA6NKlC4DXHSX9/f1hamqqXJednY3Lly/Dy8tL9xESERGR3tE6gbC1tQXwugXC2toa5ub/18RhYmKChg0bYvDgwbqPkIiIiPSO1gnE+vXrAQAuLi4ICAjg5QoiIqL/MK07USYmJqp1nHxTVlYWLly4gE8++URnwRUUO1ESEREVjM47UZYuXRqJiYnKZU9PT9y7d0+5/OTJEzRq1EhCiERERFRUaZ1AvN1QERcXh1evXuW7DREREX2cJA/jzI+m4Z1ERET08dFpAkFERET/DVqPwlAoFEhJSYGZmZlyMqnU1FQkJycDgPJffVCmuHYdQIhIHnb1R8odAhHlIf3iSq220zqBEEKgcuXKKsu1a9dWWeYlDCIiov8GrROIsLCwwoyDiIiIihCtE4hmzZoVZhxERERUhLATJREREUnGBIKIiIgkYwJBREREkjGBICIiIskkJxD5jcb48ccf3ysYIiIiKhokJxBdunTB+fPn1cqXLVuGwMBAnQRFRERE+k1yArFgwQK0bdsWN27cUJYtWrQI06ZNw/79+3UaHBEREeknreeByPXll1/i6dOnaNWqFU6ePIlt27Zhzpw5OHDgABo3blwYMRIREZGekZxAAMCkSZPw5MkT1KtXD9nZ2Th06BAaNmyo69iIiIhIT2mVQCxfvlytrEyZMrCwsEDTpk1x5swZnDlzBgAwevRo3UZIREREekchhBDv2sjV1VW7yhQK3L59+72Del8vs+SOgIjyw7txEukvnd6NMzY29r2CISIioo9LgSeSyszMxM2bN5GVxZ/7RERE/zWSE4i0tDR88cUXsLCwgIeHB+7evQsAGDVqFObNm6fzAImIiEj/SE4gAgMDERkZiePHj8PMzExZ3qpVK2zbtk2nwREREZF+kjyMc/fu3di2bRsaNmwIhUKhLPfw8EBMTIxOgyMiIiL9JLkF4tGjR3BwcFArf/HihUpCQURERB8vyQlEvXr1VKaszk0a1q5di0aNGukuMiIiItJbki9hzJkzB23btsW1a9eQlZWFZcuW4dq1azh16hT+/PPPwoiRiIiI9IzkFohPP/0Uly5dQlZWFjw9PXH48GE4ODjgr7/+Qt26dQsjRiIiItIzWs1EWdRwJkoi/caZKIn0l7YzUUpugThw4AAOHTqkVn7o0CEcPHhQanVERERUBElOIL7++mtkZ2erlQsh8PXXX+PWrVtYtmwZrly5opMAiYiISP9ITiCioqJQrVo1tfIqVargypUrCAgIwIkTJ+Dn56eTAImIiEj/SB6FYWtri9u3b8PFxUWlPDo6GsWLF8fevXsRGxuL6tWr6ypGIiIi0jOSWyA6duyIsWPHqsw6GR0djQkTJqBTp04AACsrK+zZs0dnQRIREZF+kTwK4/nz52jTpg3OnTuHsmXLAgDu37+PJk2aICQkBMWKFSuMOCXhKAwi/cZRGET6S9tRGAW6hHHq1CkcOXIEkZGRMDc3R40aNdC0aVPJQRIREVHRJCmBePXqFczNzXHp0iW0bt0arVu3Lqy4iIiISI9J6gNhbGyM8uXLaxzGSURERP8dki9hfPvtt/jmm2+wadMmFC9e/L0DyMjIwOnTp3Hnzh2kpaXB3t4etWvXhqur63vXTURERIVDcgKxcuVKREdHw8nJCc7OzrC0tFRZf+HCBa3qiYiIwLJly/C///0Pr169gq2tLczNzfH06VNkZGSgQoUKGDJkCL766itYW1tLDZOIiIgKkeQEIneo5vvo0KEDLly4gD59+uDw4cOoV68ezM3Nletv376N8PBwbNmyBYsXL8avv/4Kb2/v9z4uERER6YYsN9MKCgrCoEGDYGxs/M5tr127hoSEBLRs2VLr+jmMk0i/cRgnkf7SdhhngRKIpKQk/P7774iJicHEiRNRvHhxXLhwAaVKlUKZMmUkB5sXIQQUCoXk/ZhAEOk3JhBE+qvQ7sZ5+fJlVK5cGfPnz8fChQuRlJQEAAgJCUFgYKDU6rBgwQKN5dnZ2ejTp4/k+oiIiKjwSU4gxo8fD39/f0RFRcHMzExZ7uvrixMnTkgOYMGCBVi3bp1KWXZ2Nnr16oVLly5Jro+IiIgKn+ROlGfPnkVQUJBaeZkyZfDw4UPJAezfvx+tW7eGra0tunXrhqysLPTo0QM3btxAWFiY5PqIiIio8ElOIExNTZGcnKxWfuvWLdjb20sOoH79+ti5cyc6deoEExMTrFu3DtHR0QgLC0OpUqUk10dERESFT/IljA4dOmDmzJl49eoVAEChUODu3buYPHkyunbtWqAgWrRogV9//RVdu3ZFbGws/vzzTyYPREREeqxAd+Ps1q0bzp07h5SUFDg5OeHhw4do1KgRDhw4oDaxlCZdunTRWP7333+jYsWKKFmypLIsJCRESngAOAqDSN9xFAaR/irUu3EeOXIEJ0+exOXLl5Gamoo6deqgVatWkurQxMfHR2o4REREJANZJpIqbGyBINJvbIEg0l86b4FIT09HaGgo2rdvDwAIDAxERkaGcr2hoSFmzZqlMrRTW1lZWTh+/DhiYmLQp08fWFtb48GDB7CxsYGVlZXk+oiIiKhwaZ1AbNy4Efv371cmECtXroSHh4fyHhY3btyAk5MTxo0bJymAO3fuoE2bNrh79y4yMjLg7e0Na2trzJ8/HxkZGVizZo2k+oiIiKjwaT0KIzg4GEOGDFEp++233xAWFoawsDAsWLAA27dvlxzAmDFjUK9ePTx79kzlhlqdO3dGaGio5PqIiIio8GndAhEdHQ1PT0/lspmZGQwM/i//+OSTTzBixAjJAYSHh+PUqVMwMTFRKXdxcUF8fLzk+oiIiKjwaZ1AJCUlqfR5ePTokcr6nJwclfXaysnJQXZ2tlr5/fv3YW1tLbk+IiIiKnxaX8IoW7Ysrl69muf6y5cvo2zZspIDaN26NZYuXapcVigUSE1NxfTp0+Hr6yu5PiIiIip8WicQvr6+mDZtGl6+fKm2Lj09Hd999x3atWsnOYBFixYhIiIC1apVw8uXL9GnTx/l5Yv58+dLro+IiIgKn9bzQPz777+oVasWTExMMHLkSFSuXBkAcPPmTaxcuRJZWVm4ePFigaagzsrKwrZt2xAZGamcmKpv374qnSql4DwQRPqN80AQ6S9t54GQNJFUbGwshg0bhiNHjiB3N4VCAW9vb6xatQoVKlQoWLQ6xgSCSL8xgSDSX4UylbWrqyv++OMPPH36FNHR0QCAihUronjx4tIj/P/mzp2LUqVKYdCgQSrlv/zyCx49eoTJkycXuG4iIiIqHJLvhQEAxYsXxyeffKKTAIKCgvDbb7+plXt4eKBHjx5wcHDA3r170bVrV/Tr108nxyQiIqL3I/l23rr28OFDlC5dWq3c3t4e9+7dQ2JiIho1aoRRo0bJEB0RERFpInsCUa5cOURERKiVR0REwMXFBZMnT0aHDh1gZFSgxhIiIiIqBLL/VR48eDDGjh2LV69eoUWLFgCA0NBQTJo0CRMmTAAAuLm5ISYmRs4wiYiI6A2yJxATJ07EkydPMHz4cGRmZgJ4PU325MmTERgYCAAwNjaGsbGxnGESERHRGyQN49S17OxsREREwNPTE8bGxrh+/TrMzc1RqVIlmJqaFrheDuMk0m8cxkmkvwplGKeuGRoaonXr1rh+/TpcXV1Rv359OcMhIiIiLcneibJ69eq4ffu23GEQERGRBLInELNnz0ZAQAD27duHhIQEJCcnqzyIiIhI/8jaBwIADAz+L4dRKBTK/wshoFAoNN7q+13YB4JIv7EPBJH+KhJ9IAAgLCxM7hCIiIhIItkTiGbNmskdAhEREUkkex8IAAgPD0e/fv3g5eWF+Ph4AMCmTZtw8uRJmSMjIiIiTWRPIHbu3AkfHx+Ym5vjwoULyMjIAAA8f/4cc+bMkTk6IiIi0kT2BGL27NlYs2YNfv75Z5XZJhs3bowLFy7IGBkRERHlRfYE4ubNm2jatKlaua2tLZKSkj58QERERPROsicQjo6OiI6OVis/efIkKlSoIENERERE9C6yJxCDBw/GmDFjcPr0aSgUCjx48ADBwcEICAjAsGHD5A6PiIiINJB9GOfXX3+NnJwctGzZEmlpaWjatClMTU0REBCAUaNGyR0eERERaSD7TJS5MjMzER0djdTUVFSrVg1WVlYFroszURLpN85ESaS/isxMlLlMTExQrVo1ucMgIiIiLciWQCQkJGDlypX4/vvvAQCffvop0tLSlOsNDQ2xe/dulClTRq4QiYiIKA+ydaJctWoVnj17plyOjIxEkyZN0LFjR3Ts2BGGhoZYsmSJXOERERFRPmRrgdi3bx+WL1+uUjZmzBjl0M2GDRti/PjxWLhwoRzhERERUT5ka4GIi4uDq6urctnb2xuWlpbKZXd3d8TGxsoRGhEREb2DbAnEq1ev8OjRI+VySEgISpUqpVx+9uwZDAxkn6aCiIiINJDtL7S7uztOnTqV5/rw8HBUrlz5A0ZERERE2pItgejVqxemTZuGy5cvq62LjIzEzJkz0bt3bxkiIyIioneRbSKpV69eoVWrVjh16hS8vb3h7u4O4PXNtY4cOYJGjRohNDRU5Q6d2uJEUkT6jRNJEekvbSeSknUmyszMTCxevBhbt27FrVu3AACVKlVC7969MW7cOJiamhaoXiYQRPqNCQSR/ioSCURhYQJBpN+YQBDpL20TCFn6QHyEOQsREdF/iiwJhIeHB7Zu3YrMzMx8t4uKisKwYcMwb968DxQZERERaUOWmShXrFiByZMnY/jw4fD29ka9evXg5OQEMzMzPHv2DNeuXcPJkyfxzz//YOTIkRg2bJgcYRIREVEeZO0DcfLkSWzbtg3h4eG4c+cO0tPTUbJkSdSuXRs+Pj7o27cv7OzsJNfLPhAfj62/BWPj+nV4/PgRKrtXwdffTIVnjRpyh0XviX0gipbB3T/F4G5N4OxUHABw/fZDzPnpIA5HXFNu06CGK2aMaI/6ni7Izs7B5Vvx8Bv+I15mvJIrbCogdqKkIu+PgwcwJXASpkz/Dp6eNRG8aSMOH/4De/b9gRIlSsgdHr0HJhBFi2/T6sjOyUH03UdQQIF+fg0wbkBLNOw1D9dvP0SDGq7Ys3I4Fq4/jP1/XkFWdg5qVC6D/x2/gsxX/EIuaphAUJHXt1d3eFT3xDdTpgEAcnJy0LplM/Tu8zm+GDxE5ujofTCBKPrij8/HN0t3Y+Puv/DnxgkIPX0DM1ftlzss0gG9HoVB9C6vMjNx/do/aNjIS1lmYGCAhg29cDnyooyREf23GRgo0N2nLizNTXD6cizs7azwSQ1XPHqairAN4xF3dA4Orx0Dr1oV5A6VCplst/PWlYyMDGRkZKiUCUPTAk9CRfrhWdIzZGdnq12qKFGiBGJjb8sUFdF/l0dFJxzfOAFmJkZITc9Azwk/48bth/jE0wUA8O1QXwQu2YXLN++jb/tPcCBoFOp2n4OYu4/yr5iKrCLfAjF37lzY2tqqPBbMnyt3WEREH5Vbcf+iQa+5aNp/IX7ecRI/z/wcVSo4wsBAAQBYt/MkNu39G5E372PSohDcikvEgI6NZI6aClORb4EIDAzE+PHjVcqEIVsfijq7YnYwNDTEkydPVMqfPHmCkiVLyhQV0X/Xq6xs3L73GABw8fo91PUojxG9m2Ph+iMAXo/MeNPN2Ico5yh9FB0VHbK0QCQnJ6v8P7/Hu5iamsLGxkblwcsXRZ+xiQmqVvPA6b//Upbl5OTg9Om/UKNmbRkjIyIAMFAoYGpihDsPnuBBYhIquziorK/o7IC7CU9lio4+BFlaIOzs7JCQkAAHBwcUK1YMCoVCbRshBBQKBbKzs2WIkPTB5wMGYuo3k+HhUR3VPWtg86aNSE9PR6fOXeQOjeg/ZeaoDjgU8Q/uJTyDtaUZerath6b1KsFv+CoAwJKNRzHlq3a4cisekTfvo59fA7i7lEKfietkjpwKkywJxLFjx1C8+OsJScLCwuQIgYqANm198ezpU6xauRyPHz+Ce5WqWBW0FiV4CYPog7IvboV1s/rDsaQNnqe+xNWoePgNX4Vjp28AAFb+dhxmpsb4YUJX2Nla4MqteLQfthKx9x/LHDkVJs4DQUQfHOeBINJf2s4DIUsLxOXLl7XetganLSYiItI7siQQtWrVgkKheOdtvdkHgoiISD/JkkDExsbKcVgiIiLSEVkSCGdnZzkOS0RERDoiSwKxd+9etG3bFsbGxti7d2++23bo0OEDRUVERETakmUUhoGBAR4+fAgHBwcYGOQ9l1VB+0BwFAaRfuMoDCL9pdejMHJycjT+n4iIiIqGIn8zLSIiIvrwZGmBWL58udbbjh49uhAjISIiooKQpQ+Eq6urVtspFArcvn1bcv3sA0Gk39gHgkh/6XUfCM4DQUREVLSxDwQRERFJJksLxNvu37+PvXv34u7du8jMzFRZt3jxYpmiIiIiorzInkCEhoaiQ4cOqFChAm7cuIHq1asjLi4OQgjUqVNH7vCIiIhIA9kvYQQGBiIgIABXrlyBmZkZdu7ciXv37qFZs2bo3r273OERERGRBrInENevX0f//v0BAEZGRkhPT4eVlRVmzpyJ+fPnyxwdERERaSJ7AmFpaans91C6dGnExMQo1z1+/FiusIiIiCgfsveBaNiwIU6ePImqVavC19cXEyZMwJUrVxASEoKGDRvKHR4RERFpIHsCsXjxYqSmpgIAvvvuO6SmpmLbtm2oVKkSR2AQERHpKVlmoixsnImSSL9xJkoi/aXXM1HmJTU1Ve3unDY2NjJFQ0RERHmRvRNlbGws2rVrB0tLS9ja2sLOzg52dnYoVqwY7Ozs5A6PiIiINJC9BaJfv34QQuCXX35BqVKloFAo5A6JiIiI3kH2BCIyMhLnz5+Hu7u73KEQERGRlmS/hFG/fn3cu3dP7jCIiIhIAtlbINauXYuvvvoK8fHxqF69OoyNjVXW16hRQ6bIiIiIKC+yJxCPHj1CTEwMBg4cqCxTKBQQQkChUCA7O1vG6IiIiEgT2ROIQYMGoXbt2tiyZQs7URIRERURsicQd+7cwd69e1GxYkW5QyEiIiItyd6JskWLFoiMjJQ7DCIiIpJA9hYIPz8/jBs3DleuXIGnp6daJ8oOHTrIFBkRERHlRfZ7YRgY5N0IUtBOlLwXBpF+470wiPRXkbkXxtv3viAiIiL9J3sfCCIiIip69CKB+PPPP+Hn54eKFSuiYsWK6NChA8LDw+UOi4iIiPIgewKxefNmtGrVChYWFhg9ejRGjx4Nc3NztGzZEr/99pvc4REREZEGsneirFq1KoYMGYJx48aplC9evBg///wzrl+/LrlOdqIk0m/sREmkv7TtRCl7C8Tt27fh5+enVt6hQwfExsbKEBERERG9i+wJRLly5RAaGqpWfvToUZQrV06GiIiIiOhdZB/GOWHCBIwePRqXLl2Cl5cXACAiIgIbNmzAsmXLZI6OiIiINJE9gRg2bBgcHR2xaNEibN++HcDrfhHbtm1Dx44dZY6OiIiINJG9E2VhYCdKIv3GTpRE+qvIzESZKzMzE4mJiWozU5YvX16miIiIiCgvsicQUVFRGDRoEE6dOqVSLoQo8L0wiIiIqHDJnkD4+/vDyMgI+/btQ+nSpaFQKOQOiYiIiN5B9gTi0qVLOH/+PKpUqSJ3KERERKQl2eeBqFatGh4/fix3GERERCSB7AnE/PnzMWnSJBw/fhxPnjxBcnKyyoOIiIj0j+zDOA0MXucwb/d9eJ9OlBzGSaTfOIyTSH8VmWGcYWFhcodAREREEsmeQDRr1izPdVevXv2AkRAREZG2ZO8D8baUlBT89NNP+OSTT1CzZk25wyEiIiIN9CaBOHHiBAYMGIDSpUtj4cKFaNGiBf7++2+5wyIiIiINZL2E8fDhQ2zYsAHr1q1DcnIyevTogYyMDOzevRvVqlWTMzQiIiLKh2wtEH5+fnB3d8fly5exdOlSPHjwACtWrJArHCIiIpJAthaIgwcPYvTo0Rg2bBgqVaokVxhERERUALK1QJw8eRIpKSmoW7cuGjRogJUrV3JGSiIioiJCtgSiYcOG+Pnnn5GQkIChQ4di69atcHJyQk5ODo4cOYKUlBS5QiMiIqJ3kH0myjfdvHkT69atw6ZNm5CUlARvb2/s3btXcj2ciZJIv3EmSiL9pe1MlHozjBMA3N3d8cMPP+D+/fvYsmWL3OEQERFRHvSqBUJX2AJBpN/YAkGkv4pkCwQREREVDUwgiIiISDImEERERCQZEwgiIiKSjAkEERERScYEgoiIiCRjAkFERESSMYEgIiIiyZhAEBERkWRMIIiIiEgyJhBEREQkGRMIIiIikowJBBEREUnGBIKIiIgkYwJBREREkjGBICIiIsmYQBAREZFkTCCIiIhIMiYQREREJBkTCCIiIpKMCQQRERFJxgSCiIiIJGMCQURERJIxgSAiIiLJmEAQERGRZEwgiIiISDImEERERCQZEwgiIiKSjAkEERERScYEgoiIiCRTCCGE3EEQ5ScjIwNz585FYGAgTE1N5Q6HiN7A8/O/iwkE6b3k5GTY2tri+fPnsLGxkTscInoDz8//Ll7CICIiIsmYQBAREZFkTCCIiIhIMiYQpPdMTU0xffp0dtAi0kM8P/+72ImSiIiIJGMLBBEREUnGBIKIiIgkYwJBREREkjGBICIiIsmYQJBsjh8/DoVCgaSkpHy3Cw0NRdWqVZGdnf3ex/T390enTp3eu563bdiwAcWKFZO0T69evbBo0SKdx0JUEC4uLli6dKlyWaFQYPfu3QCAuLg4KBQKXLp0CQDPXZ67rzGB+Aj4+/tDoVBg3rx5KuW7d++GQqGQKSrdmTRpEqZMmQJDQ0M0b94cCoUiz0fz5s1libFnz564deuWpH2mTJmC77//Hs+fPy+kqOhD++uvv2BoaIh27drJHcp7S0hIQNu2bTWu8/LyQkJCAmxtbfOtg+fux40JxEfCzMwM8+fPx7Nnz3Rab2Zmpk7rk+rkyZOIiYlB165dAQAhISFISEhAQkICzpw5AwA4evSosiwkJESWOM3NzeHg4CBpn+rVq8PNzQ2bN28upKjoQ1u3bh1GjRqFEydO4MGDB3KH814cHR3znNvBxMQEjo6O+f5A4bn78WMC8ZFo1aoVHB0dMXfu3Hy327lzJzw8PGBqagoXFxe1ZjgXFxfMmjUL/fv3h42NDYYMGaJs4tu3bx/c3d1hYWGBbt26IS0tDRs3boSLiwvs7OwwevRolabKTZs2oV69erC2toajoyP69OmDxMRESc9r69at8Pb2hpmZGQCgePHicHR0hKOjI+zt7QEAJUqUUC5PnDgRrq6uMDc3h7u7O5YtW6ax3oULF6J06dIoUaIERowYgVevXqm8BrNnz0b//v1hZWUFZ2dn7N27F48ePULHjh1hZWWFGjVq4Ny5c8p93m4GnTFjBmrVqoVNmzbBxcUFtra26NWrF1JSUlTi8PPzw9atWyW9JqSfUlNTsW3bNgwbNgzt2rXDhg0bVNbnNvuHhoaiXr16sLCwgJeXF27evKmy3erVq+Hm5gYTExO4u7tj06ZNKusVCgWCgoLQvn17WFhYoGrVqvjrr78QHR2N5s2bw9LSEl5eXoiJiVHuExMTg44dO6JUqVKwsrJC/fr1cfTo0Xyfz5uXMN6mzSUMnrsfPyYQHwlDQ0PMmTMHK1aswP379zVuc/78efTo0QO9evXClStXMGPGDEydOlXti27hwoWoWbMmLl68iKlTpwIA0tLSsHz5cmzduhV//PEHjh8/js6dO+PAgQM4cOAANm3ahKCgIPz+++/Kel69eoVZs2YhMjISu3fvRlxcHPz9/SU9r/DwcNSrV0+rbXNyclC2bFns2LED165dw7Rp0/DNN99g+/btKtuFhYUhJiYGYWFh2LhxIzZs2KD2GixZsgSNGzfGxYsX0a5dO3z++efo378/+vXrhwsXLsDNzQ39+/dHfvOwxcTEYPfu3di3bx/27duHP//8U+0y0yeffIIzZ84gIyNDuxeE9Nb27dtRpUoVuLu7o1+/fvjll180fj6+/fZbLFq0COfOnYORkREGDRqkXLdr1y6MGTMGEyZMwNWrVzF06FAMHDgQYWFhKnXkJvmXLl1ClSpV0KdPHwwdOhSBgYE4d+4chBAYOXKkcvvU1FT4+voiNDQUFy9eRJs2beDn54e7d+8W2uvBc/c/QFCRN2DAANGxY0chhBANGzYUgwYNEkIIsWvXLvHmW9ynTx/h7e2tsu/EiRNFtWrVlMvOzs6iU6dOKtusX79eABDR0dHKsqFDhwoLCwuRkpKiLPPx8RFDhw7NM86zZ88KAMp9wsLCBADx7NmzPPextbUVv/76q8Z1sbGxAoC4ePFinvuPGDFCdO3aVbk8YMAA4ezsLLKyspRl3bt3Fz179lQuOzs7i379+imXExISBAAxdepUZdlff/0lAIiEhAQhxOvXyNbWVrl++vTpwsLCQiQnJyvLJk6cKBo0aKASX2RkpAAg4uLi8nwOVDR4eXmJpUuXCiGEePXqlShZsqQICwtTrs/9vB89elRZtn//fgFApKenK+sYPHiwSr3du3cXvr6+ymUAYsqUKcrl3M/iunXrlGVbtmwRZmZm+cbr4eEhVqxYoVx2dnYWS5YsUTnOrl27hBDq5xrPXZ67QgjBFoiPzPz587Fx40Zcv35dbd3169fRuHFjlbLGjRsjKipK5dKDpl8NFhYWcHNzUy6XKlUKLi4usLKyUil78xLF+fPn4efnh/Lly8Pa2hrNmjUDAEm/etLT05VNoNr48ccfUbduXdjb28PKygo//fST2vE8PDxgaGioXC5durTapZUaNWqoPC8A8PT0VCvL75KMi4sLrK2t8z2Oubk5gNctPFR03bx5E2fOnEHv3r0BAEZGRujZsyfWrVuntu2bn63SpUsD+L/PUV7n6Nvnszafz5cvXyI5ORnA6xaIgIAAVK1aFcWKFYOVlRWuX79eqC0QPHc/fkwgPjJNmzaFj48PAgMDC1yHpaWlWpmxsbHKskKh0FiWk5MDAHjx4gV8fHxgY2OD4OBgnD17Frt27QIgrWNmyZIlte4YunXrVgQEBOCLL77A4cOHcenSJQwcOFDtePnFrWmb3I5imsre3k/qcZ4+fQoAymvCVDStW7cOWVlZcHJygpGREYyMjLB69Wrs3LlTrae+1M+RJlI/nwEBAdi1axfmzJmD8PBwXLp0CZ6enoXaSZrn7sfPSO4ASPfmzZuHWrVqwd3dXaW8atWqiIiIUCmLiIhA5cqVVbJ6Xbhx4waePHmCefPmoVy5cgCg0nFJW7Vr18a1a9e02jYiIgJeXl4YPny4suzNjmT66OrVqyhbtixKliwpdyhUQFlZWfj111+xaNEitG7dWmVdp06dsGXLFnz11Vda1ZV7jg4YMEBZFhERgWrVqr1XjBEREfD390fnzp0BvG6RiIuLe68634Xn7sePLRAfIU9PT/Tt2xfLly9XKZ8wYQJCQ0Mxa9Ys3Lp1Cxs3bsTKlSsREBCg8xjKly8PExMTrFixArdv38bevXsxa9YsyfX4+Pjg5MmTWm1bqVIlnDt3DocOHcKtW7cwdepUnD17VvIxP6Tw8HC1PzpUtOzbtw/Pnj3DF198gerVq6s8unbtqvEyRl4mTpyIDRs2YPXq1YiKisLixYsREhLy3udopUqVEBISgkuXLiEyMhJ9+vSR3OohFc/djx8TiI/UzJkz1b4g6tSpg+3bt2Pr1q2oXr06pk2bhpkzZ0oeGaENe3t7bNiwATt27EC1atUwb948LFy4UHI9ffv2xT///KM21E2ToUOHokuXLujZsycaNGiAJ0+eqPyi0TcvX77E7t27MXjwYLlDofewbt06tGrVSuOkSl27dsW5c+dw+fJlrerq1KkTli1bhoULF8LDwwNBQUFYv379e0+ytHjxYtjZ2cHLywt+fn7w8fFBnTp13qvOd+G5+/FTCJHPWBYiPTBx4kQkJycjKChI7lB0avXq1di1axcOHz4sdyhEhYLn7seNLRCk97799ls4OzsXepPrh2ZsbIwVK1bIHQZRoeG5+3FjCwQRERFJxhYIIiIikowJBBEREUnGBIKIiIgkYwJBREREkjGBICIiIsmYQBDJwMXFBUuXLtV5vf7+/ujUqZPO69XG289JoVBg9+7dAIC4uDgoFApcunRJltjeZcOGDShWrJhyecaMGahVq5bOj1NY7zuRHJhAEBWAQqHI9zFjxgxZ4lq2bBk2bNjwXnXMmDFD43OqUqWKpHoSEhLQtm3b94pFKm1i1/RHvGfPnrh165bO4ng7ISH6GPFmWkQFkJCQoPz/tm3bMG3aNJUpe9+8zfmHpGk65YLw8PDA0aNHVcqMjKR9XTg6OuokFqkKEru5ubny9sz6LDMzEyYmJnKHQQSALRBEBeLo6Kh82NraQqFQKJdfvHiBvn37olSpUrCyskL9+vXV/qABQFpaGgYNGgRra2uUL18eP/30k3JdbpP/9u3b0aRJE5ibm6N+/fq4desWzp49i3r16sHKygpt27bFo0ePlPu9fQmjefPmGD16NCZNmoTixYvD0dFRq9YRIyMjlefo6OioctfBxMRE+Pn5wdzcHK6urggODlar481LGJpcvXoVbdu2hZWVFUqVKoXPP/8cjx8/LtTYmzdvjjt37mDcuHHK1gng3S0GMTExqFChAkaOHAkhBDIyMhAQEIAyZcrA0tISDRo0wPHjxwEAx48fx8CBA/H8+fN3tkglJSXhyy+/hL29PWxsbNCiRQtERkYq1+deSlm7di1cXV1hZmb2zudP9KEwgSDSsdTUVPj6+iI0NBQXL15EmzZt4Ofnh7t376pst2jRItSrVw8XL17E8OHDMWzYMLUbD02fPh1TpkzBhQsXYGRkhD59+mDSpElYtmwZwsPDER0djWnTpuUbz8aNG2FpaYnTp0/jhx9+wMyZM3HkyJH3eo7+/v64d+8ewsLC8Pvvv2PVqlVITEzUev+kpCS0aNECtWvXxrlz5/DHH3/g33//RY8ePQo19pCQEJQtWxYzZ85EQkKCSktSXi5fvoxPP/0Uffr0wcqVK6FQKDBy5Ej89ddf2Lp1Ky5fvozu3bujTZs2iIqKgpeXF5YuXQobGxvlMfK6m2b37t2RmJiIgwcP4vz586hTpw5atmyJp0+fKreJjo7Gzp07lXfTJNIbgojey/r164WtrW2+23h4eIgVK1Yol52dnUW/fv2Uyzk5OcLBwUGsXr1aCCFEbGysACDWrl2r3GbLli0CgAgNDVWWzZ07V7i7uyuXBwwYIDp27Khcbtasmfj0009VYqlfv76YPHlynrFOnz5dGBgYCEtLS5XH0KFDhRBC3Lx5UwAQZ86cUe5z/fp1AUAsWbJEWQZA7Nq1S+X5XLx4UQghxKxZs0Tr1q1Vjnvv3j0BQNy8ebPQYhfi9Wv/ZpxCqL+H06dPFzVr1hQRERHCzs5OLFy4ULnuzp07wtDQUMTHx6vU0bJlSxEYGKixPk3HDg8PFzY2NuLly5cq27i5uYmgoCBlHMbGxiIxMTHP50wkF/aBINKx1NRUzJgxA/v370dCQgKysrKQnp6u1gJRo0YN5f9zL4G8/Sv+zW1KlSoFAPD09FQpe9cv/zfrAIDSpUu/cx93d3fs3btXpczGxgYAcP36dRgZGaFu3brKdVWqVJHUaTAyMhJhYWEa+4rExMSgcuXKhRK7FHfv3oW3tze+//57jB07Vll+5coVZGdnK2PMlZGRgRIlSmhdf2RkJFJTU9X2SU9PR0xMjHLZ2dkZ9vb2kuMnKmxMIIh0LCAgAEeOHMHChQtRsWJFmJubo1u3bsjMzFTZztjYWGVZoVCo3bXwzW1yr9e/XfauOx1qc5y3mZiYoGLFivlu8z5SU1Ph5+eH+fPnq60rXbq08v9yxm5vbw8nJyds2bIFgwYNUiYhqampMDQ0xPnz52FoaKiyj5TOs6mpqShdurSy78Sb3kzGLC0tCxQ/UWFjAkGkYxEREfD390fnzp0BvP5DERcXJ29QOlSlShVkZWXh/PnzqF+/PgDg5s2bSEpK0rqOOnXqYOfOnXBxcZE8uuN9mZiYIDs7+53bmZubY9++ffD19YWPjw8OHz4Ma2tr1K5dG9nZ2UhMTESTJk0KfIw6derg4cOHMDIygouLS0GeCpGs2ImSSMcqVaqk7PAWGRmJPn36vPNXs77JysrCw4cPVR7//vsvgNeXCNq0aYOhQ4fi9OnTOH/+PL788ktJwyBHjBiBp0+fonfv3jh79ixiYmJw6NAhDBw4UKs/7gWNHXg9D8SJEycQHx+vMupDE0tLS+zfvx9GRkZo27YtUlNTUblyZfTt2xf9+/dHSEgIYmNjcebMGcydOxf79+9XHiM1NRWhoaF4/Pgx0tLS1Opu1aoVGjVqhE6dOuHw4cOIi4vDqVOn8O233+LcuXPv9RoQfQhMIIh0bPHixbCzs4OXlxf8/Pzg4+ODOnXqyB2WJP/88w9Kly6t8nB2dlauX79+PZycnNCsWTN06dIFQ4YMgYODg9b1Ozk5ISIiAtnZ2WjdujU8PT0xduxYFCtWDAYG7/e19K7YZ86cibi4OLi5uWnVt8DKygoHDx6EEALt2rXDixcvsH79evTv3x8TJkyAu7s7OnXqhLNnz6J8+fIAAC8vL3z11Vfo2bMn7O3t8cMPP6jVq1AocODAATRt2hQDBw5E5cqV0atXL9y5c0fZ34VInymEEELuIIiIiKhoYQsEERERScYEgoiIiCRjAkFERESSMYEgIiIiyZhAEBERkWRMIIiIiEgyJhBEREQkGRMIIiIikowJBBEREUnGBIKIiIgkYwJBREREkv0/LLZGtzAzgtAAAAAASUVORK5CYII=\n"},"metadata":{}}],"source":["print(\"\\n--- Model Performans Metrikleri ---\")\n","\n","# Performans metriklerini hesapla\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels)\n","recall = recall_score(true_labels, predicted_labels)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"F1-Score: {f1:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","\n","# Karışıklık Matrisini oluştur\n","cm = confusion_matrix(true_labels, predicted_labels)\n","print(\"\\nKarışıklık Matrisi:\")\n","print(cm)\n","\n","# Karışıklık Matrisini görselleştir\n","plt.figure(figsize=(6, 5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=['Normal (Tahmin)', 'Anomalili (Tahmin)'],\n","            yticklabels=['Normal (Gerçek)', 'Anomalili (Gerçek)'])\n","plt.title('AutoEncoder Anomali Tespit Karışıklık Matrisi')\n","plt.xlabel('Tahmin Edilen Etiketler')\n","plt.ylabel('Gerçek Etiketler')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1M4SO0SHo7gm-6HHuzNE2SMS77tgkhyQy"},"executionInfo":{"elapsed":5469,"status":"ok","timestamp":1766610551170,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"},"user_tz":-180},"id":"fa45dfb5","outputId":"3d1d2773-41c3-4291-9c01-5bcd8f50f5b4"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["print(\"Visualizing TEST (Good samples)\")\n","visualize_reconstructions(\n","    model,\n","    test_dataset,\n","    device,\n","    num_samples=3,\n","    is_anomaly=False,\n","    title_prefix=\"Test / Good\"\n",")\n"]},{"cell_type":"code","source":["print(\"Visualizing TEST (Defect samples)\")\n","visualize_reconstructions(\n","    model,\n","    test_dataset,\n","    device,\n","    num_samples=3,\n","    is_anomaly=True,\n","    title_prefix=\"Test / Defect\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1LA0H78JzzZNIBQJ39NTUtQFOitg5DufS"},"id":"IGQ_clJJMaQS","executionInfo":{"status":"ok","timestamp":1766610568170,"user_tz":-180,"elapsed":2831,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"}},"outputId":"9235afdb-c506-4b3d-ac3b-bba034377e80"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Train SimpleNet"],"metadata":{"id":"ThHWsu5jMGVZ"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","backbone = SimpleNet(in_channels=3, latent_dim=256).to(device)\n","model = SimpleNet(backbone, latent_dim=256).to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"zlx0mMIjP4OR","executionInfo":{"status":"error","timestamp":1766611482463,"user_tz":-180,"elapsed":247,"user":{"displayName":"Yasin Ünal","userId":"01360535112664148571"}},"outputId":"7e17ad8a-eef2-4ea7-aad5-a9963962135a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for %: 'SimpleNet' and 'int'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3652233791.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2869984178.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, latent_dim)\u001b[0m\n\u001b[1;32m     11\u001b[0m         self.features = nn.Sequential(\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 32x256x256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 32x128x128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mpadding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mdilation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"groups must be a positive integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"in_channels must be divisible by groups\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'SimpleNet' and 'int'"]}]},{"cell_type":"code","source":["NUM_EPOCHS = 15\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_dataloader:\n","        images = images.to(device)\n","        labels = labels.float().to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(images)\n","        loss = criterion(logits, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","\n","        preds = (torch.sigmoid(logits) >= 0.5).int()\n","        correct += (preds == labels.int()).sum().item()\n","        total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = correct / total\n","\n","    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n","          f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n"],"metadata":{"id":"wzU2PfKiP6z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import (\n","    confusion_matrix, accuracy_score,\n","    f1_score, recall_score, roc_curve, auc\n",")\n","\n","model.eval()\n","all_scores = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in test_dataloader:\n","        images = images.to(device)\n","\n","        logits = model(images)\n","        scores = torch.sigmoid(logits)  # anomaly probability\n","\n","        all_scores.extend(scores.cpu().numpy())\n","        all_labels.extend(labels.numpy())\n","\n","all_scores = np.array(all_scores)\n","all_labels = np.array(all_labels)\n"],"metadata":{"id":"YNEslV2aP8PJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"cthoV9tlP4iJ"}},{"cell_type":"markdown","metadata":{"id":"0b6955d8"},"source":["## Basitleştirilmiş PatchCore Yaklaşımını Anlat\n","\n","### Subtask:\n","PatchCore anomali tespit yönteminin temel prensiplerini ve basitleştirilmiş bir uygulamasının nasıl yapılabileceğini açıklayın. Bu, görüntü yamalarının nasıl çıkarılacağı, bir özellik uzayında nasıl temsil edileceği ve anormallik skorlarının nasıl hesaplanacağı hakkında kavramsal bir genel bakış içerecektir.\n","\n","### PatchCore Yaklaşımının Genel Amacı ve Anomali Tespitindeki Rolü\n","PatchCore, özellikle görsel anomali tespiti (Visual Anomaly Detection) alanında yüksek performans gösteren bir tek sınıflı (one-class) sınıflandırma yöntemidir. Amacı, yalnızca 'normal' veriler üzerinde eğitilerek, daha sonra karşılaşılan görüntülerin normal mi yoksa anomali mi olduğunu etkili bir şekilde belirlemektir. Endüstriyel denetim, tıbbi görüntüleme ve kalite kontrol gibi alanlarda, anomali örneklerinin azlığı veya çeşitliliği nedeniyle geleneksel sınıflandırma yöntemlerinin yetersiz kaldığı durumlarda büyük önem taşır.\n","\n","### Görüntü Yamalarının (Image Patches) Çıkarılması\n","PatchCore'un temel fikri, bir görüntüyü bütün olarak analiz etmek yerine, onu küçük, örtüşen parçalara (patch'ler) ayırarak her bir yamanın özelliklerini incelemektir. Bu yamalar, genellikle görüntünün farklı bölgelerindeki lokal dokuları, kenarları ve desenleri yakalar. Anomali tespiti için önemlidir, çünkü anomaliler genellikle görüntünün sadece belirli bölgelerinde (örneğin, bir yüzeydeki çatlak veya çizik) ortaya çıkar. Görüntüyü yamalara bölerek model, anomalinin tam olarak nerede olduğunu ve neye benzediğini daha hassas bir şekilde belirleyebilir.\n","\n","### Özellik Uzayında Temsil Edilme ve Özellik Öğrenimi\n","Çıkarılan her bir görüntü yaması, önceden eğitilmiş derin bir Evrişimsel Sinir Ağı (CNN) (örneğin, ResNet gibi bir omurga ağı) kullanılarak bir özellik vektörüne dönüştürülür. Bu CNN'ler genellikle büyük ölçekli görüntü sınıflandırma görevlerinde (ImageNet gibi) eğitilmiş olup, genel görüntü özelliklerini çıkarma konusunda oldukça etkilidirler. Her yama için elde edilen bu özellik vektörleri, görüntünün anlamsal içeriğini ve dokusal bilgilerini yoğunlaştırılmış bir biçimde temsil eder. Bu özellikler, yüksek boyutlu bir 'özellik uzayında' yer alır.\n","\n","### Normal Dağılımın Oluşturulması ve Sapmaların Değerlendirilmesi\n","Eğitim aşamasında, yalnızca 'normal' kabul edilen görüntüler kullanılır. Bu normal görüntülerden çıkarılan tüm yama özellik vektörleri toplanır ve bu özellik uzayında bir 'bellek bankası' (memory bank) veya 'çekirdek kümesi' (coreset) oluşturulur. Bu bellek bankası, normal veri dağılımının bir temsilini sağlar. Amacı, normal görüntülerdeki çeşitli doku ve desenleri kapsayan, ancak aynı zamanda gereksiz tekrarı azaltan temsili bir özellik kümesi oluşturmaktır. Test aşamasında, bir görüntünün yamalarından çıkarılan özellikler bu bellek bankasındaki en yakın normal yamalarla karşılaştırılır. Bu karşılaştırma, öklid mesafesi veya diğer benzerlik ölçütleri ile yapılır.\n","\n","### Anormallik Skorlarının Hesaplanması\n","Bir test görüntüsü verildiğinde:\n","1. Görüntü, yamalara ayrılır.\n","2. Her bir yama, önceden eğitilmiş modelden bir özellik vektörü olarak çıkarılır.\n","3. Her bir yama özelliği vektörü için, bellek bankasındaki (normal örneklerden oluşturulan) en yakın komşu (k-NN) veya komşular bulunur.\n","4. Bu en yakın komşuya olan mesafe, o yamanın 'anormallik skoru' olarak kabul edilir. Mesafe ne kadar büyükse, yama o kadar anomalidir.\n","5. Görüntünün genel anormallik skoru ise, genellikle görüntüyü oluşturan yamalardan elde edilen en yüksek (maksimum) anormallik skorudur. Bu, anomali genellikle görüntünün sadece küçük bir bölümünü etkilediği için mantıklıdır.\n","\n","Sonuç olarak, yüksek anormallik skoruna sahip bir görüntü veya görüntü bölgesi, modelin eğitimde görmediği 'normal' kalıplardan önemli ölçüde sapan bir durum olarak işaretlenir. Bu basit ama etkili yaklaşım, anomalilerin lokal doğasından yararlanarak başarılı sonuçlar elde edilmesini sağlar."]},{"cell_type":"markdown","metadata":{"id":"5edeae6a"},"source":["## Padim Yaklaşımını Anlat\n","\n","### Subtask:\n","Padim anomali tespit yönteminin temel prensiplerini ve uygulamasının nasıl yapılabileceğini açıklayın. Bu, çok ölçekli özellik çıkarma, Gaussian dağılımı ile normalleştirme ve anormallik skorlarının nasıl hesaplanacağı hakkında kavramsal bir genel bakış içerecektir.\n","\n","### Padim: Anomali Tespiti İçin Çok Ölçekli Bir Yaklaşım\n","\n","Padim (PAtch Dİstribution Modeling), özellikle görüntü verilerinde anomali tespiti için geliştirilmiş, tek sınıflı bir sınıflandırma yöntemidir. Temel amacı, yalnızca 'normal' veya 'iyi' verilere maruz kalarak bir sistemin veya ürünün normal davranışını öğrenmek ve ardından bu normal davranıştan sapan her şeyi anomali olarak işaretlemektir. Bu, endüstriyel denetim ve kalite kontrol gibi alanlarda, anomali örneklerinin az veya hiç bulunmadığı durumlarda son derece değerlidir.\n","\n","### 1. Çok Ölçekli Özellik Çıkarma\n","\n","Padim'in ilk adımı, eğitim verilerinden zengin ve çok ölçekli özellik temsilleri elde etmektir. Bu genellikle önceden eğitilmiş bir Evrişimsel Sinir Ağı (CNN) kullanılarak yapılır (örneğin, ImageNet üzerinde eğitilmiş ResNet gibi bir model). İşlem şu adımları içerir:\n","\n","*   **Önceden Eğitilmiş CNN Kullanımı**: Bir görüntü, önceden eğitilmiş CNN'in farklı katmanlarından geçirilir. Tipik olarak, düşük seviyeli özellikler (kenarlar, dokular) ve daha yüksek seviyeli, semantik özellikler (nesne parçaları) yakalamak için çeşitli derinliklerden katman çıktıları seçilir.\n","*   **Özellik Haritalarının Birleştirilmesi**: Seçilen katmanlardan elde edilen özellik haritaları, uzamsal konumlarını koruyarak bir araya getirilir. Her bir konumdaki özellik vektörü, görüntünün o bölgesindeki çok ölçekli temsili haline gelir. Bu, özellikle küçük anomalilerin tespitinde kritiktir, çünkü farklı katmanlar farklı çözünürlüklerde ve soyutluk seviyelerinde bilgi taşır.\n","*   **Rastgele Projektör**: Bellek ve hesaplama yükünü azaltmak için, çıkarılan özellik vektörleri genellikle rastgele bir projeksiyon matrisi kullanılarak daha düşük boyutlu bir uzaya indirgenir. Bu, bilginin çoğunu korurken verimliliği artırır.\n","\n","### 2. Gaussian Dağılımı ile Normalleştirme\n","\n","Eğitim setindeki normal görüntülerden çıkarılan çok ölçekli özellik vektörleri kullanılarak, her bir uzamsal konum için bir Gaussian dağılımı modellenir. Bu adım, normal verinin istatistiksel özelliklerini öğrenir ve anormallikleri ayırt etmek için bir referans sağlar:\n","\n","*   **Özellik Vektörlerinin Toplanması**: Eğitim setindeki tüm normal görüntülerden, her bir uzamsal konum (örneğin, bir özellik haritasındaki her piksel konumu) için elde edilen özellik vektörleri toplanır.\n","*   **Gaussian Parametrelerinin Hesaplanması**: Her bir uzamsal konum `(i, j)` için, bu konumdaki tüm normal özellik vektörlerinin ortalaması (μ<sub>ij</sub>) ve eşdeğer kovaryans matrisi (Σ<sub>ij</sub>) hesaplanır. Bu ortalama ve kovaryans matrisi, o konumdaki normal özelliklerin Gaussian dağılımını tanımlar. Geleneksel olarak, tüm konumlar için ortak bir kovaryans matrisi de kullanılabilir, ancak konum bazlı öğrenme daha hassastır.\n","*   **Normalizasyon**: Bu istatistikler, yeni gelen bir görüntünün özelliklerinin 'normallik' derecesini değerlendirmek için bir referans noktası görevi görür.\n","\n","### 3. Anormallik Skorlarının Hesaplanması\n","\n","Bir test görüntüsü geldiğinde, Padim anomali tespitini şu şekilde gerçekleştirir:\n","\n","*   **Özellik Çıkarma**: Test görüntüsü de eğitim sırasında kullanılan aynı önceden eğitilmiş CNN'den geçirilir ve çok ölçekli özellik vektörleri çıkarılır.\n","*   **Mahalanobis Mesafesi**: Her bir uzamsal konumdaki çıkarılan özellik vektörü `f_test` için, daha önce öğrenilen Gaussian dağılımının parametreleri (μ<sub>ij</sub>, Σ<sub>ij</sub>) kullanılarak Mahalanobis mesafesi hesaplanır. Mahalanobis mesafesi, bir noktanın bir dağılımın merkezinden ne kadar uzakta olduğunu, dağılımın şeklini (kovaryans) dikkate alarak ölçer. Yüksek Mahalanobis mesafesi, o konumdaki özelliğin normal dağılımdan saptığını gösterir.\n","    Mahalanobis Mesafesi Formülü: `d(f_test) = sqrt((f_test - μ_ij)^T * Σ_ij^-1 * (f_test - μ_ij))`\n","*   **Anomali Haritası Oluşturma**: Her piksel konumuna karşılık gelen Mahalanobis mesafesi değerleri, görüntünün bir anomali haritasını oluşturur. Bu harita, görüntünün hangi bölgelerinin normalden saptığını görsel olarak gösterir.\n","*   **Nihai Anomali Skoru**: Görüntünün genel anomali skoru, anomali haritasındaki en yüksek Mahalanobis mesafesi değeri (piksel seviyesindeki en büyük sapma) veya anomali haritasının toplamı/ortalaması gibi bir metrik kullanılarak belirlenir. Bu skor, görüntünün genel olarak anomalili olup olmadığını sınıflandırmak için bir eşik değerle karşılaştırılır.\n","\n","### Padim'in Avantajları ve Uygulama Senaryoları\n","\n","**Avantajları**:\n","\n","*   **Tek Sınıflı Öğrenme**: Yalnızca normal verilere ihtiyaç duyar, bu da anomali verilerinin az olduğu veya hiç bulunmadığı senaryolarda büyük bir avantajdır.\n","*   **Yerelleştirilmiş Anomali Tespiti**: Özellik haritası tabanlı yaklaşımı sayesinde, anomali haritaları oluşturarak anomalilerin görüntü içindeki kesin konumlarını belirleyebilir.\n","*   **Çok Ölçeklilik**: Farklı katmanlardan özellikler çıkararak hem küçük dokusal kusurları hem de daha büyük yapısal anomalileri tespit edebilir.\n","*   **Yorumlanabilirlik**: Anomali haritaları, tespit edilen anomalilerin neden ve nerede olduğunu anlamayı kolaylaştırır.\n","\n","**Uygulama Senaryoları**:\n","\n","*   **Endüstriyel Kalite Kontrol**: Üretim hatlarındaki ürünlerin yüzey kusurlarını, montaj hatalarını veya malzeme anomalilerini otomatik olarak tespit etmek.\n","*   **Tıbbi Görüntüleme**: X-ışınları, MRI veya diğer tıbbi görüntülerdeki anormallikleri veya patolojileri belirlemek.\n","*   **Güvenlik ve Gözetim**: Güvenlik kameralarından gelen görüntülerdeki anormal davranışları veya olayları tespit etmek.\n","*   **Tarım**: Bitki hastalıklarının veya ürün kusurlarının erken tespiti.\n"]},{"cell_type":"markdown","metadata":{"id":"97a5ac5f"},"source":["## Kavramsal EfficientAD Yaklaşımı\n","\n","### Subtask:\n","EfficientAD anomali tespit yönteminin temel fikirlerini ve kavramsal olarak nasıl çalıştığını açıklayın. Bu, bilgi damıtımı (knowledge distillation) ve farklı modellerin anomali tespiti için nasıl birleştirilebileceği hakkında bir genel bakış içerecektir.\n","\n","### 1. EfficientAD'nin Genel Amacı ve Anomali Tespitindeki Rolü\n","\n","**EfficientAD (Efficient Anomaly Detection)**, özellikle görüntü tabanlı anomali tespitinde yüksek performans ve kaynak verimliliğini bir araya getirmeyi hedefleyen modern bir yaklaşımdır. Geleneksel anomali tespit yöntemleri genellikle büyük ve karmaşık modeller gerektirebilirken, EfficientAD bu karmaşıklığı azaltmayı ve daha hafif, daha hızlı modellerle benzer veya daha iyi sonuçlar elde etmeyi amaçlar. Temel rolü, üretim ortamları gibi gerçek zamanlı veya kaynak kısıtlı senaryolarda anomalileri (hataları, kusurları) hızlı ve doğru bir şekilde tespit etmektir.\n","\n","**Anomali Tespitindeki Rolü:**\n","*   **Yüksek Performans:** Sınırlı normal veri ile bile anomalileri etkili bir şekilde ayırt etme yeteneği.\n","*   **Kaynak Verimliliği:** Daha az parametreye sahip modeller kullanarak bellek ve işlem gücü tüketimini optimize etme.\n","*   **Hız:** Gerçek zamanlı uygulamalarda hızlı çıkarım (inference) süreleri sağlama.\n","*   **Ölçeklenebilirlik:** Büyük veri setleri ve çeşitli uygulama alanları için uyarlanabilirlik.\n","\n","EfficientAD, genellikle tek sınıflı öğrenme (one-class learning) prensibine dayanır, yani sadece 'normal' verilere maruz kalarak bir model eğitilir ve bu normal dağılımdan sapan her şey anomali olarak kabul edilir. Bu, özellikle anomali örneklerinin nadir veya tanımlanması zor olduğu endüstriyel denetim gibi senaryolarda büyük bir avantaj sağlar.\n"]},{"cell_type":"markdown","metadata":{"id":"b4402cd1"},"source":["### 2. Bilgi Damıtımı (Knowledge Distillation) ve EfficientAD'deki Kullanımı\n","\n","**Bilgi Damıtımı (Knowledge Distillation)**, büyük ve karmaşık bir \"öğretmen\" modelden öğrenilen bilginin, daha küçük ve basit bir \"öğrenci\" modele aktarılması sürecidir. Amaç, öğrenci modelin öğretmen modelin performansına yaklaşmasını sağlarken, çok daha az kaynak tüketerek daha hızlı çalışmasını sağlamaktır. Anomali tespiti bağlamında EfficientAD, bu tekniği anomalileri daha etkin bir şekilde tespit etmek için kullanır.\n","\n","**EfficientAD'deki Uygulaması:**\n","\n","EfficientAD'de bilgi damıtımı genellikle şu şekilde işler:\n","\n","1.  **Öğretmen Modellerin Eğitimi:** Genellikle önceden eğitilmiş, büyük ve güçlü bir özellik çıkarıcı (feature extractor) veya bir AutoEncoder gibi modeller \"öğretmen\" olarak kullanılır. Bu öğretmen modeller, normal (hatasız) görüntüler üzerinde eğitilerek, normal veri dağılımının derinlemesine bir temsilini öğrenirler.\n","\n","2.  **Öğrenci Modellerin Eğitimi:** Daha küçük, daha hafif bir \"öğrenci\" model, öğretmen modellerin çıktılarını taklit edecek şekilde eğitilir. Öğrenci model, normal görüntülerden gelen \"öğretmen\" özelliklerini yeniden üretmeye çalışır. Bu eğitim sırasında, öğrenci modeli yalnızca normal verilere maruz kalır.\n","\n","3.  **Anomali Skorunun Hesaplanması:** Test aşamasında, hem öğretmen hem de öğrenci modellerden geçen bir görüntü için özellikler çıkarılır. Ardından, öğretmen ve öğrenci modellerin ürettiği özellik temsilleri arasındaki fark (örneğin, MSE veya kozinüs benzerliği gibi bir metrikle) anomali skoru olarak kullanılır. Normal görüntüler için bu farkın düşük olması beklenirken, anormal görüntüler için öğrenci modelin öğretmen modelin çıktısını doğru bir şekilde taklit edememesi nedeniyle yüksek bir fark oluşur.\n","\n","4.  **Neden Öğrenci ve Öğretmen Modelleri?** Öğrenci model, sadece normal verilere maruz kalarak eğitildiği için, anormal özelliklere aşina değildir. Öğretmen model ise daha genel ve kapsamlı bir bilgiye sahiptir. Anormal bir girdi geldiğinde, öğretmen model hala anlamlı özellikler üretebilirken, öğrenci model bu anormal özellikleri doğru bir şekilde temsil etmekte zorlanacak ve bu da aralarında büyük bir fark yaratacaktır. Bu fark, anomalinin varlığına işaret eder.\n"]},{"cell_type":"markdown","metadata":{"id":"010e8d63"},"source":["### 3. Farklı Modellerin Anomali Tespiti İçin Birleştirilmesi (Ensemble Yaklaşımları)\n","\n","EfficientAD, sadece bilgi damıtımıyla sınırlı kalmayıp, anomali tespit performansını artırmak için farklı model türlerini veya aynı türden birden fazla modeli birleştirebilir. Bu birleştirme teknikleri genellikle *ensemble öğrenme* olarak adlandırılır ve modelin genelleştirme yeteneğini ve karar gücünü artırmayı hedefler.\n","\n","**Nasıl Birleştirilir?**\n","\n","1.  **Çoklu Öğretmen/Öğrenci Modelleri:** Birden fazla öğretmen-öğrenci çifti kullanılabilir. Her çift farklı bir özelliği veya farklı bir model mimarisini temsil edebilir. Bu durumda, her bir çiftin ürettiği anomali skorları bir araya getirilerek (örneğin, ortalama alınarak veya ağırlıklı toplam yapılarak) nihai bir anomali skoru elde edilir.\n","2.  **Özellik Temelli ve Rekonstrüksiyon Temelli Modellerin Entegrasyonu:** Bazı EfficientAD varyantları, derin özellik öğrenimi tabanlı modeller (örneğin, öğretmen-öğrenci modelleri) ile geleneksel rekonstrüksiyon tabanlı modelleri (örneğin, AutoEncoderlar) birleştirebilir. Her iki model türünün de anomaliye farklı açılardan hassasiyeti olduğu için, bu entegrasyon daha sağlam bir anomali tespiti sağlayabilir.\n","3.  **Karar Seviyesinde Birleştirme:** Her bir model ayrı ayrı bir anomali skoru veya bir anomali tahmini üretir. Bu bireysel tahminler daha sonra bir oylama mekanizması (voting), bir meta-öğrenici (meta-learner) veya basit bir ortalama alma gibi yöntemlerle birleştirilerek nihai bir karar verilir.\n","\n","### 4. EfficientAD'nin Avantajları ve Uygulama Senaryoları\n","\n","**Avantajları:**\n","\n","*   **Yüksek Duyarlılık ve Özgüllük:** Normal verinin dağılımını çok iyi öğrendiği için, normalden en ufak sapmaları bile yüksek hassasiyetle tespit edebilir.\n","*   **Veri Verimliliği:** Genellikle sadece normal verilere ihtiyaç duyar, bu da anomali örneklerinin az veya elde edilmesinin zor olduğu durumlar için idealdir.\n","*   **Hesaplama Verimliliği:** Bilgi damıtımı sayesinde, çıkarım aşamasında daha küçük ve hızlı öğrenci modeller kullanılır, bu da gerçek zamanlı uygulamalar için kritik öneme sahiptir.\n","*   **Genellenebilirlik:** Farklı anomali türlerine ve çeşitli veri setlerine uyarlanabilir bir çerçeve sunar.\n","*   **Yorumlanabilirlik (Potansiyel):** Öğretmen ve öğrenci modeller arasındaki fark haritaları, anomalinin tam olarak nerede olduğunu göstererek yorumlanabilirliği artırabilir.\n","\n","**Uygulama Senaryoları:**\n","\n","*   **Endüstriyel Kalite Kontrol:** Üretim hattındaki ürünlerin (örneğin, ahşap, metal yüzeyler, elektronik bileşenler) görsel kusurlarını otomatik olarak tespit etme.\n","*   **Tıbbi Görüntüleme:** MR veya CT taramalarında anormal doku veya lezyonları (örneğin, tümörleri) belirleme.\n","*   **Gözetim ve Güvenlik:** Video akışlarında olağan dışı davranışları veya olayları (örneğin, izinsiz giriş, düşme) tespit etme.\n","*   **Makinelerde Arıza Tespiti:** Sensör verilerinden veya görsel denetimlerden makinelerdeki anormal çalışma durumlarını veya arızaları öngörme.\n","*   **Finansal Dolandırıcılık Tespiti:** İşlemlerden veya müşteri davranışlarından şüpheli kalıpları belirleme.\n","\n","**Özetle, EfficientAD,** anomali tespitinde hem yüksek performans hem de operasyonel verimlilik arayan uygulamalar için güçlü ve esnek bir çerçeve sunar."]},{"cell_type":"markdown","metadata":{"id":"7f4b3322"},"source":["### 3. Farklı Modellerin Anomali Tespiti İçin Birleştirilmesi (Ensemble Yaklaşımları)\n","\n","EfficientAD, sadece bilgi damıtımıyla sınırlı kalmayıp, anomali tespit performansını artırmak için farklı model türlerini veya aynı türden birden fazla modeli birleştirebilir. Bu birleştirme teknikleri genellikle *ensemble öğrenme* olarak adlandırılır ve modelin genelleştirme yeteneğini ve karar gücünü artırmayı hedefler.\n","\n","**Nasıl Birleştirilir?**\n","\n","1.  **Çoklu Öğretmen/Öğrenci Modelleri:** Birden fazla öğretmen-öğrenci çifti kullanılabilir. Her çift farklı bir özelliği veya farklı bir model mimarisini temsil edebilir. Bu durumda, her bir çiftin ürettiği anomali skorları bir araya getirilerek (örneğin, ortalama alınarak veya ağırlıklı toplam yapılarak) nihai bir anomali skoru elde edilir.\n","2.  **Özellik Temelli ve Rekonstrüksiyon Temelli Modellerin Entegrasyonu:** Bazı EfficientAD varyantları, derin özellik öğrenimi tabanlı modeller (örneğin, öğretmen-öğrenci modelleri) ile geleneksel rekonstrüksiyon tabanlı modelleri (örneğin, AutoEncoderlar) birleştirebilir. Her iki model türünün de anomaliye farklı açılardan hassasiyeti olduğu için, bu entegrasyon daha sağlam bir anomali tespiti sağlayabilir.\n","3.  **Karar Seviyesinde Birleştirme:** Her bir model ayrı ayrı bir anomali skoru veya bir anomali tahmini üretir. Bu bireysel tahminler daha sonra bir oylama mekanizması (voting), bir meta-öğrenici (meta-learner) veya basit bir ortalama alma gibi yöntemlerle birleştirilerek nihai bir karar verilir.\n","\n","### 4. EfficientAD'nin Avantajları ve Uygulama Senaryoları\n","\n","**Avantajları:**\n","\n","*   **Yüksek Duyarlılık ve Özgüllük:** Normal verinin dağılımını çok iyi öğrendiği için, normalden en ufak sapmaları bile yüksek hassasiyetle tespit edebilir.\n","*   **Veri Verimliliği:** Genellikle sadece normal verilere ihtiyaç duyar, bu da anomali örneklerinin az veya elde edilmesinin zor olduğu durumlar için idealdir.\n","*   **Hesaplama Verimliliği:** Bilgi damıtımı sayesinde, çıkarım aşamasında daha küçük ve hızlı öğrenci modeller kullanılır, bu da gerçek zamanlı uygulamalar için kritik öneme sahiptir.\n","*   **Genellenebilirlik:** Farklı anomali türlerine ve çeşitli veri setlerine uyarlanabilir bir çerçeve sunar.\n","*   **Yorumlanabilirlik (Potansiyel):** Öğretmen ve öğrenci modeller arasındaki fark haritaları, anomalinin tam olarak nerede olduğunu göstererek yorumlanabilirliği artırabilir.\n","\n","**Uygulama Senaryoları:**\n","\n","*   **Endüstriyel Kalite Kontrol:** Üretim hattındaki ürünlerin (örneğin, ahşap, metal yüzeyler, elektronik bileşenler) görsel kusurlarını otomatik olarak tespit etme.\n","*   **Tıbbi Görüntüleme:** MR veya CT taramalarında anormal doku veya lezyonları (örneğin, tümörleri) belirleme.\n","*   **Gözetim ve Güvenlik:** Video akışlarında olağan dışı davranışları veya olayları (örneğin, izinsiz giriş, düşme) tespit etme.\n","*   **Makinelerde Arıza Tespiti:** Sensör verilerinden veya görsel denetimlerden makinelerdeki anormal çalışma durumlarını veya arızaları öngörme.\n","*   **Finansal Dolandırıcılık Tespiti:** İşlemlerden veya müşteri davranışlarından şüpheli kalıpları belirleme.\n","\n","**Özetle, EfficientAD,** anomali tespitinde hem yüksek performans hem de operasyonel verimlilik arayan uygulamalar için güçlü ve esnek bir çerçeve sunar."]}]}