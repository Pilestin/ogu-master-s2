{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQKHDn15izvV"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wood Anomaly Detection V3 - Experiment Framework\n",
    "=================================================\n",
    "Hyperparameter testing and comparison framework for cold-start anomaly detection.\n",
    "\n",
    "Features:\n",
    "- Grid search for hyperparameter optimization\n",
    "- Results comparison table (CSV + console)\n",
    "- Best model selection (auto or manual)\n",
    "- Final evaluation with heatmaps\n",
    "\n",
    "Usage:\n",
    "    # Quick grid search (reduced epochs)\n",
    "    python compare_anomaly_models_v3.py --mode=grid --quick\n",
    "\n",
    "    # Full grid search\n",
    "    python compare_anomaly_models_v3.py --mode=grid\n",
    "\n",
    "    # Single model experiment\n",
    "    python compare_anomaly_models_v3.py --mode=single --model=AutoEncoder\n",
    "\n",
    "    # Final evaluation with specific config\n",
    "    python compare_anomaly_models_v3.py --mode=final\n",
    "\n",
    "Author: V3 Experiment Framework\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from typing import Tuple, List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "import pandas as pd\n",
    "import json\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ee9HT8LGtPEW",
    "outputId": "4f97d2bb-8dbc-4b17-abe2-846db1b3eec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ”¬ WOOD ANOMALY DETECTION V3 - EXPERIMENT FRAMEWORK\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ðŸ”¬ FULL EXPERIMENT MODE\n",
      "================================================================================\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "\n",
      "ðŸ”¬ Grid Search: PatchCore\n",
      "   Parameters: ['memory_bank_size', 'k_neighbors', 'use_multi_layer']\n",
      "   Combinations: 18\n",
      "\n",
      "[1/18] {'memory_bank_size': 1000, 'k_neighbors': 3, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132M/132M [00:00<00:00, 152MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AUC: 0.6194 | AUPRO: 0.0989 | F1: 0.8406\n",
      "\n",
      "[2/18] {'memory_bank_size': 1000, 'k_neighbors': 3, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.7056 | AUPRO: 0.1037 | F1: 0.6415\n",
      "\n",
      "[3/18] {'memory_bank_size': 1000, 'k_neighbors': 5, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6528 | AUPRO: 0.0973 | F1: 0.8611\n",
      "\n",
      "[4/18] {'memory_bank_size': 1000, 'k_neighbors': 5, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5806 | AUPRO: 0.1002 | F1: 0.6429\n",
      "\n",
      "[5/18] {'memory_bank_size': 1000, 'k_neighbors': 9, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6111 | AUPRO: 0.1062 | F1: 0.7879\n",
      "\n",
      "[6/18] {'memory_bank_size': 1000, 'k_neighbors': 9, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5639 | AUPRO: 0.1065 | F1: 0.7941\n",
      "\n",
      "[7/18] {'memory_bank_size': 2000, 'k_neighbors': 3, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6611 | AUPRO: 0.0963 | F1: 0.8235\n",
      "\n",
      "[8/18] {'memory_bank_size': 2000, 'k_neighbors': 3, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5750 | AUPRO: 0.1153 | F1: 0.5200\n",
      "\n",
      "[9/18] {'memory_bank_size': 2000, 'k_neighbors': 5, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6500 | AUPRO: 0.1006 | F1: 0.7333\n",
      "\n",
      "[10/18] {'memory_bank_size': 2000, 'k_neighbors': 5, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5194 | AUPRO: 0.1057 | F1: 0.5490\n",
      "\n",
      "[11/18] {'memory_bank_size': 2000, 'k_neighbors': 9, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5972 | AUPRO: 0.1077 | F1: 0.7419\n",
      "\n",
      "[12/18] {'memory_bank_size': 2000, 'k_neighbors': 9, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5250 | AUPRO: 0.1116 | F1: 0.7761\n",
      "\n",
      "[13/18] {'memory_bank_size': 3000, 'k_neighbors': 3, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6556 | AUPRO: 0.1066 | F1: 0.7812\n",
      "\n",
      "[14/18] {'memory_bank_size': 3000, 'k_neighbors': 3, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.4972 | AUPRO: 0.1078 | F1: 0.3913\n",
      "\n",
      "[15/18] {'memory_bank_size': 3000, 'k_neighbors': 5, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6500 | AUPRO: 0.1079 | F1: 0.6786\n",
      "\n",
      "[16/18] {'memory_bank_size': 3000, 'k_neighbors': 5, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5500 | AUPRO: 0.1093 | F1: 0.6552\n",
      "\n",
      "[17/18] {'memory_bank_size': 3000, 'k_neighbors': 9, 'use_multi_layer': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6083 | AUPRO: 0.1071 | F1: 0.7879\n",
      "\n",
      "[18/18] {'memory_bank_size': 3000, 'k_neighbors': 9, 'use_multi_layer': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6250 | AUPRO: 0.1181 | F1: 0.7333\n",
      "\n",
      "ðŸ”¬ Grid Search: SimpleNet\n",
      "   Parameters: ['noise_std', 'adaptor_dim', 'use_multi_noise']\n",
      "   Combinations: 12\n",
      "\n",
      "[1/12] {'noise_std': 0.01, 'adaptor_dim': 256, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.4583 | AUPRO: 0.0667 | F1: 0.9000\n",
      "\n",
      "[2/12] {'noise_std': 0.01, 'adaptor_dim': 256, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5222 | AUPRO: 0.0883 | F1: 0.8169\n",
      "\n",
      "[3/12] {'noise_std': 0.01, 'adaptor_dim': 512, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6639 | AUPRO: 0.0724 | F1: 0.6296\n",
      "\n",
      "[4/12] {'noise_std': 0.01, 'adaptor_dim': 512, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5056 | AUPRO: 0.0950 | F1: 0.6316\n",
      "\n",
      "[5/12] {'noise_std': 0.015, 'adaptor_dim': 256, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5694 | AUPRO: 0.0897 | F1: 0.7879\n",
      "\n",
      "[6/12] {'noise_std': 0.015, 'adaptor_dim': 256, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5417 | AUPRO: 0.0864 | F1: 0.3636\n",
      "\n",
      "[7/12] {'noise_std': 0.015, 'adaptor_dim': 512, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6278 | AUPRO: 0.0874 | F1: 0.7333\n",
      "\n",
      "[8/12] {'noise_std': 0.015, 'adaptor_dim': 512, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.3361 | AUPRO: 0.0748 | F1: 0.8750\n",
      "\n",
      "[9/12] {'noise_std': 0.02, 'adaptor_dim': 256, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.4778 | AUPRO: 0.0868 | F1: 0.7302\n",
      "\n",
      "[10/12] {'noise_std': 0.02, 'adaptor_dim': 256, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.6361 | AUPRO: 0.0951 | F1: 0.8235\n",
      "\n",
      "[11/12] {'noise_std': 0.02, 'adaptor_dim': 512, 'use_multi_noise': True}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5722 | AUPRO: 0.0895 | F1: 0.6429\n",
      "\n",
      "[12/12] {'noise_std': 0.02, 'adaptor_dim': 512, 'use_multi_noise': False}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "   AUC: 0.5139 | AUPRO: 0.0751 | F1: 0.7097\n",
      "\n",
      "ðŸ”¬ Grid Search: EfficientAD\n",
      "   Parameters: ['student_dim', 'autoencoder_dim', 'backbone']\n",
      "   Combinations: 9\n",
      "\n",
      "[1/9] {'student_dim': 256, 'autoencoder_dim': 256, 'backbone': 'resnet18'}\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 155MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Configuration Classes\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class BaseConfig:\n",
    "    \"\"\"Base configuration\"\"\"\n",
    "    environment: str = \"colab\"\n",
    "    dataset_name: str = \"baseline_256\"\n",
    "    image_size: Tuple[int, int] = (256, 256)  # Dataset Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ ile eÅŸleÅŸmeli\n",
    "    batch_size: int = 8\n",
    "    augmentation_type: str = \"enhanced\"\n",
    "    early_stopping_patience: int = 10\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AutoEncoderConfig:\n",
    "    \"\"\"AutoEncoder experiment configuration\"\"\"\n",
    "    latent_dim: int = 256\n",
    "    learning_rate: float = 1e-3\n",
    "    epochs: int = 100\n",
    "    use_ssim: bool = True\n",
    "    ssim_weight: float = 0.5\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatchCoreConfig:\n",
    "    \"\"\"PatchCore experiment configuration\"\"\"\n",
    "    backbone: str = \"wide_resnet50_2\"\n",
    "    memory_bank_size: int = 2000\n",
    "    target_dim: int = 512\n",
    "    k_neighbors: int = 5\n",
    "    use_multi_layer: bool = True\n",
    "    aggregate_neighbors: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimpleNetConfig:\n",
    "    \"\"\"SimpleNet experiment configuration\"\"\"\n",
    "    backbone: str = \"wide_resnet50_2\"\n",
    "    adaptor_dim: int = 512\n",
    "    noise_std: float = 0.015\n",
    "    learning_rate: float = 1e-4\n",
    "    epochs: int = 50\n",
    "    use_multi_noise: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EfficientADConfig:\n",
    "    \"\"\"EfficientAD experiment configuration\"\"\"\n",
    "    backbone: str = \"resnet18\"  # Lightweight backbone for speed\n",
    "    student_dim: int = 384\n",
    "    autoencoder_dim: int = 384\n",
    "    learning_rate: float = 1e-4\n",
    "    epochs: int = 70\n",
    "    weight_decay: float = 1e-5\n",
    "    teacher_momentum: float = 0.999\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Complete experiment configuration\"\"\"\n",
    "    experiment_name: str = \"default\"\n",
    "    base: BaseConfig = field(default_factory=BaseConfig)\n",
    "    autoencoder: AutoEncoderConfig = field(default_factory=AutoEncoderConfig)\n",
    "    patchcore: PatchCoreConfig = field(default_factory=PatchCoreConfig)\n",
    "    simplenet: SimpleNetConfig = field(default_factory=SimpleNetConfig)\n",
    "    efficientad: EfficientADConfig = field(default_factory=EfficientADConfig)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'experiment_name': self.experiment_name,\n",
    "            'base': asdict(self.base),\n",
    "            'autoencoder': asdict(self.autoencoder),\n",
    "            'patchcore': asdict(self.patchcore),\n",
    "            'simplenet': asdict(self.simplenet),\n",
    "            'efficientad': asdict(self.efficientad)\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, d: dict) -> 'ExperimentConfig':\n",
    "        return cls(\n",
    "            experiment_name=d.get('experiment_name', 'default'),\n",
    "            base=BaseConfig(**d.get('base', {})),\n",
    "            autoencoder=AutoEncoderConfig(**d.get('autoencoder', {})),\n",
    "            patchcore=PatchCoreConfig(**d.get('patchcore', {})),\n",
    "            simplenet=SimpleNetConfig(**d.get('simplenet', {})),\n",
    "            efficientad=EfficientADConfig(**d.get('efficientad', {}))\n",
    "        )\n",
    "\n",
    "\n",
    "def get_paths(config: BaseConfig) -> dict:\n",
    "    \"\"\"Get dataset paths based on environment\"\"\"\n",
    "    if config.environment == \"colab\":\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        base_path = \"/content/drive/MyDrive/Kod/machine_learning/dataset\"\n",
    "        project_root = \"/content/drive/MyDrive/Kod/machine_learning\"\n",
    "    else:\n",
    "        project_root = os.getcwd()\n",
    "        base_path = os.path.join(project_root, \"dataset\")\n",
    "\n",
    "    dataset_path = os.path.join(base_path, config.dataset_name)\n",
    "\n",
    "    return {\n",
    "        \"train_good\": os.path.join(dataset_path, \"train\", \"good\"),\n",
    "        \"test_good\": os.path.join(dataset_path, \"test\", \"good\"),\n",
    "        \"test_defect\": os.path.join(dataset_path, \"test\", \"defect\"),\n",
    "        \"results\": os.path.join(project_root, \"results\")\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SSIM Loss\n",
    "# ============================================================================\n",
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    \"\"\"Structural Similarity Index Loss\"\"\"\n",
    "\n",
    "    def __init__(self, window_size: int = 11, sigma: float = 1.5):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.sigma = sigma\n",
    "        self.channel = 3\n",
    "        self.window = self._create_window(window_size, sigma, 3)\n",
    "\n",
    "    def _create_window(self, window_size: int, sigma: float, channel: int):\n",
    "        coords = torch.arange(window_size).float() - window_size // 2\n",
    "        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
    "        g = g / g.sum()\n",
    "        window = g.unsqueeze(1) @ g.unsqueeze(0)\n",
    "        window = window.unsqueeze(0).unsqueeze(0)\n",
    "        window = window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "        return window\n",
    "\n",
    "    def forward(self, img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:\n",
    "        channel = img1.size(1)\n",
    "        if self.window.device != img1.device:\n",
    "            self.window = self.window.to(img1.device)\n",
    "        if channel != self.channel:\n",
    "            self.window = self._create_window(self.window_size, self.sigma, channel)\n",
    "            self.window = self.window.to(img1.device)\n",
    "            self.channel = channel\n",
    "\n",
    "        mu1 = F.conv2d(img1, self.window, padding=self.window_size//2, groups=channel)\n",
    "        mu2 = F.conv2d(img2, self.window, padding=self.window_size//2, groups=channel)\n",
    "        mu1_sq, mu2_sq, mu1_mu2 = mu1 ** 2, mu2 ** 2, mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(img1 * img1, self.window, padding=self.window_size//2, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, self.window, padding=self.window_size//2, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, self.window, padding=self.window_size//2, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1, C2 = 0.01 ** 2, 0.03 ** 2\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return 1 - ssim_map.mean()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Dataset\n",
    "# ============================================================================\n",
    "\n",
    "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "\n",
    "class WoodDataset(Dataset):\n",
    "    \"\"\"Wood anomaly detection dataset\"\"\"\n",
    "\n",
    "    def __init__(self, good_path: str, defect_path: Optional[str] = None,\n",
    "                 image_size: Tuple[int, int] = (256, 256), augmentation_type: str = \"none\"):\n",
    "        self.image_size = image_size\n",
    "        self.augmentation_type = augmentation_type\n",
    "        self.transform = self._build_transform()\n",
    "        self.paths, self.labels = [], []\n",
    "\n",
    "        if good_path and os.path.exists(good_path):\n",
    "            for f in Path(good_path).iterdir():\n",
    "                if f.suffix.lower() in IMG_EXTS:\n",
    "                    self.paths.append(str(f))\n",
    "                    self.labels.append(0)\n",
    "\n",
    "        if defect_path and os.path.exists(defect_path):\n",
    "            for f in Path(defect_path).iterdir():\n",
    "                if f.suffix.lower() in IMG_EXTS:\n",
    "                    self.paths.append(str(f))\n",
    "                    self.labels.append(1)\n",
    "\n",
    "    def _build_transform(self):\n",
    "        transforms_list = [transforms.ToPILImage(), transforms.Resize(self.image_size)]\n",
    "\n",
    "        if self.augmentation_type == \"basic\":\n",
    "            transforms_list.append(transforms.RandomRotation(degrees=15))\n",
    "        elif self.augmentation_type == \"enhanced\":\n",
    "            transforms_list.extend([\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.3),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05)\n",
    "            ])\n",
    "\n",
    "        transforms_list.extend([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return transforms.Compose(transforms_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read: {img_path}\")\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        return self.transform(img), label, img_path\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Models (Simplified for experiments)\n",
    "# ============================================================================\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 256, input_size: int = 256):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            self._conv(3, 32), self._conv(32, 64), self._conv(64, 128),\n",
    "            self._conv(128, 256), self._conv(256, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            self._deconv(latent_dim, 256), self._deconv(256, 128),\n",
    "            self._deconv(128, 64), self._deconv(64, 32),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _conv(self, i, o):\n",
    "        return nn.Sequential(nn.Conv2d(i, o, 4, 2, 1), nn.BatchNorm2d(o), nn.LeakyReLU(0.2, True))\n",
    "\n",
    "    def _deconv(self, i, o):\n",
    "        return nn.Sequential(nn.ConvTranspose2d(i, o, 4, 2, 1), nn.BatchNorm2d(o), nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "class AutoEncoderModel:\n",
    "    def __init__(self, config: AutoEncoderConfig, base_config: BaseConfig, device: str = None):\n",
    "        self.config = config\n",
    "        self.base_config = base_config\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.model = ConvAutoEncoder(config.latent_dim, base_config.image_size[0]).to(self.device)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=config.epochs)\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.ssim_loss = SSIMLoss() if config.use_ssim else None\n",
    "\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(self.device)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(self.device)\n",
    "\n",
    "    def _denorm(self, x):\n",
    "        return torch.clamp(x * self.std + self.mean, 0, 1)\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, verbose: bool = True):\n",
    "        self.model.train()\n",
    "        best_loss, patience = float('inf'), 0\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            total_loss = 0\n",
    "            for batch, _, _ in train_loader:\n",
    "                batch = self._denorm(batch.to(self.device))\n",
    "                self.optimizer.zero_grad()\n",
    "                recon = self.model(batch)\n",
    "                mse = self.mse_loss(recon, batch).mean()\n",
    "                loss = mse if not self.ssim_loss else (1 - self.config.ssim_weight) * mse + self.config.ssim_weight * self.ssim_loss(recon, batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            self.scheduler.step()\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss, patience = avg_loss, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            if patience >= self.base_config.early_stopping_patience:\n",
    "                if verbose: print(f\"  Early stop at {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader: DataLoader) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "        self.model.eval()\n",
    "        all_scores, all_maps, all_labels, all_paths = [], [], [], []\n",
    "\n",
    "        for batch, labels, paths in test_loader:\n",
    "            batch = self._denorm(batch.to(self.device))\n",
    "            recon = self.model(batch)\n",
    "            error = (recon - batch) ** 2\n",
    "\n",
    "            for i in range(error.shape[0]):\n",
    "                all_scores.append(error[i].mean().cpu().numpy())\n",
    "                amap = error[i].mean(dim=0).cpu().numpy()\n",
    "                all_maps.append(cv2.resize(amap, (256, 256)))\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "        scores = np.array(all_scores)\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min() + 1e-8), np.array(all_maps), np.array(all_labels), all_paths\n",
    "\n",
    "\n",
    "class PatchCoreModel:\n",
    "    def __init__(self, config: PatchCoreConfig, base_config: BaseConfig, device: str = None):\n",
    "        self.config = config\n",
    "        self.base_config = base_config\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.memory_bank = None\n",
    "        self.random_projection = None\n",
    "        self.nn_model = None\n",
    "        self.feature_map_size = None\n",
    "\n",
    "        self._build_extractor()\n",
    "\n",
    "    def _build_extractor(self):\n",
    "        if self.config.backbone == 'wide_resnet50_2':\n",
    "            backbone = models.wide_resnet50_2(weights='IMAGENET1K_V1')\n",
    "        else:\n",
    "            backbone = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n",
    "            backbone.layer1, backbone.layer2, backbone.layer3\n",
    "        ).to(self.device).eval()\n",
    "\n",
    "        for p in self.feature_extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        if self.config.use_multi_layer:\n",
    "            self.base_layers = nn.Sequential(\n",
    "                backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool, backbone.layer1\n",
    "            ).to(self.device).eval()\n",
    "            self.layer2 = backbone.layer2.to(self.device).eval()\n",
    "            self.layer3 = backbone.layer3.to(self.device).eval()\n",
    "            for p in list(self.base_layers.parameters()) + list(self.layer2.parameters()) + list(self.layer3.parameters()):\n",
    "                p.requires_grad = False\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _extract_features(self, loader):\n",
    "        all_feats = []\n",
    "        for batch, _, _ in loader:\n",
    "            batch = batch.to(self.device)\n",
    "            if self.config.use_multi_layer:\n",
    "                base = self.base_layers(batch)\n",
    "                l2 = self.layer2(base)\n",
    "                l3 = self.layer3(l2)  # FIXED: was self.layer3(self.layer2(base))\n",
    "                l2_resized = F.interpolate(l2, size=l3.shape[2:], mode='bilinear', align_corners=False)\n",
    "                feats = torch.cat([l2_resized, l3], dim=1)\n",
    "            else:\n",
    "                feats = self.feature_extractor(batch)\n",
    "\n",
    "            # L2 normalize features (important for PatchCore)\n",
    "            feats = F.normalize(feats, p=2, dim=1)\n",
    "\n",
    "            if self.feature_map_size is None:\n",
    "                self.feature_map_size = (feats.shape[2], feats.shape[3])\n",
    "\n",
    "            b, c, h, w = feats.shape\n",
    "            all_feats.append(feats.permute(0, 2, 3, 1).reshape(b, -1, c).cpu().numpy())\n",
    "\n",
    "        return np.concatenate(all_feats, axis=0).reshape(-1, all_feats[0].shape[-1])\n",
    "\n",
    "    def _coreset_sample(self, feats, k):\n",
    "        if len(feats) <= k:\n",
    "            return feats\n",
    "\n",
    "        indices = [np.random.randint(len(feats))]\n",
    "        min_dists = np.full(len(feats), np.inf)\n",
    "\n",
    "        for _ in range(1, k):\n",
    "            dists = np.linalg.norm(feats - feats[indices[-1]], axis=1)\n",
    "            min_dists = np.minimum(min_dists, dists)\n",
    "            min_dists[indices] = -1\n",
    "            indices.append(np.argmax(min_dists))\n",
    "\n",
    "        return feats[indices]\n",
    "\n",
    "    def fit(self, train_loader, verbose=True):\n",
    "        feats = self._extract_features(train_loader)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"    Total patches extracted: {len(feats)}\")\n",
    "\n",
    "        if feats.shape[1] > self.config.target_dim:\n",
    "            self.random_projection = SparseRandomProjection(n_components=self.config.target_dim, random_state=42)\n",
    "            feats = self.random_projection.fit_transform(feats)\n",
    "\n",
    "        # memory_bank_size = -1 means use all patches (no coreset sampling)\n",
    "        if self.config.memory_bank_size == -1 or len(feats) <= self.config.memory_bank_size:\n",
    "            self.memory_bank = feats\n",
    "            if verbose:\n",
    "                print(f\"    Using all {len(feats)} patches in memory bank\")\n",
    "        else:\n",
    "            self.memory_bank = self._coreset_sample(feats, self.config.memory_bank_size)\n",
    "            if verbose:\n",
    "                print(f\"    Coreset sampled to {len(self.memory_bank)} patches\")\n",
    "\n",
    "        self.nn_model = NearestNeighbors(n_neighbors=self.config.k_neighbors, algorithm='auto', metric='euclidean', n_jobs=-1)\n",
    "        self.nn_model.fit(self.memory_bank)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "        all_scores, all_maps, all_labels, all_paths = [], [], [], []\n",
    "\n",
    "        for batch, labels, paths in test_loader:\n",
    "            batch = batch.to(self.device)\n",
    "            if self.config.use_multi_layer:\n",
    "                base = self.base_layers(batch)\n",
    "                l2 = self.layer2(base)\n",
    "                l3 = self.layer3(l2)  # FIXED: was self.layer3(self.layer2(base))\n",
    "                l2_resized = F.interpolate(l2, size=l3.shape[2:], mode='bilinear', align_corners=False)\n",
    "                feats = torch.cat([l2_resized, l3], dim=1)\n",
    "            else:\n",
    "                feats = self.feature_extractor(batch)\n",
    "\n",
    "            # L2 normalize features (same as training)\n",
    "            feats = F.normalize(feats, p=2, dim=1)\n",
    "\n",
    "            b, c, h, w = feats.shape\n",
    "            feats_flat = feats.permute(0, 2, 3, 1).reshape(-1, c).cpu().numpy()\n",
    "\n",
    "            if self.random_projection:\n",
    "                feats_flat = self.random_projection.transform(feats_flat)\n",
    "\n",
    "            dists, _ = self.nn_model.kneighbors(feats_flat)\n",
    "            dists = dists.mean(axis=1)\n",
    "\n",
    "            for i in range(b):\n",
    "                img_dists = dists[i * h * w:(i + 1) * h * w]\n",
    "                all_scores.append(np.max(img_dists))\n",
    "                all_maps.append(cv2.resize(img_dists.reshape(h, w), (256, 256)))\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "        scores = np.array(all_scores)\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min() + 1e-8), np.array(all_maps), np.array(all_labels), all_paths\n",
    "\n",
    "\n",
    "class SimpleNetModel:\n",
    "    def __init__(self, config: SimpleNetConfig, base_config: BaseConfig, device: str = None):\n",
    "        self.config = config\n",
    "        self.base_config = base_config\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.feature_map_size = None\n",
    "\n",
    "        if config.backbone == 'wide_resnet50_2':\n",
    "            backbone = models.wide_resnet50_2(weights='IMAGENET1K_V1')\n",
    "            feat_dim = 1024\n",
    "        else:\n",
    "            backbone = models.resnet18(weights='IMAGENET1K_V1')\n",
    "            feat_dim = 256\n",
    "\n",
    "        self.extractor = nn.Sequential(\n",
    "            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n",
    "            backbone.layer1, backbone.layer2, backbone.layer3\n",
    "        ).to(self.device).eval()\n",
    "\n",
    "        for p in self.extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.adaptor = nn.Sequential(nn.Linear(feat_dim, config.adaptor_dim, bias=False), nn.LayerNorm(config.adaptor_dim)).to(self.device)\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(config.adaptor_dim, 256), nn.BatchNorm1d(256), nn.LeakyReLU(0.2), nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.LeakyReLU(0.2), nn.Linear(128, 1)\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _gen_anomaly(self, feats):\n",
    "        if self.config.use_multi_noise:\n",
    "            stds = [self.config.noise_std * m for m in [0.5, 1.0, 2.0]]\n",
    "            bs = feats.shape[0] // 3\n",
    "            parts = [feats[i*bs:(i+1)*bs if i < 2 else feats.shape[0]] + torch.randn_like(feats[i*bs:(i+1)*bs if i < 2 else feats.shape[0]]) * s for i, s in enumerate(stds)]\n",
    "            return torch.cat(parts, dim=0)\n",
    "        return feats + torch.randn_like(feats) * self.config.noise_std\n",
    "\n",
    "    def _focal_loss(self, pred, target, gamma=2.0, alpha=0.25):\n",
    "        bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        return (alpha * (1 - pt) ** gamma * bce).mean()\n",
    "\n",
    "    def fit(self, train_loader, verbose=True):\n",
    "        opt = AdamW(list(self.adaptor.parameters()) + list(self.disc.parameters()), lr=self.config.learning_rate, weight_decay=1e-4)\n",
    "        sched = CosineAnnealingLR(opt, T_max=self.config.epochs)\n",
    "\n",
    "        self.adaptor.train()\n",
    "        self.disc.train()\n",
    "        best_loss, patience = float('inf'), 0\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            total_loss = 0\n",
    "            for batch, _, _ in train_loader:\n",
    "                batch = batch.to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    feats = self.extractor(batch)\n",
    "                    if self.feature_map_size is None:\n",
    "                        self.feature_map_size = (feats.shape[2], feats.shape[3])\n",
    "\n",
    "                b, c, h, w = feats.shape\n",
    "                flat = feats.permute(0, 2, 3, 1).reshape(-1, c)\n",
    "                adapted = self.adaptor(flat)\n",
    "                anomaly = self._gen_anomaly(adapted.detach())\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss = self._focal_loss(self.disc(adapted), torch.zeros(adapted.size(0), 1, device=self.device)) + \\\n",
    "                       self._focal_loss(self.disc(anomaly), torch.ones(anomaly.size(0), 1, device=self.device))\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            sched.step()\n",
    "            if total_loss / len(train_loader) < best_loss:\n",
    "                best_loss, patience = total_loss / len(train_loader), 0\n",
    "            else:\n",
    "                patience += 1\n",
    "            if patience >= self.base_config.early_stopping_patience:\n",
    "                break\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "        self.adaptor.eval()\n",
    "        self.disc.eval()\n",
    "        all_scores, all_maps, all_labels, all_paths = [], [], [], []\n",
    "\n",
    "        for batch, labels, paths in test_loader:\n",
    "            batch = batch.to(self.device)\n",
    "            feats = self.extractor(batch)\n",
    "            b, c, h, w = feats.shape\n",
    "            flat = feats.permute(0, 2, 3, 1).reshape(-1, c)\n",
    "            scores = torch.sigmoid(self.disc(self.adaptor(flat))).squeeze().cpu().numpy()\n",
    "\n",
    "            for i in range(b):\n",
    "                img_scores = scores[i * h * w:(i + 1) * h * w]\n",
    "                all_scores.append(np.max(img_scores))\n",
    "                all_maps.append(cv2.resize(img_scores.reshape(h, w), (256, 256)))\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "        scores = np.array(all_scores)\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min() + 1e-8), np.array(all_maps), np.array(all_labels), all_paths\n",
    "\n",
    "\n",
    "class EfficientADModel:\n",
    "    \"\"\"\n",
    "    EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level Latencies\n",
    "\n",
    "    Uses a Student-Teacher architecture with a lightweight autoencoder for\n",
    "    detecting both structural and logical anomalies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: EfficientADConfig, base_config: BaseConfig, device: str = None):\n",
    "        self.config = config\n",
    "        self.base_config = base_config\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.feature_map_size = None\n",
    "\n",
    "        # Build teacher and student networks\n",
    "        self._build_networks()\n",
    "\n",
    "    def _build_networks(self):\n",
    "        \"\"\"Build PDN (Patch Description Network) teacher, student, and autoencoder\"\"\"\n",
    "        # Use ResNet18 as lightweight backbone\n",
    "        if self.config.backbone == 'resnet18':\n",
    "            backbone = models.resnet18(weights='IMAGENET1K_V1')\n",
    "            feat_dim = 256\n",
    "        else:\n",
    "            backbone = models.wide_resnet50_2(weights='IMAGENET1K_V1')\n",
    "            feat_dim = 1024\n",
    "\n",
    "        # Teacher feature extractor (frozen)\n",
    "        self.teacher = nn.Sequential(\n",
    "            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n",
    "            backbone.layer1, backbone.layer2, backbone.layer3\n",
    "        ).to(self.device).eval()\n",
    "\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Student network (learnable) - same architecture as teacher\n",
    "        student_backbone = models.resnet18(weights=None) if self.config.backbone == 'resnet18' else models.wide_resnet50_2(weights=None)\n",
    "        self.student = nn.Sequential(\n",
    "            student_backbone.conv1, student_backbone.bn1, student_backbone.relu, student_backbone.maxpool,\n",
    "            student_backbone.layer1, student_backbone.layer2, student_backbone.layer3\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Lightweight autoencoder for local anomaly detection\n",
    "        self.autoencoder = nn.Sequential(\n",
    "            # Encoder\n",
    "            nn.Conv2d(feat_dim, self.config.autoencoder_dim, 3, 2, 1),\n",
    "            nn.BatchNorm2d(self.config.autoencoder_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(self.config.autoencoder_dim, self.config.autoencoder_dim // 2, 3, 2, 1),\n",
    "            nn.BatchNorm2d(self.config.autoencoder_dim // 2),\n",
    "            nn.ReLU(True),\n",
    "            # Decoder\n",
    "            nn.ConvTranspose2d(self.config.autoencoder_dim // 2, self.config.autoencoder_dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.config.autoencoder_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(self.config.autoencoder_dim, feat_dim, 4, 2, 1),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Projection heads for student to match teacher dimensions\n",
    "        self.student_head = nn.Sequential(\n",
    "            nn.Conv2d(feat_dim, self.config.student_dim, 1),\n",
    "            nn.BatchNorm2d(self.config.student_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(self.config.student_dim, feat_dim, 1)\n",
    "        ).to(self.device)\n",
    "\n",
    "    def fit(self, train_loader, verbose=True):\n",
    "        \"\"\"Train student and autoencoder on normal samples\"\"\"\n",
    "        params = list(self.student.parameters()) + list(self.autoencoder.parameters()) + list(self.student_head.parameters())\n",
    "        optimizer = AdamW(params, lr=self.config.learning_rate, weight_decay=self.config.weight_decay)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.config.epochs)\n",
    "\n",
    "        self.student.train()\n",
    "        self.autoencoder.train()\n",
    "        self.student_head.train()\n",
    "\n",
    "        best_loss, patience = float('inf'), 0\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            total_loss = 0\n",
    "            for batch, _, _ in train_loader:\n",
    "                batch = batch.to(self.device)\n",
    "\n",
    "                # Get teacher features (frozen)\n",
    "                with torch.no_grad():\n",
    "                    teacher_feats = self.teacher(batch)\n",
    "                    if self.feature_map_size is None:\n",
    "                        self.feature_map_size = (teacher_feats.shape[2], teacher_feats.shape[3])\n",
    "\n",
    "                # Get student features\n",
    "                student_feats = self.student(batch)\n",
    "                student_feats = self.student_head(student_feats)\n",
    "\n",
    "                # Autoencoder reconstruction\n",
    "                ae_input = teacher_feats.detach()\n",
    "                ae_output = self.autoencoder(ae_input)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Student-Teacher distillation loss\n",
    "                st_loss = F.mse_loss(student_feats, teacher_feats.detach())\n",
    "\n",
    "                # Autoencoder reconstruction loss\n",
    "                ae_loss = F.mse_loss(ae_output, ae_input)\n",
    "\n",
    "                # Combined loss\n",
    "                loss = st_loss + ae_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss, patience = avg_loss, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            if patience >= self.base_config.early_stopping_patience:\n",
    "                if verbose:\n",
    "                    print(f\"  Early stop at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, test_loader) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "        \"\"\"Predict anomaly scores using combined ST and AE differences\"\"\"\n",
    "        self.student.eval()\n",
    "        self.autoencoder.eval()\n",
    "        self.student_head.eval()\n",
    "\n",
    "        all_scores, all_maps, all_labels, all_paths = [], [], [], []\n",
    "\n",
    "        for batch, labels, paths in test_loader:\n",
    "            batch = batch.to(self.device)\n",
    "\n",
    "            # Teacher features\n",
    "            teacher_feats = self.teacher(batch)\n",
    "\n",
    "            # Student features\n",
    "            student_feats = self.student_head(self.student(batch))\n",
    "\n",
    "            # Autoencoder output\n",
    "            ae_output = self.autoencoder(teacher_feats)\n",
    "\n",
    "            # Calculate anomaly maps\n",
    "            # ST difference: where student fails to match teacher\n",
    "            st_diff = (teacher_feats - student_feats) ** 2\n",
    "            st_diff = st_diff.mean(dim=1)  # Average over channels\n",
    "\n",
    "            # AE difference: reconstruction error\n",
    "            ae_diff = (teacher_feats - ae_output) ** 2\n",
    "            ae_diff = ae_diff.mean(dim=1)\n",
    "\n",
    "            # Combined anomaly map (weighted sum)\n",
    "            anomaly_map = 0.5 * st_diff + 0.5 * ae_diff\n",
    "\n",
    "            b = batch.shape[0]\n",
    "            for i in range(b):\n",
    "                amap = anomaly_map[i].cpu().numpy()\n",
    "                all_scores.append(np.max(amap))\n",
    "                all_maps.append(cv2.resize(amap, (256, 256)))\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "        scores = np.array(all_scores)\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min() + 1e-8), np.array(all_maps), np.array(all_labels), all_paths\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Evaluation Functions\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_aupro_approximated(anomaly_maps: np.ndarray, labels: np.ndarray,\n",
    "                                  num_thresholds: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Calculate approximated AUPRO (Area Under Per-Region-Overlap curve).\n",
    "\n",
    "    Since we don't have ground truth masks, this uses a threshold-based approach\n",
    "    to estimate region overlap. For defect images, we assume high anomaly regions\n",
    "    correspond to actual defects, and measure consistency across thresholds.\n",
    "\n",
    "    Args:\n",
    "        anomaly_maps: Anomaly heatmaps for each image (N, H, W)\n",
    "        labels: Ground truth labels (0=good, 1=defect)\n",
    "        num_thresholds: Number of thresholds to evaluate\n",
    "\n",
    "    Returns:\n",
    "        Approximated AUPRO score (0-1)\n",
    "    \"\"\"\n",
    "    if len(anomaly_maps) == 0 or np.sum(labels == 1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Normalize all maps to [0, 1]\n",
    "    all_maps_flat = anomaly_maps.reshape(-1)\n",
    "    global_min, global_max = all_maps_flat.min(), all_maps_flat.max()\n",
    "    if global_max - global_min < 1e-8:\n",
    "        return 0.5\n",
    "\n",
    "    normalized_maps = (anomaly_maps - global_min) / (global_max - global_min + 1e-8)\n",
    "\n",
    "    # Get defect and good maps separately\n",
    "    defect_maps = normalized_maps[labels == 1]\n",
    "    good_maps = normalized_maps[labels == 0]\n",
    "\n",
    "    # Calculate PRO-like metric across thresholds\n",
    "    thresholds = np.linspace(0, 1, num_thresholds)\n",
    "    pro_scores = []\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        # For defects: ratio of pixels above threshold (should be high for good detection)\n",
    "        defect_coverage = np.mean([np.mean(m > thresh) for m in defect_maps]) if len(defect_maps) > 0 else 0\n",
    "\n",
    "        # For good images: ratio of pixels above threshold (should be low - false positives)\n",
    "        good_fp_rate = np.mean([np.mean(m > thresh) for m in good_maps]) if len(good_maps) > 0 else 0\n",
    "\n",
    "        # PRO score: balance between catching defects and avoiding false positives\n",
    "        if defect_coverage + (1 - good_fp_rate) > 0:\n",
    "            pro_score = 2 * defect_coverage * (1 - good_fp_rate) / (defect_coverage + (1 - good_fp_rate) + 1e-8)\n",
    "        else:\n",
    "            pro_score = 0\n",
    "\n",
    "        pro_scores.append(pro_score)\n",
    "\n",
    "    # Area under the PRO curve\n",
    "    aupro = np.trapz(pro_scores, thresholds)\n",
    "    return float(np.clip(aupro, 0, 1))\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_scores, threshold=0.5, anomaly_maps=None):\n",
    "    \"\"\"Calculate all metrics including AUPRO\"\"\"\n",
    "    y_pred = (y_scores >= threshold).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        'auc_roc': roc_auc_score(y_true, y_scores),\n",
    "        'f1_score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "    # Calculate AUPRO if anomaly maps are provided\n",
    "    if anomaly_maps is not None:\n",
    "        metrics['aupro'] = calculate_aupro_approximated(anomaly_maps, y_true)\n",
    "    else:\n",
    "        metrics['aupro'] = 0.0\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    return thresholds[np.argmax(tpr - fpr)]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Heatmap Generation (Fixed)\n",
    "# ============================================================================\n",
    "\n",
    "def save_heatmaps(model_name: str, scores: np.ndarray, maps: np.ndarray,\n",
    "                  labels: np.ndarray, paths: List[str], threshold: float,\n",
    "                  output_dir: str):\n",
    "    \"\"\"Save anomaly heatmaps for each test image\"\"\"\n",
    "    good_dir = os.path.join(output_dir, \"heatmaps\", model_name, \"good\")\n",
    "    defect_dir = os.path.join(output_dir, \"heatmaps\", model_name, \"defect\")\n",
    "    os.makedirs(good_dir, exist_ok=True)\n",
    "    os.makedirs(defect_dir, exist_ok=True)\n",
    "\n",
    "    for i, (anomaly_map, score, label, img_path) in enumerate(zip(maps, scores, labels, paths)):\n",
    "        # Read original image\n",
    "        img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Ensure anomaly map is 2D and correct size\n",
    "        if len(anomaly_map.shape) > 2:\n",
    "            anomaly_map = anomaly_map.mean(axis=0) if anomaly_map.shape[0] <= 3 else anomaly_map[:, :, 0]\n",
    "        anomaly_map = cv2.resize(anomaly_map.astype(np.float32), (256, 256))\n",
    "\n",
    "        # Normalize\n",
    "        if anomaly_map.max() > anomaly_map.min():\n",
    "            anomaly_map_norm = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min())\n",
    "        else:\n",
    "            anomaly_map_norm = np.zeros_like(anomaly_map)\n",
    "\n",
    "        # Create heatmap\n",
    "        heatmap_uint8 = (anomaly_map_norm * 255).astype(np.uint8)\n",
    "        heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "        heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Overlay\n",
    "        overlay = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        im = axes[1].imshow(anomaly_map_norm, cmap='jet', vmin=0, vmax=1)\n",
    "        axes[1].set_title(f'Anomaly Map\\nScore: {score:.4f}')\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
    "\n",
    "        axes[2].imshow(overlay)\n",
    "        pred = \"DEFECT\" if score >= threshold else \"GOOD\"\n",
    "        true = \"DEFECT\" if label == 1 else \"GOOD\"\n",
    "        color = 'green' if pred == true else 'red'\n",
    "        axes[2].set_title(f'Overlay\\nPred: {pred} | True: {true}', color=color)\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        plt.suptitle(f'{model_name} - {os.path.basename(img_path)}', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save\n",
    "        save_dir = defect_dir if label == 1 else good_dir\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        plt.savefig(os.path.join(save_dir, f\"{base_name}_score_{score:.4f}.png\"), dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Experiment Runner\n",
    "# ============================================================================\n",
    "\n",
    "class ExperimentRunner:\n",
    "    \"\"\"Runs experiments and collects results\"\"\"\n",
    "\n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = output_dir\n",
    "        self.results = []\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def run_single(self, config: ExperimentConfig, model_type: str,\n",
    "                   use_augmentation: bool = True, verbose: bool = True) -> dict:\n",
    "        \"\"\"Run single experiment\"\"\"\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        paths = get_paths(config.base)\n",
    "\n",
    "        # Create datasets\n",
    "        aug_type = config.base.augmentation_type if use_augmentation else \"none\"\n",
    "        train_ds = WoodDataset(paths[\"train_good\"], None, config.base.image_size, aug_type)\n",
    "        test_ds = WoodDataset(paths[\"test_good\"], paths[\"test_defect\"], config.base.image_size, \"none\")\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=config.base.batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(test_ds, batch_size=config.base.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        # Create and train model\n",
    "        if model_type == \"AutoEncoder\":\n",
    "            model = AutoEncoderModel(config.autoencoder, config.base, device)\n",
    "        elif model_type == \"PatchCore\":\n",
    "            model = PatchCoreModel(config.patchcore, config.base, device)\n",
    "        elif model_type == \"SimpleNet\":\n",
    "            model = SimpleNetModel(config.simplenet, config.base, device)\n",
    "        elif model_type == \"EfficientAD\":\n",
    "            model = EfficientADModel(config.efficientad, config.base, device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_type}\")\n",
    "\n",
    "        model.fit(train_loader, verbose=verbose)\n",
    "        scores, maps, labels, img_paths = model.predict(test_loader)\n",
    "\n",
    "        threshold = find_optimal_threshold(labels, scores)\n",
    "        # Pass anomaly_maps to calculate_metrics for AUPRO calculation\n",
    "        metrics = calculate_metrics(labels, scores, threshold, anomaly_maps=maps)\n",
    "\n",
    "        result = {\n",
    "            'experiment_name': config.experiment_name,\n",
    "            'model': model_type,\n",
    "            'augmentation': use_augmentation,\n",
    "            **metrics,\n",
    "            'config': config.to_dict(),\n",
    "            'scores': scores,\n",
    "            'maps': maps,\n",
    "            'labels': labels,\n",
    "            'paths': img_paths\n",
    "        }\n",
    "\n",
    "        self.results.append(result)\n",
    "        return result\n",
    "\n",
    "    def run_grid_search(self, model_type: str, param_grid: Dict[str, List[Any]],\n",
    "                        base_config: ExperimentConfig, use_augmentation: bool = True,\n",
    "                        verbose: bool = True) -> List[dict]:\n",
    "        \"\"\"Run grid search over parameters\"\"\"\n",
    "        param_names = list(param_grid.keys())\n",
    "        param_values = list(param_grid.values())\n",
    "        combinations = list(product(*param_values))\n",
    "\n",
    "        print(f\"\\nðŸ”¬ Grid Search: {model_type}\")\n",
    "        print(f\"   Parameters: {param_names}\")\n",
    "        print(f\"   Combinations: {len(combinations)}\")\n",
    "\n",
    "        results = []\n",
    "        for i, combo in enumerate(combinations):\n",
    "            config = ExperimentConfig.from_dict(base_config.to_dict())\n",
    "            config.experiment_name = f\"{model_type}_exp_{i+1}\"\n",
    "\n",
    "            # Update config with grid parameters\n",
    "            for name, value in zip(param_names, combo):\n",
    "                if model_type == \"AutoEncoder\":\n",
    "                    setattr(config.autoencoder, name, value)\n",
    "                elif model_type == \"PatchCore\":\n",
    "                    setattr(config.patchcore, name, value)\n",
    "                elif model_type == \"SimpleNet\":\n",
    "                    setattr(config.simplenet, name, value)\n",
    "                elif model_type == \"EfficientAD\":\n",
    "                    setattr(config.efficientad, name, value)\n",
    "\n",
    "            print(f\"\\n[{i+1}/{len(combinations)}] {dict(zip(param_names, combo))}\")\n",
    "            result = self.run_single(config, model_type, use_augmentation, verbose=False)\n",
    "            results.append(result)\n",
    "            print(f\"   AUC: {result['auc_roc']:.4f} | AUPRO: {result['aupro']:.4f} | F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_results_table(self) -> pd.DataFrame:\n",
    "        \"\"\"Get results as DataFrame with all parameters\"\"\"\n",
    "        rows = []\n",
    "        for r in self.results:\n",
    "            config = r['config']\n",
    "            base_cfg = config['base']\n",
    "\n",
    "            row = {\n",
    "                'experiment': r['experiment_name'],\n",
    "                'model': r['model'],\n",
    "                'dataset': base_cfg['dataset_name'],\n",
    "                'augmentation': r['augmentation'],\n",
    "                'image_size': f\"{base_cfg['image_size'][0]}x{base_cfg['image_size'][1]}\",\n",
    "                'AUC_ROC': r['auc_roc'],\n",
    "                'AUPRO': r.get('aupro', 0.0),\n",
    "                'F1_Score': r['f1_score'],\n",
    "                'Accuracy': r['accuracy'],\n",
    "                'Precision': r['precision'],\n",
    "                'Recall': r['recall'],\n",
    "                'Threshold': r['threshold']\n",
    "            }\n",
    "\n",
    "            # Add model-specific parameters\n",
    "            if r['model'] == 'AutoEncoder':\n",
    "                ae_cfg = config['autoencoder']\n",
    "                row['latent_dim'] = ae_cfg['latent_dim']\n",
    "                row['ssim_weight'] = ae_cfg['ssim_weight']\n",
    "                row['epochs'] = ae_cfg['epochs']\n",
    "                row['learning_rate'] = ae_cfg['learning_rate']\n",
    "            elif r['model'] == 'PatchCore':\n",
    "                pc_cfg = config['patchcore']\n",
    "                row['memory_bank'] = pc_cfg['memory_bank_size']\n",
    "                row['k_neighbors'] = pc_cfg['k_neighbors']\n",
    "                row['multi_layer'] = pc_cfg['use_multi_layer']\n",
    "            elif r['model'] == 'SimpleNet':\n",
    "                sn_cfg = config['simplenet']\n",
    "                row['noise_std'] = sn_cfg['noise_std']\n",
    "                row['adaptor_dim'] = sn_cfg['adaptor_dim']\n",
    "                row['epochs'] = sn_cfg['epochs']\n",
    "                row['multi_noise'] = sn_cfg['use_multi_noise']\n",
    "            elif r['model'] == 'EfficientAD':\n",
    "                ead_cfg = config['efficientad']\n",
    "                row['backbone'] = ead_cfg['backbone']\n",
    "                row['student_dim'] = ead_cfg['student_dim']\n",
    "                row['autoencoder_dim'] = ead_cfg['autoencoder_dim']\n",
    "                row['epochs'] = ead_cfg['epochs']\n",
    "\n",
    "            rows.append(row)\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def save_results(self, filename: str = \"experiment_results.csv\"):\n",
    "        \"\"\"Save results to CSV\"\"\"\n",
    "        df = self.get_results_table()\n",
    "        df.to_csv(os.path.join(self.output_dir, filename), index=False)\n",
    "        print(f\"âœ“ Results saved: {filename}\")\n",
    "        return df\n",
    "\n",
    "    def get_best_result(self, metric: str = 'auc_roc') -> dict:\n",
    "        \"\"\"Get best result by metric\"\"\"\n",
    "        return max(self.results, key=lambda x: x[metric])\n",
    "\n",
    "    def plot_confusion_matrices(self):\n",
    "        \"\"\"Plot confusion matrices for all experiments\"\"\"\n",
    "        n_results = len(self.results)\n",
    "        if n_results == 0:\n",
    "            return\n",
    "\n",
    "        # Group by model type\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        # Plot best result per model\n",
    "        n_models = len(models)\n",
    "        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
    "        if n_models == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, (model_name, results) in enumerate(models.items()):\n",
    "            best = max(results, key=lambda x: x['auc_roc'])\n",
    "            y_true = best['labels']\n",
    "            y_pred = (best['scores'] >= best['threshold']).astype(int)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                       xticklabels=['Good', 'Defect'], yticklabels=['Good', 'Defect'])\n",
    "            axes[idx].set_xlabel('Predicted')\n",
    "            axes[idx].set_ylabel('True')\n",
    "            axes[idx].set_title(f'{model_name}\\nAUC: {best[\"auc_roc\"]:.3f} | F1: {best[\"f1_score\"]:.3f}')\n",
    "\n",
    "        plt.suptitle('Confusion Matrices (Best per Model)', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'confusion_matrices.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"âœ“ Confusion matrices saved\")\n",
    "\n",
    "    def plot_roc_curves(self):\n",
    "        \"\"\"Plot ROC curves for all experiments\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        # Group by model\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = {'AutoEncoder': 'blue', 'PatchCore': 'green', 'SimpleNet': 'red', 'EfficientAD': 'purple'}\n",
    "\n",
    "        for model_name, results in models.items():\n",
    "            best = max(results, key=lambda x: x['auc_roc'])\n",
    "            fpr, tpr, _ = roc_curve(best['labels'], best['scores'])\n",
    "            plt.plot(fpr, tpr, color=colors.get(model_name, 'gray'), linewidth=2,\n",
    "                    label=f'{model_name} (AUC={best[\"auc_roc\"]:.3f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title('ROC Curves (Best per Model)', fontsize=14, fontweight='bold')\n",
    "        plt.legend(loc='lower right', fontsize=10)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'roc_curves.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"âœ“ ROC curves saved\")\n",
    "\n",
    "    def plot_score_distributions(self):\n",
    "        \"\"\"Plot score distributions for best models\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        n_models = len(models)\n",
    "        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
    "        if n_models == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, (model_name, results) in enumerate(models.items()):\n",
    "            best = max(results, key=lambda x: x['auc_roc'])\n",
    "            scores = best['scores']\n",
    "            labels = best['labels']\n",
    "            threshold = best['threshold']\n",
    "\n",
    "            good_scores = scores[labels == 0]\n",
    "            defect_scores = scores[labels == 1]\n",
    "\n",
    "            axes[idx].hist(good_scores, bins=15, alpha=0.6, label='Good', color='green')\n",
    "            axes[idx].hist(defect_scores, bins=15, alpha=0.6, label='Defect', color='red')\n",
    "            axes[idx].axvline(threshold, color='black', linestyle='--', linewidth=2,\n",
    "                             label=f'Threshold={threshold:.3f}')\n",
    "            axes[idx].set_xlabel('Anomaly Score')\n",
    "            axes[idx].set_ylabel('Count')\n",
    "            axes[idx].set_title(f'{model_name}')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.suptitle('Score Distributions (Best per Model)', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'score_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"âœ“ Score distributions saved\")\n",
    "\n",
    "    def plot_metrics_comparison(self):\n",
    "        \"\"\"Plot metrics comparison bar chart\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        # Get best per model\n",
    "        best_results = {name: max(results, key=lambda x: x['auc_roc'])\n",
    "                       for name, results in models.items()}\n",
    "\n",
    "        metrics = ['auc_roc', 'aupro', 'f1_score', 'accuracy', 'precision', 'recall']\n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.20  # Narrower bars for 4 models\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        colors = {'AutoEncoder': 'steelblue', 'PatchCore': 'forestgreen', 'SimpleNet': 'indianred', 'EfficientAD': 'purple'}\n",
    "\n",
    "        for i, (model_name, result) in enumerate(best_results.items()):\n",
    "            values = [result.get(m, 0.0) for m in metrics]\n",
    "            ax.bar(x + i*width, values, width, label=model_name, color=colors.get(model_name, 'gray'))\n",
    "\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        ax.set_title('Metrics Comparison (Best per Model)', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(['AUC-ROC', 'AUPRO', 'F1 Score', 'Accuracy', 'Precision', 'Recall'])\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "        # Add value labels\n",
    "        for i, (model_name, result) in enumerate(best_results.items()):\n",
    "            values = [result.get(m, 0.0) for m in metrics]\n",
    "            for j, v in enumerate(values):\n",
    "                ax.text(x[j] + i*width, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'metrics_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"âœ“ Metrics comparison saved\")\n",
    "\n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"Generate a detailed summary report\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        # Find best overall and best per model\n",
    "        best_overall = self.get_best_result('auc_roc')\n",
    "        best_config = best_overall['config']\n",
    "\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        best_per_model = {name: max(results, key=lambda x: x['auc_roc'])\n",
    "                         for name, results in models.items()}\n",
    "\n",
    "        report = []\n",
    "        report.append(\"=\" * 80)\n",
    "        report.append(\"ðŸ“Š EXPERIMENT SUMMARY REPORT\")\n",
    "        report.append(\"=\" * 80)\n",
    "        report.append(f\"\\nTotal Experiments: {len(self.results)}\")\n",
    "        report.append(f\"Output Directory: {self.output_dir}\")\n",
    "        report.append(f\"Dataset: {best_config['base']['dataset_name']}\")\n",
    "        report.append(f\"Image Size: {best_config['base']['image_size']}\")\n",
    "\n",
    "        report.append(\"\\n\" + \"-\" * 40)\n",
    "        report.append(\"ðŸ† BEST OVERALL RESULT\")\n",
    "        report.append(\"-\" * 40)\n",
    "        report.append(f\"  Experiment: {best_overall['experiment_name']}\")\n",
    "        report.append(f\"  Model:      {best_overall['model']}\")\n",
    "        report.append(f\"  AUC-ROC:    {best_overall['auc_roc']:.4f}\")\n",
    "        report.append(f\"  AUPRO:      {best_overall.get('aupro', 0.0):.4f}\")\n",
    "        report.append(f\"  F1 Score:   {best_overall['f1_score']:.4f}\")\n",
    "        report.append(f\"  Accuracy:   {best_overall['accuracy']:.4f}\")\n",
    "        report.append(f\"  Precision:  {best_overall['precision']:.4f}\")\n",
    "        report.append(f\"  Recall:     {best_overall['recall']:.4f}\")\n",
    "        report.append(f\"  Threshold:  {best_overall['threshold']:.4f}\")\n",
    "\n",
    "        # Add best model parameters\n",
    "        report.append(\"\\n  Parameters:\")\n",
    "        if best_overall['model'] == 'AutoEncoder':\n",
    "            ae = best_config['autoencoder']\n",
    "            report.append(f\"    latent_dim: {ae['latent_dim']}\")\n",
    "            report.append(f\"    ssim_weight: {ae['ssim_weight']}\")\n",
    "            report.append(f\"    epochs: {ae['epochs']}\")\n",
    "            report.append(f\"    learning_rate: {ae['learning_rate']}\")\n",
    "        elif best_overall['model'] == 'PatchCore':\n",
    "            pc = best_config['patchcore']\n",
    "            report.append(f\"    memory_bank_size: {pc['memory_bank_size']}\")\n",
    "            report.append(f\"    k_neighbors: {pc['k_neighbors']}\")\n",
    "            report.append(f\"    use_multi_layer: {pc['use_multi_layer']}\")\n",
    "        elif best_overall['model'] == 'SimpleNet':\n",
    "            sn = best_config['simplenet']\n",
    "            report.append(f\"    noise_std: {sn['noise_std']}\")\n",
    "            report.append(f\"    adaptor_dim: {sn['adaptor_dim']}\")\n",
    "            report.append(f\"    epochs: {sn['epochs']}\")\n",
    "            report.append(f\"    use_multi_noise: {sn['use_multi_noise']}\")\n",
    "        elif best_overall['model'] == 'EfficientAD':\n",
    "            ead = best_config['efficientad']\n",
    "            report.append(f\"    backbone: {ead['backbone']}\")\n",
    "            report.append(f\"    student_dim: {ead['student_dim']}\")\n",
    "            report.append(f\"    autoencoder_dim: {ead['autoencoder_dim']}\")\n",
    "            report.append(f\"    epochs: {ead['epochs']}\")\n",
    "\n",
    "        report.append(\"\\n\" + \"-\" * 40)\n",
    "        report.append(\"ðŸ“ˆ BEST PER MODEL\")\n",
    "        report.append(\"-\" * 40)\n",
    "\n",
    "        for model_name, result in best_per_model.items():\n",
    "            cfg = result['config']\n",
    "            report.append(f\"\\n  [{model_name}]\")\n",
    "            report.append(f\"    Experiment: {result['experiment_name']}\")\n",
    "            report.append(f\"    AUC-ROC:    {result['auc_roc']:.4f}\")\n",
    "            report.append(f\"    AUPRO:      {result.get('aupro', 0.0):.4f}\")\n",
    "            report.append(f\"    F1 Score:   {result['f1_score']:.4f}\")\n",
    "            report.append(f\"    Accuracy:   {result['accuracy']:.4f}\")\n",
    "            report.append(f\"    Precision:  {result['precision']:.4f}\")\n",
    "            report.append(f\"    Recall:     {result['recall']:.4f}\")\n",
    "\n",
    "        report.append(\"\\n\" + \"-\" * 40)\n",
    "        report.append(\"ðŸ“ GENERATED FILES\")\n",
    "        report.append(\"-\" * 40)\n",
    "        report.append(\"  - experiment_results.csv\")\n",
    "        report.append(\"  - confusion_matrices.png\")\n",
    "        report.append(\"  - roc_curves.png\")\n",
    "        report.append(\"  - score_distributions.png\")\n",
    "        report.append(\"  - metrics_comparison.png\")\n",
    "        report.append(\"  - heatmaps/ (for best model)\")\n",
    "        report.append(\"  - summary_report.txt\")\n",
    "\n",
    "        report.append(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "\n",
    "        # Save to file\n",
    "        with open(os.path.join(self.output_dir, 'summary_report.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        print(\"âœ“ Summary report saved\")\n",
    "\n",
    "        return report_text\n",
    "\n",
    "    def save_all_visualizations(self):\n",
    "        \"\"\"Generate and save all visualizations\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ðŸ“Š GENERATING VISUALIZATIONS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        self.plot_confusion_matrices()\n",
    "        self.plot_roc_curves()\n",
    "        self.plot_score_distributions()\n",
    "        self.plot_metrics_comparison()\n",
    "        self.generate_summary_report()\n",
    "        self.save_best_config()\n",
    "\n",
    "    def save_best_config(self, metric: str = 'auc_roc'):\n",
    "        \"\"\"Save best model configuration to JSON\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        best = self.get_best_result(metric)\n",
    "        config = best['config']\n",
    "\n",
    "        # Add metrics to config\n",
    "        best_config = {\n",
    "            'experiment_name': best['experiment_name'],\n",
    "            'model_type': best['model'],\n",
    "            'metrics': {\n",
    "                'auc_roc': best['auc_roc'],\n",
    "                'f1_score': best['f1_score'],\n",
    "                'accuracy': best['accuracy'],\n",
    "                'precision': best['precision'],\n",
    "                'recall': best['recall'],\n",
    "                'threshold': best['threshold']\n",
    "            },\n",
    "            'config': config\n",
    "        }\n",
    "\n",
    "        config_path = os.path.join(self.output_dir, 'best_config.json')\n",
    "        with open(config_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(best_config, f, indent=2, default=str)\n",
    "        print(f\"âœ“ Best config saved: best_config.json\")\n",
    "\n",
    "    def save_best_model(self, metric: str = 'auc_roc'):\n",
    "        \"\"\"\n",
    "        Retrain and save the best model to file.\n",
    "        Note: This retrains the model with best config since we don't store model weights during grid search.\n",
    "        \"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        best = self.get_best_result(metric)\n",
    "        config = ExperimentConfig.from_dict(best['config'])\n",
    "        model_type = best['model']\n",
    "\n",
    "        print(f\"\\nðŸ’¾ Saving best model: {best['experiment_name']}\")\n",
    "        print(f\"   Retraining with best configuration...\")\n",
    "\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        paths = get_paths(config.base)\n",
    "\n",
    "        # Create datasets\n",
    "        train_ds = WoodDataset(paths[\"train_good\"], None, config.base.image_size, config.base.augmentation_type)\n",
    "        train_loader = DataLoader(train_ds, batch_size=config.base.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        # Create and train model\n",
    "        if model_type == \"AutoEncoder\":\n",
    "            model = AutoEncoderModel(config.autoencoder, config.base, device)\n",
    "        elif model_type == \"PatchCore\":\n",
    "            model = PatchCoreModel(config.patchcore, config.base, device)\n",
    "        elif model_type == \"SimpleNet\":\n",
    "            model = SimpleNetModel(config.simplenet, config.base, device)\n",
    "        elif model_type == \"EfficientAD\":\n",
    "            model = EfficientADModel(config.efficientad, config.base, device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_type}\")\n",
    "\n",
    "        model.fit(train_loader, verbose=True)\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(self.output_dir, f'best_model_{model_type.lower()}.pkl')\n",
    "\n",
    "        # For AutoEncoder, save the nn.Module state dict\n",
    "        if model_type == \"AutoEncoder\":\n",
    "            torch.save({\n",
    "                'model_state_dict': model.model.state_dict(),\n",
    "                'config': best['config'],\n",
    "                'metrics': {\n",
    "                    'auc_roc': best['auc_roc'],\n",
    "                    'aupro': best.get('aupro', 0.0),\n",
    "                    'f1_score': best['f1_score'],\n",
    "                    'threshold': best['threshold']\n",
    "                }\n",
    "            }, model_path)\n",
    "        else:\n",
    "            # For PatchCore, SimpleNet, and EfficientAD, save with pickle\n",
    "            save_data = {\n",
    "                'model_type': model_type,\n",
    "                'config': best['config'],\n",
    "                'metrics': {\n",
    "                    'auc_roc': best['auc_roc'],\n",
    "                    'aupro': best.get('aupro', 0.0),\n",
    "                    'f1_score': best['f1_score'],\n",
    "                    'threshold': best['threshold']\n",
    "                }\n",
    "            }\n",
    "            if model_type == \"PatchCore\":\n",
    "                save_data['memory_bank'] = model.memory_bank\n",
    "                save_data['random_projection'] = model.random_projection\n",
    "            elif model_type == \"SimpleNet\":\n",
    "                save_data['adaptor_state'] = model.adaptor.state_dict()\n",
    "                save_data['disc_state'] = model.disc.state_dict()\n",
    "            elif model_type == \"EfficientAD\":\n",
    "                save_data['student_state'] = model.student.state_dict()\n",
    "                save_data['autoencoder_state'] = model.autoencoder.state_dict()\n",
    "                save_data['student_head_state'] = model.student_head.state_dict()\n",
    "\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(save_data, f)\n",
    "\n",
    "        print(f\"âœ“ Best model saved: {os.path.basename(model_path)}\")\n",
    "\n",
    "    def save_best_heatmaps(self, metric: str = 'auc_roc'):\n",
    "        \"\"\"Save heatmaps for best model\"\"\"\n",
    "        best = self.get_best_result(metric)\n",
    "        print(f\"\\nðŸ“¸ Generating heatmaps for best model: {best['experiment_name']}\")\n",
    "\n",
    "        save_heatmaps(\n",
    "            best['model'], best['scores'], best['maps'],\n",
    "            best['labels'], best['paths'], best['threshold'],\n",
    "            self.output_dir\n",
    "        )\n",
    "        print(f\"âœ“ Heatmaps saved\")\n",
    "\n",
    "    def save_all_best_heatmaps(self, metric: str = 'auc_roc'):\n",
    "        \"\"\"Save heatmaps for best result of EACH model type\"\"\"\n",
    "        if len(self.results) == 0:\n",
    "            return\n",
    "\n",
    "        # Group results by model type\n",
    "        models = {}\n",
    "        for r in self.results:\n",
    "            model = r['model']\n",
    "            if model not in models:\n",
    "                models[model] = []\n",
    "            models[model].append(r)\n",
    "\n",
    "        print(f\"\\nðŸ“¸ Generating heatmaps for best result of each model...\")\n",
    "        print(f\"   Models found: {list(models.keys())}\")\n",
    "\n",
    "        for model_name, results in models.items():\n",
    "            # Find best result for this model\n",
    "            best = max(results, key=lambda x: x[metric])\n",
    "            print(f\"\\n   [{model_name}] Best: {best['experiment_name']} (AUC: {best['auc_roc']:.4f})\")\n",
    "\n",
    "            save_heatmaps(\n",
    "                model_name, best['scores'], best['maps'],\n",
    "                best['labels'], best['paths'], best['threshold'],\n",
    "                self.output_dir\n",
    "            )\n",
    "            print(f\"   âœ“ {model_name} heatmaps saved\")\n",
    "\n",
    "        print(f\"\\nâœ… All model heatmaps saved to: {self.output_dir}/heatmaps/\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main Functions\n",
    "# ============================================================================\n",
    "\n",
    "def run_quick_experiments():\n",
    "    \"\"\"Quick experiments with reduced parameters\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ”¬ QUICK EXPERIMENT MODE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Base config with reduced epochs\n",
    "    base = ExperimentConfig()\n",
    "    # BaseConfig'deki environment deÄŸeri kullanÄ±lacak (local)\n",
    "    base.autoencoder.epochs = 20\n",
    "    base.simplenet.epochs = 15\n",
    "\n",
    "    # Get paths based on environment (local vs colab)\n",
    "    paths = get_paths(base.base)\n",
    "    output_dir = os.path.join(paths[\"results\"], f\"experiment_{timestamp}\")\n",
    "\n",
    "    runner = ExperimentRunner(output_dir)\n",
    "\n",
    "    # AutoEncoder grid\n",
    "    runner.run_grid_search(\"AutoEncoder\", {\n",
    "        'latent_dim': [128, 256],\n",
    "        'ssim_weight': [0.3, 0.5, 0.7]\n",
    "    }, base)\n",
    "\n",
    "    # PatchCore grid (-1 = use all patches)\n",
    "    runner.run_grid_search(\"PatchCore\", {\n",
    "        'memory_bank_size': [2000, 5000, -1],\n",
    "        'k_neighbors': [3, 5, 9]\n",
    "    }, base)\n",
    "\n",
    "    # SimpleNet grid\n",
    "    runner.run_grid_search(\"SimpleNet\", {\n",
    "        'noise_std': [0.01, 0.015, 0.02]\n",
    "    }, base)\n",
    "\n",
    "    # EfficientAD grid\n",
    "    base.efficientad.epochs = 25  # Reduced for quick mode\n",
    "    runner.run_grid_search(\"EfficientAD\", {\n",
    "        'student_dim': [256, 384],\n",
    "        'autoencoder_dim': [256, 384]\n",
    "    }, base)\n",
    "\n",
    "    # Save and display results\n",
    "    df = runner.save_results()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.sort_values('AUC_ROC', ascending=False).to_string(index=False))\n",
    "\n",
    "    # Generate all visualizations\n",
    "    runner.save_all_visualizations()\n",
    "    runner.save_all_best_heatmaps()  # Save heatmaps for all 4 models\n",
    "\n",
    "    print(f\"\\nâœ… Experiments complete! Results in: {output_dir}\")\n",
    "    return runner\n",
    "\n",
    "\n",
    "def run_full_experiments():\n",
    "    \"\"\"Full experiments with all parameters\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ”¬ FULL EXPERIMENT MODE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    base = ExperimentConfig()\n",
    "    # BaseConfig'deki environment deÄŸeri kullanÄ±lacak (local)\n",
    "\n",
    "    # Get paths based on environment (local vs colab)\n",
    "    paths = get_paths(base.base)\n",
    "    output_dir = os.path.join(paths[\"results\"], f\"experiment_full_{timestamp}\")\n",
    "\n",
    "    runner = ExperimentRunner(output_dir)\n",
    "\n",
    "    # # AutoEncoder\n",
    "    # runner.run_grid_search(\"AutoEncoder\", {\n",
    "    #     'latent_dim': [128, 256, 512],\n",
    "    #     'ssim_weight': [0.3, 0.5, 0.7],\n",
    "    #     'learning_rate': [1e-3, 5e-4]\n",
    "    # }, base)\n",
    "\n",
    "    # PatchCore\n",
    "    runner.run_grid_search(\"PatchCore\", {\n",
    "        'memory_bank_size': [1000, 2000, 3000],\n",
    "        'k_neighbors': [3, 5, 9],\n",
    "        'use_multi_layer': [True, False]\n",
    "    }, base)\n",
    "\n",
    "    # SimpleNet\n",
    "    runner.run_grid_search(\"SimpleNet\", {\n",
    "        'noise_std': [0.01, 0.015, 0.02],\n",
    "        'adaptor_dim': [256, 512],\n",
    "        'use_multi_noise': [True, False]\n",
    "    }, base)\n",
    "\n",
    "    # EfficientAD\n",
    "    runner.run_grid_search(\"EfficientAD\", {\n",
    "        'student_dim': [256, 384, 512],\n",
    "        'autoencoder_dim': [256, 384, 512],\n",
    "        'backbone': ['resnet18']\n",
    "    }, base)\n",
    "\n",
    "    df = runner.save_results()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š RESULTS SUMMARY (Top 10)\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.sort_values('AUC_ROC', ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "    # Generate all visualizations\n",
    "    runner.save_all_visualizations()\n",
    "    runner.save_all_best_heatmaps()  # Save heatmaps for all 4 models\n",
    "\n",
    "    print(f\"\\nâœ… Full experiments complete! Results in: {output_dir}\")\n",
    "    return runner\n",
    "\n",
    "\n",
    "def run_single_model(model_type: str):\n",
    "    \"\"\"Run experiments for single model\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(f\"\\nðŸ”¬ Single Model Experiment: {model_type}\")\n",
    "\n",
    "    base = ExperimentConfig()\n",
    "    # BaseConfig'deki environment deÄŸeri kullanÄ±lacak (local)\n",
    "    base.autoencoder.epochs = 30\n",
    "    base.simplenet.epochs = 20\n",
    "\n",
    "    # Get paths based on environment (local vs colab)\n",
    "    paths = get_paths(base.base)\n",
    "    output_dir = os.path.join(paths[\"results\"], f\"experiment_{model_type.lower()}_{timestamp}\")\n",
    "\n",
    "    runner = ExperimentRunner(output_dir)\n",
    "\n",
    "    if model_type == \"AutoEncoder\":\n",
    "        runner.run_grid_search(\"AutoEncoder\", {\n",
    "            'latent_dim': [128, 256, 512],\n",
    "            'ssim_weight': [0.3, 0.5, 0.7]\n",
    "        }, base)\n",
    "    elif model_type == \"PatchCore\":\n",
    "        runner.run_grid_search(\"PatchCore\", {\n",
    "            'memory_bank_size': [1000, 2000, 3000],\n",
    "            'k_neighbors': [3, 5, 9]\n",
    "        }, base)\n",
    "    elif model_type == \"SimpleNet\":\n",
    "        runner.run_grid_search(\"SimpleNet\", {\n",
    "            'noise_std': [0.01, 0.015, 0.02],\n",
    "            'adaptor_dim': [256, 512]\n",
    "        }, base)\n",
    "    elif model_type == \"EfficientAD\":\n",
    "        base.efficientad.epochs = 30\n",
    "        runner.run_grid_search(\"EfficientAD\", {\n",
    "            'student_dim': [256, 384, 512],\n",
    "            'autoencoder_dim': [256, 384, 512]\n",
    "        }, base)\n",
    "\n",
    "    df = runner.save_results()\n",
    "    print(\"\\nðŸ“Š Results:\")\n",
    "    print(df.sort_values('AUC_ROC', ascending=False).to_string(index=False))\n",
    "\n",
    "    # Generate all visualizations\n",
    "    runner.save_all_visualizations()\n",
    "    runner.save_all_best_heatmaps()  # Save heatmaps for all models\n",
    "    return runner\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    import sys\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ”¬ WOOD ANOMALY DETECTION V3 - EXPERIMENT FRAMEWORK\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Parse arguments\n",
    "    mode = \"full\"  # default\n",
    "    model = None\n",
    "\n",
    "    for arg in sys.argv[1:]:\n",
    "        if arg.startswith(\"--mode=\"):\n",
    "            mode = arg.split(\"=\")[1]\n",
    "        elif arg.startswith(\"--model=\"):\n",
    "            model = arg.split(\"=\")[1]\n",
    "        elif arg == \"--quick\":\n",
    "            mode = \"quick\"\n",
    "        elif arg == \"--full\":\n",
    "            mode = \"full\"\n",
    "\n",
    "    # Run appropriate mode\n",
    "    if mode == \"quick\":\n",
    "        run_quick_experiments()\n",
    "    elif mode == \"full\":\n",
    "        run_full_experiments()\n",
    "    elif mode == \"single\" and model:\n",
    "        run_single_model(model)\n",
    "    else:\n",
    "        print(\"Usage:\")\n",
    "        print(\"  --mode=quick    Quick experiments (reduced epochs)\")\n",
    "        print(\"  --mode=full     Full experiments (all parameters)\")\n",
    "        print(\"  --mode=single --model=AutoEncoder|PatchCore|SimpleNet|EfficientAD\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPoh4Oig5eYrfCcce2MZga8",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1PJrNxn7rrclV7y4QfYPLk9KX-miBIfYB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
